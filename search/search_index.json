{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#nmims-notes-bti-25","title":"NMIMS Notes - BTI 25'","text":"Scheduled Time Table Day &amp; Date Course Time Monday, 28 April, 2025 Reverse Engineering and Malware Analysis 2:00 pm - 5:00 pm Wednesday, 30 April, 2025 Robotic Process Automation (Practical) 10:00 am - 01:00 pm Friday, 2 May, 2025 Information Systems Audit 10:00 am - 01:00 pm Saturday, 3 May, 2025 Computer Vision 2:00 pm - 5:00 pm Thursday, 8 May, 2025 Reinforcement Learning (Practical) 10:00 am - 01:00 pm Saturday, 10 May, 2025 Mobile Computing 10:00 am - 01:00 pm Monday, 12 May, 2025 Mobile Device Security and Forensics 10:00 am - 01:00 pm"},{"location":"RL_Unit1/","title":"RL Unit1","text":""},{"location":"RL_Unit1/#unit-1","title":"Unit 1","text":"<pre><code>graph LR\n    subgraph Input\n    A[Data with Labels] --&gt; B[Supervised Learning]\n    C[Data without Labels] --&gt; D[Unsupervised Learning]\n    E[States + Actions] --&gt; F[Reinforcement Learning]\n    end\n\n    B --&gt; G[Mapping]\n    D --&gt; H[Classes]\n    F --&gt; I[Action]\n\n    B -.-&gt;|Error| B\n    F -.-&gt;|Reward| F</code></pre>"},{"location":"RL_Unit1/#supervised-learning","title":"Supervised Learning","text":"<p>Definition: Learning from labeled data where the model maps inputs to outputs.</p> <ul> <li>Input: Labeled data (features + target labels)</li> <li>Process: Learning from labeled examples</li> <li>Output: Prediction model</li> <li>Feedback: Error measurement against known labels</li> </ul>"},{"location":"RL_Unit1/#applications","title":"Applications","text":"<ul> <li>Classification: Spam detection, Image recognition</li> <li>Regression: Price prediction, Sales forecasting</li> </ul>"},{"location":"RL_Unit1/#unsupervised-learning","title":"Unsupervised Learning","text":"<p>Definition: Learning patterns from unlabeled data.</p> <ul> <li>Input: Unlabeled data</li> <li>Process: Pattern/structure discovery</li> <li>Output: Data grouping/structure</li> <li>Feedback: Internal validation metrics</li> </ul>"},{"location":"RL_Unit1/#applications_1","title":"Applications","text":"<ul> <li>Clustering: Customer segmentation</li> <li>Dimensionality Reduction: Feature extraction</li> </ul>"},{"location":"RL_Unit1/#reinforcement-learning-rl","title":"Reinforcement Learning (RL)","text":"<p>Definition: Learning through trial and error to maximize rewards.</p> <ul> <li>Input: States + possible actions</li> <li>Process: Trial and error learning</li> <li>Output: Action policy</li> <li>Feedback: Rewards/penalties</li> </ul>"},{"location":"RL_Unit1/#applications_2","title":"Applications","text":"<ul> <li>Game AI: Chess, Go</li> <li>Robotics: Navigation, Control</li> </ul>"},{"location":"RL_Unit1/#common-algorithms","title":"Common Algorithms","text":"Learning Type Algorithms Supervised Linear Regression, Random Forest, Neural Networks Unsupervised K-means, PCA, Autoencoders Reinforcement Q-Learning, Policy Gradient, DQN"},{"location":"RL_Unit1/#reinforcement-learning-rl_1","title":"Reinforcement Learning (RL)","text":"<p>Reinforcement learning is learning what to do\u2014how to map situations to actions\u2014so as to maximize a numerical reward signal. The learner is not told which actions to take, but instead must discover which actions yield the most reward by trying them. In the most interesting and challenging cases, actions may a\u21b5ect not only the immediate reward but also the next situation and, through that, all subsequent rewards. These two characteristics\u2014trial-and-error search and delayed reward\u2014are the two most important distinguishing features of reinforcement learning.</p>"},{"location":"RL_Unit1/#key-characteristics","title":"Key Characteristics","text":"<ul> <li>Reward and Punishment: Encourages repeating good actions and avoiding bad ones.</li> <li>Trial and Error: Learns by trying different methods.</li> <li>Learning Over Time: Improves through continuous experience.</li> <li>Long-Term Rewards: Actions influence future rewards.</li> </ul>"},{"location":"RL_Unit1/#example-applications","title":"Example Applications","text":"<ul> <li>Chess</li> <li>Maze Solving</li> <li>Industrial Robot Arms</li> <li>Path Planning</li> <li>Sweeper Robots</li> </ul>"},{"location":"RL_Unit1/#how-rl-differs-from-supervised-learning","title":"How RL Differs from Supervised Learning","text":"Feature Supervised Learning Reinforcement Learning Training Data Has labeled answers No labeled answers; learns from experience Decision Making Independent of past decisions Dependent on past decisions Learning Method Trained with a dataset Learns through trial and error"},{"location":"RL_Unit1/#elements-of-rl","title":"Elements of RL","text":"<pre><code>graph LR\n    A[Agent] --&gt;|Action| B[Environment]\n    B --&gt;|State| A\n    B --&gt;|Reward| A</code></pre>"},{"location":"RL_Unit1/#agent","title":"Agent","text":"<ul> <li>Definition: An entity that interacts with the environment.</li> <li>Examples: Robot, human, software program.</li> </ul>"},{"location":"RL_Unit1/#environment","title":"Environment","text":"<ul> <li>Definition: The external system in which the agent operates.</li> <li>Examples: Physical world, game simulation.</li> </ul>"},{"location":"RL_Unit1/#learning-process","title":"Learning Process","text":"<ol> <li>The agent moves from the initial state to the goal state.</li> <li>The agent continually asks, \"What is the best action in each state?\"</li> </ol>"},{"location":"RL_Unit1/#advantages-of-reinforcement-learning","title":"Advantages of Reinforcement Learning","text":"<ul> <li>\u2705 No need for predefined instructions or human intervention. </li> <li>\u2705 Can adapt to both static and dynamic environments. </li> <li>\u2705 Solves a wide range of problems (decision-making, prediction, optimization). </li> <li>\u2705 Improves with experience and fine-tunes over time.</li> </ul>"},{"location":"RL_Unit1/#disadvantages-of-reinforcement-learning","title":"Disadvantages of Reinforcement Learning","text":"<ul> <li>\u274c Performance depends on the quality of the reward function. </li> <li>\u274c Designing and tuning RL models can be complex.</li> </ul> <p>Note</p> <p>Reinforcement Learning is most suitable when: - The problem environment is complex and uncertain, making traditional programming methods ineffective. - Feedback is sparse, delayed, and dependent on multiple decisions. - Decision-making (actions) follows a feedback loop.</p> <p>Why Is Reinforcement Learning Difficult?</p> <p>The toughest parts of Reinforcement Learning are: - Mapping the Environment. - Including All Possible Actions.</p> <p>Core Concepts</p> <ul> <li>Goal-Oriented Learning: The agent learns by trying to achieve a goal.</li> <li>Learning from Consequences: The agent learns from the consequences of its actions.</li> <li>Active Research Area: RL is one of the most active fields in Artificial Intelligence (AI).</li> </ul>"},{"location":"RL_Unit1/#rl-algorithm-steps","title":"RL Algorithm Steps","text":"<pre><code>graph TD;\n    A[Agent Observes Environment] --&gt; B[Agent Performs Action];\n    B --&gt; C[Agent Moves to New State];\n    C --&gt; D[Agent Receives Reward];\n    D --&gt; E[Agent Evaluates Action - Good or Bad];\n    E --&gt; F[Agent Adjusts Strategy to Maximize Reward];\n\n</code></pre>"},{"location":"RL_Unit1/#learning-and-planning","title":"Learning and Planning","text":""},{"location":"RL_Unit1/#two-fundamental-problems-in-sequential-decision-making","title":"Two Fundamental Problems in Sequential Decision Making","text":""},{"location":"RL_Unit1/#reinforcement-learning-rl_2","title":"Reinforcement Learning (RL):","text":"<ul> <li>The environment is initially unknown.</li> <li>The agent interacts with the environment.<ul> <li>The agent improves its policy.</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#planning","title":"Planning:","text":"<ul> <li>A model of the environment is known.</li> <li>The agent performs computations with its model (without any external interaction).</li> <li>The agent improves its policy, also known as deliberation, reasoning, introspection, pondering, thought, search.</li> </ul>"},{"location":"RL_Unit1/#model-of-the-environment","title":"Model of the Environment:","text":"<ul> <li>A model mimics the behavior of the environment. With the help of the model, one can make inferences about how the environment will behave. For example, if a state and an action are given, the model can predict the next state and reward.</li> <li>The model is used for planning, providing a way to take a course of action by considering all future situations before actually experiencing those situations.</li> <li>Approaches for solving RL problems with the help of the model are termed model-based approach.</li> <li>An approach without using a model is called a model-free approach.</li> </ul>"},{"location":"RL_Unit1/#types-of-reinforcement-learning-algorithms-on-the-basis-of-model-based","title":"Types of Reinforcement Learning Algorithms ( on the basis of model based)","text":"<p>There are various algorithms used in reinforcement learning such as Q-learning, policy gradient methods, Monte Carlo method and many more. All these algorithms can be classified into two broad categories - </p>"},{"location":"RL_Unit1/#model-free-reinforcement-learning","title":"Model-free Reinforcement Learning :","text":"<ul> <li>It is a category of reinforcement learning algorithms that learns to make decisions by interacting with the environment directly, without creating a model of the environment's dynamics.</li> <li>The agent performs different actions multiple times to learn the outcomes and creates a strategy (policy) that optimizes its reward points. This is ideal for changing, large or complex environments.</li> <li>Not applicable for some scenario like self driving car.</li> </ul>"},{"location":"RL_Unit1/#model-based-reinforcement-learning","title":"Model-based Reinforcement Learning:","text":"<ul> <li>This category of reinforcement learning algorithms involves creating a model of the environment's dynamics to make decisions and improve performance.</li> <li>Ideal for environments that are static and well-defined, where real-world environment testing is difficult.</li> </ul>"},{"location":"RL_Unit1/#key-differences-between-model-free-and-model-based-reinforcement-learning","title":"Key Differences Between Model-free and Model-based Reinforcement Learning","text":"Feature Model-Free RL Model-Based RL Learning Approach Direct learning from environment Indirect learning through model building Efficiency Requires more real-world interactions More sample-efficient Complexity Simpler implementation More complex due to model learning Environment Utilization No internal model Builds and uses a model Adaptability Slower to adapt to changes Faster adaptation with accurate model Computational Requirements Less intensive More computational resources needed Examples Q-Learning, SARSA, DQN, PPO Dyna-Q, Model-Based Value Iteration"},{"location":"RL_Unit1/#rl-framework-the-rl-process-a-loop-of-state-action-reward-and-next-state","title":"RL Framework - The RL Process: A Loop of State, Action, Reward, and Next State","text":""},{"location":"RL_Unit1/#main-characteristics-of-rl","title":"Main Characteristics of RL","text":"<ul> <li>No supervisor while training.</li> <li>Environment is generally stochastic for real-world applications.</li> <li>Model of the environment can be incomplete.</li> <li>Feedback (Negative/Positive Reward) can be delayed or partial.</li> <li>The agent uses experience from the past to improve its performance over time.</li> <li>Actions that have fetched more rewards are preferred.</li> <li>The agent tries various actions and prefers those that are best or have fetched more rewards.</li> <li>RL uses Markov Decision Process (MDP) framework to define the interaction between a learning agent and its environment.</li> </ul>"},{"location":"RL_Unit1/#reinforcement-learning-rl-problem-challenges-in-rl","title":"Reinforcement Learning (RL) Problem - Challenges in RL","text":""},{"location":"RL_Unit1/#trade-off-between-exploration-and-exploitation","title":"Trade-off between Exploration and Exploitation:","text":"<ul> <li>To obtain rewards, an RL agent must prefer actions that it has tried in the past and found effective (Exploit).</li> <li>However, to discover such actions, it must try actions it has not selected before (Explore).</li> </ul> <p>Note</p> <p>Neither exploration nor exploitation can be pursued exclusively without failing at the task.</p>"},{"location":"RL_Unit1/#fundamental-components-of-rl","title":"Fundamental Components of RL","text":"<ul> <li>Policy: Defines the agent\u2019s behavior.</li> <li>Reward Function: Provides feedback on actions.</li> <li>Value Function: Evaluates future rewards.</li> <li>Model of the Environment: Simulates how the environment works.</li> </ul>"},{"location":"RL_Unit1/#policy","title":"Policy:","text":"<p>A policy is a strategy or set of rules that defines the actions the agent should take in a given state.</p> <ul> <li>The policy can be deterministic (one action for a state) or stochastic (probabilistic actions for a state).</li> <li>The goal is to find an optimal policy that maximizes the total expected reward.</li> </ul> <p>Example:</p> <ul> <li>A robot navigating a maze may follow a policy that says, \"Always turn left unless there's an obstacle, then turn right.\"</li> </ul> <p>Note</p> <p>A policy is like a person's habit or plan of action, such as the decision to exercise every morning or take an umbrella when it's cloudy.</p>"},{"location":"RL_Unit1/#value-function","title":"Value function:","text":"<p>Roughly speaking, the value of a state is the total amount of reward an agent can expect to accumulate over the future, starting from that state.  - Rewards determine the immediate, intrinsic desirability of environmental states.  - Values indicate the long-term desirability of states after considering the states likely to follow and the rewards available in those states.  - Example: - A state might always yield a low immediate reward but still have a high value because it is followed by states that yield high rewards. </p> <p>Note</p> <p>Rewards are somewhat like pleasure (if high) and pain (if low). - Values correspond to a more refined and farsighted judgment of how pleased or displeased we are by the environment.</p>"},{"location":"RL_Unit1/#reward-function","title":"Reward Function:","text":"<p>The reward function provides feedback on the actions the agent takes, indicating whether an action was good or bad.</p> <ul> <li>It assigns a numeric value to the agent's actions, which the agent uses to evaluate the desirability of its actions in a given state.</li> <li>The goal of the agent is to maximize the cumulative reward over time.</li> </ul> <p>Example:</p> <ul> <li>In a game, winning a round might give a reward of +10, while losing gives a reward of -1.</li> </ul> <p>Note</p> <p>The reward function is like the feedback a person gets from their actions, such as feeling happy after a good deed or guilty after a mistake.</p>"},{"location":"RL_Unit1/#model-of-the-environment_1","title":"Model of the Environment:","text":"<p>The model of the environment simulates how the environment behaves, helping the agent predict the outcomes of actions.</p> <ul> <li>This model can be used for planning future actions by simulating potential outcomes.</li> <li>A model-free approach directly learns from experience, while a model-based approach uses a model to predict actions' results before performing them.</li> </ul> <p>Example:</p> <ul> <li>A self-driving car may use a model to simulate various driving scenarios and plan its route accordingly.</li> </ul> <p>Note</p> <p>The model of the environment is like a mental map that a person forms, which helps them predict the likely outcomes of their actions, such as deciding to avoid a route with heavy traffic.</p>"},{"location":"RL_Unit1/#types-of-reinforcement-learning","title":"Types of Reinforcement Learning","text":"<p>There are three main types of Reinforcement Learning (RL): - Value-Based - Policy-Based - Model-Based</p> <p>Each approach has its own strengths and weaknesses, and the choice of algorithm will depend on the specific problem you are trying to solve.</p>"},{"location":"RL_Unit1/#value-based-reinforcement-learning","title":"Value-Based Reinforcement Learning","text":"<ul> <li>In this approach, the agent learns to estimate the value of each state or action based on the rewards it receives.</li> <li>This value is known as Q-values.</li> <li>The agent then selects the actions with the highest Q-value in each state to maximize its long-term reward.</li> <li>The most commonly used algorithm for value-based reinforcement learning is Q-learning.</li> </ul>"},{"location":"RL_Unit1/#policy-based-reinforcement-learning","title":"Policy-Based Reinforcement Learning","text":"<ul> <li>In this approach, the agent learns an optimal policy, which is a mapping from states to actions, without calculating the value function.</li> <li>The policy is updated based on the rewards received by the agent, with the goal of maximizing the expected reward over time.</li> <li>The most common algorithm used for policy-based reinforcement learning is the REINFORCE algorithm.</li> </ul>"},{"location":"RL_Unit1/#model-based-reinforcement-learning_1","title":"Model-Based Reinforcement Learning","text":"<ul> <li>In this approach, the agent learns a model of the environment, which it can use to simulate different scenarios and plan its actions accordingly.</li> <li>The model can learn through supervised or unsupervised learning, and the agent can use it to predict the outcome of its actions before taking them.</li> <li>The most common model-based reinforcement learning algorithm is the Dyna algorithm.</li> </ul>"},{"location":"RL_Unit1/#formal-presentation-of-rl-fundamentals","title":"Formal Presentation of RL Fundamentals","text":""},{"location":"RL_Unit1/#1-state-s-and-action-a","title":"1. State (\\(s\\)) and Action (\\(a\\))","text":"<ul> <li>Current state: \\(s_t\\)</li> <li>Next state: \\(s_{t+1}\\)</li> <li>Action: \\(a\\), an action performed by the agent to move from state \\(s_t\\) to \\(s_{t+1}\\).</li> <li>State space: The set of all possible states the agent can be in.</li> </ul>"},{"location":"RL_Unit1/#2-reward-r-or-rs-a","title":"2. Reward (\\(r\\) or \\(R(s, a)\\))","text":"<ul> <li>The result of taking action \\(a\\) at state \\(s\\).</li> <li>Actions affect not only the immediate reward but also the next states and all subsequent rewards.</li> </ul>"},{"location":"RL_Unit1/#3-episode","title":"3. Episode","text":"<ul> <li>A sequence of states and actions until reaching a terminal state.</li> </ul>"},{"location":"RL_Unit1/#4-transition-probability-ps-s-a","title":"4. Transition Probability (\\(P(s' | s, a)\\))","text":"<ul> <li>The probability of reaching state \\(s'\\) when taking action \\(a\\) at state \\(s_t\\).</li> </ul>"},{"location":"RL_Unit1/#5-policy-pis-a","title":"5. Policy (\\(\\pi(s, a)\\))","text":"<ul> <li>A mapping of each state to an action, determining how the agent acts at each state.</li> <li>Types of Policies:<ul> <li>Deterministic: Always selects the same action for a given state.</li> <li>Stochastic: Selects actions based on probability distribution.</li> <li>\\(\\pi(a | s) = P(A_t = a | S_t = s)\\).</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#6-return-g_t","title":"6. Return (\\(G_t\\))","text":"<ul> <li>The total future reward from state \\(s_t\\).</li> <li>\\(Gt=rt+\u03b3rt+1+\u03b32rt+2+\u22ef+\u03b3T\u22121rTG_t = r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + \\dots + \\gamma^{T-1} r_T\\)</li> <li>Discount factor (\\(\\gamma\\)):<ul> <li>Determines the importance of future rewards.</li> <li>Higher \\(\\gamma\\) \u2192 more focus on long-term rewards.</li> <li>Lower \\(\\gamma\\) \u2192 more focus on immediate rewards.</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#7-value-function-vs","title":"7. Value Function (\\(V(s)\\))","text":"<ul> <li>The expected return from starting at state \\(s\\).</li> <li>Also called the State-Value Function:  </li> </ul> <p>Formula</p> <p>\\(V(s)=E[Gt\u2223st=s]=E[rt+\u03b3rt+1+\u03b32rt+2+\u22ef+\u03b3T\u22121rT\u2223st=s]V(s) = \\mathbb{E}[G_t | s_t = s] = \\mathbb{E} \\left[ r_t + \\gamma r_{t+1} + \\gamma^2 r_{t+2} + \\dots + \\gamma^{T-1} r_T \\mid s_t = s \\right]\\)</p> <ul> <li>Breakdown:<ul> <li>Immediate reward: \\(r_t\\).</li> <li>Discounted value of successor states.</li> <li>Represents the long-term desirability of state \\(s\\).</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#8-optimal-policy-pis","title":"8. Optimal Policy (\\(\\pi^*(s)\\))","text":"<ul> <li>The best possible policy for a given state, maximizing expected future rewards.</li> </ul>"},{"location":"RL_Unit1/#9-optimal-value-functions","title":"9. Optimal Value Functions","text":"<ul> <li>Optimal State-Value Function:<ul> <li>Maximum value function over all policies: \\(V\u2217(s)=max\u2061\u03c0V\u03c0(s)V^*(s) = \\max_{\\pi} V_{\\pi}(s)\\)</li> </ul> </li> <li>Optimal Action-Value Function (\\(Q^*(s, a)\\)):<ul> <li>Maximum action-value function over all policies: \\(Q\u2217(s,a)=max\u2061\u03c0Q\u03c0(s,a)Q^*(s, a) = \\max_{\\pi} Q_{\\pi}(s, a)\\)</li> <li>Represents the best possible expected return for taking action \\(a\\) in state \\(s\\).</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#two-fundamental-tasks-of-reinforcement-learning","title":"Two Fundamental Tasks of Reinforcement Learning","text":""},{"location":"RL_Unit1/#1-prediction-task","title":"1. Prediction Task","text":"<ul> <li>We have a policy:<ul> <li>The goal is to evaluate the policy by estimating the state-value or Q-value of running actions within a given policy.</li> <li>Evaluate the future.</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#2-control-task","title":"2. Control Task","text":"<ul> <li>We don't know the policy, and the goal is:<ul> <li>To find the optimal policy aiming to collect maximum rewards.</li> <li>Optimize the future.</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#tabular-solution-methods","title":"Tabular Solution Methods","text":""},{"location":"RL_Unit1/#core-idea","title":"Core Idea","text":"<ul> <li>In their simplest form, RL algorithms assume that the state and action spaces are small enough for approximate value functions to be represented as arrays or tables.</li> <li>These methods can often find exact solutions (i.e., optimal value function and optimal policy).</li> </ul>"},{"location":"RL_Unit1/#fundamental-classes-of-methods-for-solving-finite-mdps","title":"Fundamental Classes of Methods for Solving Finite MDPs","text":"<ol> <li> <p>Dynamic Programming (DP)</p> <ul> <li>Requires a complete and accurate model of the environment.</li> <li>Mathematically well-developed.</li> <li> <p>Monte Carlo Methods</p> </li> <li> <p>No model required and conceptually simple.</p> </li> <li>Not well suited for step-by-step incremental computation.</li> <li> <p>Temporal Difference (TD) Learning</p> </li> <li> <p>Requires no model and is fully incremental.</p> </li> <li>More complex to analyze but efficient.</li> <li>Differences exist in efficiency and speed of convergence.</li> </ul> </li> </ol> <p>Each method has its own strengths and weaknesses.</p>"},{"location":"RL_Unit1/#immediate-reinforcement-learning-vs-full-reinforcement-learning","title":"Immediate Reinforcement Learning vs. Full Reinforcement Learning","text":""},{"location":"RL_Unit1/#immediate-reinforcement-learning-immediate-rl","title":"Immediate Reinforcement Learning (Immediate RL)","text":"<ul> <li>Policy Update Frequency<ul> <li>Updates the policy or value function after every action.</li> <li>The agent learns and adapts in real time as it interacts with the environment.</li> </ul> </li> <li>Learning Approach<ul> <li>Online Learning: Updates are made continuously and incrementally after each interaction.</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#immediate-rl-vs-full-rl","title":"Immediate RL vs. Full RL","text":"Feature Immediate RL Full RL Reward Timing Immediate rewards after each action. Delayed rewards, requiring long-term strategy. Decision Making Faster, as actions are evaluated instantly. Requires profound understanding of the environment. Example Bandit Problem Chess, Go, or strategic planning tasks."},{"location":"RL_Unit1/#explore-exploit-dilemma-in-immediate-rl","title":"Explore-Exploit Dilemma in Immediate RL","text":"<ul> <li>The agent must explore different actions to identify near-optimal actions.</li> <li>Once enough exploration is done, it exploits the best-known action.</li> <li>The challenge: How much to explore before exploiting?</li> </ul>"},{"location":"RL_Unit1/#examples-of-reinforcement-learning-in-real-life","title":"Examples of Reinforcement Learning in Real Life","text":""},{"location":"RL_Unit1/#immediate-rl-examples","title":"Immediate RL Examples","text":"<ul> <li>Giving treats for homework completion.</li> <li>Earning points in a game.</li> <li>Receiving applause after a performance.</li> <li>Receiving praise for completing a task.</li> <li>Getting paid directly after work.</li> <li>Eating immediately after feeling hungry.</li> <li>Social media notifications.</li> </ul>"},{"location":"RL_Unit1/#delayed-reinforcement-examples","title":"Delayed Reinforcement Examples`","text":"<ul> <li>Saving money for future goals.</li> <li>Completing a degree for career advancement.</li> <li>Physical fitness and exercise.</li> <li>Learning a musical instrument.</li> <li>Learning a new language.</li> </ul>"},{"location":"RL_Unit1/#suitability-of-immediate-rl","title":"Suitability of Immediate RL","text":"<ul> <li>Real-time applications: Suitable where quick decision-making is needed, such as:<ul> <li>Tic-Tac-Toe: The agent updates its strategy after each move.</li> <li>Self-driving cars: The control system updates the driving policy in real time.</li> </ul> </li> </ul>"},{"location":"RL_Unit1/#general-reinforcement-learning-rl","title":"General Reinforcement Learning (RL","text":"<ul> <li> <p>Policy Update Frequency</p> <ul> <li>Updates can be made after accumulating a batch of experiences or at the end of an episode.</li> <li> <p>Learning Approach</p> </li> <li> <p>Online and Offline Learning</p> <ul> <li>Online RL: Updates occur during interaction with the environment.</li> <li>Offline RL: The agent gathers experience first and updates the policy afterward.</li> </ul> </li> </ul> </li> </ul>"},{"location":"RL_Unit1/#state-action-value-function-qs-a","title":"State-Action Value Function (\\(Q(s, a)\\))","text":"<ul> <li>The state-action value function (or Q-function) specifies how good it is for an agent to take a particular action \\(a\\) in a given state \\(s\\) under a policy \\(\\pi\\).</li> <li>Denoted as: \\(Q(s,a)=E[Gt\u2223St=s,At=a]Q(s, a) = \\mathbb{E}[G_t | S_t = s, A_t = a]\\)</li> <li>Represents the expected cumulative reward of taking action \\(a\\) in state \\(s\\).</li> </ul>"},{"location":"RL_Unit1/#reinforcement-learning-rl-fundamentals","title":"Reinforcement Learning (RL) Fundamentals","text":""},{"location":"RL_Unit1/#temporal-difference-td-learning","title":"Temporal Difference (TD) Learning","text":"<ul> <li>A simple rule to explain complex behaviors.</li> <li>Intuition: Prediction of the outcome at time t+1t+1t+1 is better than at time ttt. The later prediction is used to adjust the earlier prediction.</li> <li>Has had a profound impact on behavioral psychology and neuroscience.</li> </ul>"},{"location":"RL_Unit1/#optimal-control","title":"Optimal Control","text":"<ul> <li>A branch of mathematical optimization.</li> <li>Goal: Design a controller that maximizes or minimizes an objective function.</li> <li>Key Concept: Finding a control policy that optimizes the cumulative reward or minimizes the cost over time.</li> <li>Deals with dynamical systems, determining the best sequence of actions to achieve an optimal outcome.</li> </ul>"},{"location":"RL_Unit1/#dynamic-programming-dp-in-rl","title":"Dynamic Programming (DP) in RL","text":"<ul> <li>A mathematical approach to solving optimization problems by breaking them down into simpler subproblems.</li> <li>In Markov Decision Processes (MDPs), DP methods help find optimal policies by solving Bellman equations.</li> </ul>"},{"location":"RL_Unit1/#two-primary-dp-methods","title":"Two Primary DP Methods","text":"<ol> <li>Policy Iteration:<ul> <li>Alternates between evaluating a policy and improving it.</li> </ul> </li> <li>Value Iteration:<ul> <li>Iteratively updates the value function directly to find the optimal policy.</li> </ul> </li> </ol>"},{"location":"RL_Unit1/#on-policy-vs-off-policy-reinforcement-learning","title":"On-Policy vs. Off-Policy Reinforcement Learning","text":"<p>In Reinforcement Learning (RL), learning strategies can be classified into on-policy and off-policy methods. These approaches define how an agent interacts with the environment and learns optimal behavior.  </p>"},{"location":"RL_Unit1/#on-policy-learning","title":"On-Policy Learning","text":"<ul> <li>The agent learns while following its own policy.  </li> <li>Explores and exploits simultaneously.  </li> <li>Typically used in algorithms like SARSA (State-Action-Reward-State-Action).  </li> </ul> <p>\u2705 Example: - Learning to ride a bike by trial and error\u2014adjusting balance while practicing.  </p>"},{"location":"RL_Unit1/#off-policy-learning","title":"Off-Policy Learning","text":"<ul> <li>The agent learns from data generated by other policies (not just its own).  </li> <li>More flexible as it allows learning from past experiences.  </li> <li>Used in algorithms like Q-learning, where the agent updates its policy using the best-known actions.  </li> </ul> <p>\u2705 Example: - Learning to ride a bike by watching others rather than directly practicing.  </p>"},{"location":"RL_Unit1/#unit-2","title":"Unit 2","text":""},{"location":"RL_Unit1/#the-one-armed-and-multi-armed-bandit-problems","title":"The One-Armed and Multi-Armed Bandit Problems","text":"<p>The One-Armed Bandit Problem and its extension, the k-Armed (Multi-Armed) Bandit Problem, are fundamental concepts in reinforcement learning and decision-making under uncertainty.  </p>"},{"location":"RL_Unit1/#one-armed-bandit-problem","title":"\ud83c\udfb0 One-Armed Bandit Problem","text":"<p>\u2705 Definition: - Refers to a slot machine with a single lever (arm). - Each spin has a certain probability of winning, but this probability is unknown. - The outcome is uncertain, and a player must decide whether to keep playing or stop.  </p> <p>\u2705 Key Challenge: - The probability distribution of rewards is unknown and cannot be determined with a limited number of trials.  </p> <p>\u2705 Real-World Analogy: - A gambler playing one slot machine without knowing its payout rate.  </p>"},{"location":"RL_Unit1/#multi-armed-k-armed-bandit-problem","title":"\ud83c\udfb0 Multi-Armed (k-Armed) Bandit Problem","text":"<p>\u2705 Definition: - A gambler faces multiple slot machines (each with different and unknown payout probabilities). - The goal is to maximize total winnings by choosing which machine (arm) to play.  </p> <p>\u2705 Core Concept in Reinforcement Learning: - Balances exploration (trying different machines) vs. exploitation (sticking to the best-known machine). - Each arm has a unique probability distribution, which is stationary (remains constant over time).  </p> <p>\u2705 Mathematical Model: - An agent selects between N different actions (arms). - Each arm provides a reward drawn from an unknown probability distribution. - The goal is to maximize cumulative reward over multiple trials.  </p>"},{"location":"RL_Unit1/#why-is-it-called-a-bandit","title":"\ud83d\udd0d Why is it Called a \"Bandit\"?","text":"<ul> <li>The term \"bandit\" refers to a thief.  </li> <li>Slot machines are called \"one-armed bandits\" because casinos configure them to ensure players eventually lose money.  </li> </ul>"},{"location":"RL_Unit1/#applications-of-the-multi-armed-bandit-problem","title":"\ud83d\udccc Applications of the Multi-Armed Bandit Problem","text":"<ul> <li>Online Advertising \u2013 Deciding which ads to display to maximize clicks.  </li> <li>Clinical Trials \u2013 Testing multiple treatments to determine the most effective one.  </li> <li>A/B Testing \u2013 Comparing website designs or marketing strategies.  </li> <li>Stock Trading \u2013 Choosing the best stocks to invest in over time.  </li> </ul> <p>The k-Armed Bandit Problem serves as a foundation for reinforcement learning algorithms, influencing decision-making strategies in uncertain environments.</p>"},{"location":"RL_Unit1/#k-armed-bandit-problem-in-reinforcement-learning","title":"k-Armed Bandit Problem in Reinforcement Learning","text":"<p>The k-Armed Bandit Problem is a fundamental challenge in reinforcement learning and decision theory, where an agent must choose between multiple actions (arms) to maximize total reward.  </p>"},{"location":"RL_Unit1/#key-concepts-in-k-armed-bandit-problem","title":"\ud83d\udccc Key Concepts in k-Armed Bandit Problem","text":"<ul> <li>Action Value (\\( q^*(a) \\)) </li> <li>The true expected reward for selecting action \\( a \\).  </li> <li>Defined as:     $$    q^*(a) = \\mathbb{E}[R_t | A_t = a]    $$</li> <li> <p>If the true values of all actions were known, the best approach would be to always select the action with the highest \\( q^*(a) \\).  </p> </li> <li> <p>Estimated Action Value (\\( Q_t(a) \\)) </p> </li> <li>The empirical mean of observed rewards from action \\( a \\).  </li> <li>Defined as:     $$  Q_t(a) = \\frac{1}{n_a} \\sum_{i=1}^{n_a} r_i   $$</li> <li>As more rewards are observed, \\( Q_t(a) \\) converges to \\( q^*(a) \\).  </li> </ul>"},{"location":"RL_Unit1/#expected-vs-estimated-value","title":"Expected vs. Estimated Value","text":"Concept Definition Formula Expected Value \\( q^*(a) \\) The longrun average reward for an action \\( q^*(a) = \\sum r \\cdot P(r,a) \\) Estimated Value \\( Q_t(a) \\) The empirical mean reward based on observed outcomes \\( Q_t(a) = \\frac{1}{n_a} \\sum_{i=1}^{n_a} r_i \\) <ul> <li>Expected Value is theoretical and based on an unknown probability distribution.  </li> <li>Estimated Value is calculated from real observations and improves over time.  </li> </ul>"},{"location":"RL_Unit1/#exploitation-vs-exploration-trade-off","title":"Exploitation vs. Exploration Trade-Off","text":"<ul> <li>Greedy Actions: </li> <li>Actions with the highest estimated value \\( Q_t(a) \\).  </li> <li> <p>Exploitation: Selecting the best-known action to maximize immediate reward.  </p> </li> <li> <p>Non-Greedy Actions: </p> </li> <li>Actions that do not have the highest estimated value.  </li> <li>Exploration: Trying different actions to improve estimates and potentially discover better rewards.  </li> </ul> <p>\ud83d\udd39 Key Dilemma: - Exploiting greedy actions maximizes short-term rewards. - Exploring new actions may lead to better long-term gains.  </p>"},{"location":"RL_Unit1/#optimistic-initial-values-in-reinforcement-learning","title":"Optimistic Initial Values in Reinforcement Learning","text":"<p>Optimistic initial values are a simple yet effective technique used to encourage exploration in reinforcement learning, particularly in multi-armed bandit problems and value-based learning methods.  </p>"},{"location":"RL_Unit1/#how-does-it-work","title":"\ud83d\udccc How Does It Work?","text":"<p>Instead of initializing action values to zero or a neutral estimate, we set them to a highly optimistic value.  </p> <p>For example, in a 10-armed bandit problem where the true action values (\\( q^*(a) \\)) are drawn from a normal distribution (mean = 0, variance = 1): - Instead of initializing all \\( Q_1(a) = 0 \\), we set them to +5 (a high optimistic value).  </p>"},{"location":"RL_Unit1/#why-does-optimistic-initialization-encourage-exploration","title":"\ud83d\udd0d Why Does Optimistic Initialization Encourage Exploration?","text":"<ol> <li>Initial Overestimation:  </li> <li> <p>Since the true rewards are lower than +5, the agent will be disappointed by its first few actions.  </p> </li> <li> <p>Forces the Agent to Try Other Actions:  </p> </li> <li> <p>As the agent realizes that the initial choices don\u2019t meet expectations, it explores alternative actions.  </p> </li> <li> <p>More Thorough Exploration in Early Steps:  </p> </li> <li> <p>The agent tries multiple actions before settling on the best one.  </p> </li> <li> <p>Converges to Optimal Action Over Time:  </p> </li> <li>Eventually, the estimates stabilize as the agent gathers more data.  </li> </ol>"},{"location":"RL_Unit1/#comparison-optimistic-vs-greedy-exploration","title":"\ud83d\udcc8 Comparison: Optimistic vs. \u03b5-Greedy Exploration","text":"Exploration Method How It Works Pros Cons Optimistic Initial Values Set initial action values high Encourages early exploration, works well in stationary environments May not adapt well in non-stationary environments \u03b5-Greedy Selects a random action with probability \u03b5 Works well in both stationary and non-stationary settings Requires tuning of \u03b5, exploration is uniform"},{"location":"RL_Unit1/#upper-confidence-bound-ucb-in-reinforcement-learning","title":"Upper Confidence Bound (UCB) in Reinforcement Learning","text":""},{"location":"RL_Unit1/#why-is-exploration-needed","title":"Why is Exploration Needed?","text":"<ul> <li>Action-value estimates always contain uncertainty.  </li> <li>Greedy actions (highest estimated value) may not be truly optimal.  </li> <li>\u03b5-Greedy exploration forces random selection but does not prioritize actions with high uncertainty.  </li> </ul>"},{"location":"RL_Unit1/#upper-confidence-bound-ucb-approach","title":"Upper Confidence Bound (UCB) Approach","text":"<p>Instead of exploring randomly, UCB selects actions by balancing: 1. Current estimate of reward (exploitation). 2. Uncertainty of the estimate (exploration).  </p>"},{"location":"RL_Unit1/#ucb-formula","title":"\ud83d\udccc UCB Formula","text":"<p>For an action \\( a \\), UCB selects the action that maximizes: [ Q_t(a) + c \\sqrt{\\frac{\\log t}{N_t(a)}} ] where: - \\( Q_t(a) \\) = Estimated value of action \\( a \\). - \\( t \\) = Total number of time steps. - \\( N_t(a) \\) = Number of times action \\( a \\) has been selected. - \\( c \\) = Exploration parameter (higher \\( c \\) encourages more exploration).  </p>"},{"location":"RL_Unit1/#how-ucb-works","title":"How UCB Works?","text":"<ul> <li>The square-root term measures the uncertainty in the estimate of \\( Q_t(a) \\).  </li> <li>Actions that have been chosen fewer times (\\( N_t(a) \\) is low) will have higher uncertainty, making them more likely to be selected.  </li> <li>As an action is selected more often, \\( N_t(a) \\) increases, reducing the exploration term.  </li> </ul>"},{"location":"RL_Unit1/#key-properties-of-ucb","title":"Key Properties of UCB","text":"<p>\u2705 Encourages exploration of uncertain actions \u2013 Prefers actions that haven't been tried enough. \u2705 Gradually reduces exploration \u2013 As all actions are explored, the agent shifts towards exploitation. \u2705 Logarithmic growth \u2013 Ensures that exploration is bounded over time but never stops completely.  </p>"},{"location":"RL_Unit1/#comparison-ucb-vs-greedy","title":"Comparison: UCB vs. \u03b5-Greedy","text":"Method Exploration Type Strengths Weaknesses \u03b5-Greedy Random exploration Simple, works well in practice Does not focus on uncertain actions UCB Uncertainty-based exploration Smart exploration, prioritizes less tried actions More complex, requires tuning \\( c \\)"},{"location":"RL_Unit1/#markov-decision-process-mdp-in-reinforcement-learning","title":"Markov Decision Process (MDP) in Reinforcement Learning","text":""},{"location":"RL_Unit1/#what-is-a-markov-decision-process-mdp","title":"\ud83d\udccc What is a Markov Decision Process (MDP)?","text":"<p>A Markov Decision Process (MDP) is a mathematical framework used to model decision-making problems where outcomes are partially random and partially controlled by an agent.  </p> <p>It extends a Markov Chain by incorporating actions and rewards, allowing an agent to interact with an environment sequentially to maximize long-term rewards.  </p>"},{"location":"RL_Unit1/#what-is-a-markov-chain","title":"\ud83d\udccc What is a Markov Chain?","text":"<p>A Markov Chain is a stochastic process that follows the Markov Property:  </p> <p>The probability of transitioning to the next state only depends on the current state and not on past states.  </p> <p>Mathematically, [ P(S_{t+1} | S_t, S_{t-1}, ..., S_0) = P(S_{t+1} | S_t) ]  </p> <p>\u2705 Key Feature: Memoryless property (Future states depend only on the present state, not history).  </p>"},{"location":"RL_Unit1/#what-is-a-transition-in-mdp","title":"\ud83d\udccc What is a Transition in MDP?","text":"<p>A transition defines the probability of moving from one state to another when taking a specific action.  </p> <p>Denoted as \\( P(s' | s, a) \\): - \\( s \\) = Current state - \\( a \\) = Action taken - \\( s' \\) = Next state - \\( P(s' | s, a) \\) = Probability of transitioning to \\( s' \\) after taking action \\( a \\) in state \\( s \\).  </p> <p>\u2705 Example: - If a robot is in a room and moves right, there is an 80% chance it reaches the next room, but a 20% chance it remains in the same room (if the door is stuck).  </p>"},{"location":"RL_Unit1/#how-is-mdp-used-in-reinforcement-learning-rl","title":"\ud83d\udccc How is MDP Used in Reinforcement Learning (RL)?","text":"<p>In Reinforcement Learning, MDP helps formulate the environment as a mathematical model, guiding the agent to learn optimal policies.  </p> <ul> <li>Agent interacts with an environment following MDP dynamics.  </li> <li>State transitions occur based on agent actions.  </li> <li>The goal is to learn a policy that maximizes cumulative rewards over time.  </li> </ul>"},{"location":"RL_Unit1/#components-of-an-mdp","title":"\ud83d\udccc Components of an MDP","text":"<p>An MDP is defined by the tuple \\( (S, A, P, R, \\gamma) \\):  </p> Component Definition \\( S \\) (State Space) Set of all possible states the agent can be in. \\( A \\) (Action Space) Set of actions the agent can take. **( P(s' s, a) ) (Transition Probability)** \\( R(s, a) \\) (Reward Function) Reward received after taking action \\( a \\) in state \\( s \\). \\( \\gamma \\) (Discount Factor) Determines the importance of future rewards (\\( 0 \\leq \\gamma \\leq 1 \\)). <p>\u2705 Example in RL: - Self-driving car:   - \\( S \\): Location of the car, speed, traffic signals.   - \\( A \\): Accelerate, brake, turn left, turn right.   - \\( P(s' | s, a) \\): Probability of reaching the next position based on current speed and action.   - \\( R(s, a) \\): Reward for avoiding obstacles and staying on track.   - \\( \\gamma \\): Balances short-term (safety) vs. long-term (reaching destination quickly).  </p>"},{"location":"RL_Unit1/#summary","title":"\ud83d\udccc Summary","text":"<ul> <li>Markov Chain models state transitions without actions or rewards.  </li> <li>MDP extends Markov Chains by adding actions and rewards, allowing decision-making.  </li> <li>MDP is the foundation of RL, providing a structured way for agents to learn optimal policies.  </li> </ul>"},{"location":"computer-vision-unit%201/","title":"Computer vision unit 1","text":"Unit 1 Unit 2 Unit 3 Unit 4"},{"location":"computer-vision-unit%201/#introduction-to-computer-vision","title":"Introduction to Computer Vision","text":""},{"location":"computer-vision-unit%201/#unit-1","title":"Unit 1","text":""},{"location":"computer-vision-unit%201/#introduction","title":"Introduction","text":"<ul> <li>Image Processing: Image in \u2192 Image out.</li> <li>Computer Vision: Image/Video in \u2192 Interpretation out.</li> <li>Objective: Enable computers to see and interpret objects like humans.</li> </ul>"},{"location":"computer-vision-unit%201/#human-vs-computer-vision","title":"Human vs. Computer Vision","text":"<ul> <li>Humans: Quick recognition, intelligent decision-making.</li> <li>Computers: Require complex processing, pattern recognition, and AI.</li> </ul>"},{"location":"computer-vision-unit%201/#features-of-human-vision","title":"Features of Human Vision","text":"<ul> <li>Stereo Vision: Two eyes perceive depth using different distances.</li> <li>Texture &amp; Color: Identifies objects based on patterns and colors.</li> <li>Object Recognition: Recognizes objects despite illumination, viewpoint, or expression changes.</li> <li>Context Awareness: Infers key information from a scene.</li> </ul>"},{"location":"computer-vision-unit%201/#limitations-of-human-vision","title":"Limitations of Human Vision","text":"<ul> <li>Memory Constraints: Limited ability to recall vast image data.</li> <li>Restricted Spectrum: Limited to visible light.</li> <li>Optical Illusions: Misinterpretations of size, shape, and perspective.</li> </ul>"},{"location":"computer-vision-unit%201/#computer-vision-vs-image-processing","title":"Computer Vision vs. Image Processing","text":"<ul> <li>Image Processing: Low-level operations (compression, restoration, enhancement).</li> <li>Computer Vision: High-level understanding (object recognition, scene interpretation).</li> </ul>"},{"location":"computer-vision-unit%201/#applications-of-computer-vision","title":"Applications of Computer Vision","text":"<ul> <li>Self-driving Cars: Navigation and obstacle detection.</li> <li>Facial Recognition: Identity verification.</li> <li>Augmented Reality: Merging virtual objects with reality.</li> <li>Medical Imaging: Detecting anomalies in X-rays and MRIs.</li> <li>Manufacturing: Detecting defective products.</li> <li>Retail &amp; Banking: OCR, fraud detection, and identity verification.</li> </ul>"},{"location":"computer-vision-unit%201/#computer-vision-processing-levels","title":"Computer Vision Processing Levels","text":""},{"location":"computer-vision-unit%201/#low-level-processing","title":"Low-Level Processing","text":"<ul> <li>Enhances image quality and extracts basic features like edges, corners, textures.</li> <li>Works on raw pixel data without understanding objects.</li> <li>Steps for low level processing:</li> <li>Image Preprocessing: Contrast enhancement, noise reduction.</li> <li>Feature Extraction: Edge detection (Canny, Sobel filters).</li> <li>Segmentation: Divides an image into meaningful parts.</li> <li>Super-Resolution: Converts low-resolution to high-resolution images.</li> </ul> <p>Important</p> <p>Low-level processing extracts fundamental features such as edges, lines, corners, and salient points from an image. These features serve as the building blocks for higher-level processing, enabling pattern recognition, object detection, and scene understanding.</p> <p>How Low-Level Processing Helps: - \u2705 Feature Extraction: Identifies edges, textures, and key points in an image. - \u2705 Segmentation: Divides images into meaningful regions and shapes. - \u2705 Noise Reduction: Enhances image clarity by removing unwanted distortions. - \u2705 Super-Resolution: Generates higher-resolution images from fewer pixels. - \u2705 Depth Perception: Uses stereo vision (left &amp; right cameras) to create disparity maps for estimating depth.</p>"},{"location":"computer-vision-unit%201/#mid-level-processing","title":"Mid-Level Processing","text":"<ul> <li>Uses patterns and object features for recognition.</li> <li>Works on segmented objects to classify, track, and detect motion.</li> <li>Examples:</li> <li>Object Detection: Recognizes and labels objects.</li> <li>Image Classification: Assigns categories to images.</li> <li>Image Matching &amp; Stitching: Used in panoramas.</li> <li>Object Tracking: Predicts movement using optical flow.</li> <li>Clustering (K-Means): Segments objects into groups.</li> </ul>"},{"location":"computer-vision-unit%201/#high-level-processing","title":"High-Level Processing","text":"<ul> <li>Involves complex scene understanding and AI-based interpretations.</li> <li>Integrates low-level features for semantic meaning.</li> <li>Examples:</li> <li>Semantic Segmentation: Classifies pixels into categories (e.g., road, car, tree).</li> <li>Instance Segmentation: Differentiates between multiple objects of the same type.</li> <li>Panoptic Segmentation: Combines semantic + instance segmentation.</li> <li>Deep Learning for Segmentation: Uses CNNs &amp; RNNs for precise object recognition.</li> <li>Theme Understanding: Identifies scene context (e.g., marketplace vs. garden).</li> <li>Visual Question Answering (VQA): AI interprets images + text-based queries.</li> </ul>"},{"location":"computer-vision-unit%201/#applications-of-computer-vision_1","title":"Applications of Computer Vision","text":"<ul> <li>Self-Driving Cars: Detects lanes, pedestrians, and traffic signs.</li> <li>Facial Recognition: Matches faces for identity verification.</li> <li>Medical Imaging: Detects diseases in X-rays &amp; MRIs.</li> <li>Manufacturing: Identifies defective products.</li> <li>Retail &amp; Banking: Uses OCR, fraud detection, and customer authentication.</li> </ul>"},{"location":"computer-vision-unit%201/#deep-learning-for-image-segmentation","title":"Deep Learning for Image Segmentation","text":"<p>\ud83d\udd39 Convolutional Neural Networks (CNNs) play a crucial role in image segmentation, enabling computers to understand objects at a pixel level.</p> <p>How Deep Learning Works for Image Segmentation: - 1\ufe0f\u20e3 Feature Extraction with CNNs: CNNs process images and detect key features for segmentation. - 2\ufe0f\u20e3 Object Localization with Region Proposal Network (RPN): Identifies potential object locations and generates bounding boxes. - 3\ufe0f\u20e3 Refining Features from the Region of Interest (ROI): CNN extracts features within the bounding box. - 4\ufe0f\u20e3 Instance Segmentation using Fully Convolutional Networks (FCN): The extracted features are passed into an FCN, which learns to segment the object from its surroundings. - 5\ufe0f\u20e3 Binary Mask Output: The FCN produces a binary mask, highlighting which pixels belong to the object and which do not.</p> <p>\ud83d\ude80 From raw images to object masks, deep learning models enhance precision in image segmentation by combining feature extraction, region detection, and pixel-level classification! \ud83d\ude80</p>"},{"location":"computer-vision-unit%201/#difference-between-low-level-and-high-level-features","title":"Difference Between Low-Level and High-Level Features","text":"Feature Type Low-Level Features \ud83d\uddbc\ufe0f High-Level Features \ud83e\udde0 Content Deals with raw pixel data, detecting edges, textures, and simple patterns. Focuses on object understanding, classification, and relationships. Sensitivity More sensitive to noise, lighting, and orientation changes. More robust, can interpret complex scenes despite variations. Scale Extracted from local regions (e.g., edges in a small part of the image). Global features\u2014considers the entire image for context. Resources Requires fewer system resources, as it focuses on simple features. Uses advanced AI models, requiring higher computation power. Use Cases Applied in image segmentation, feature matching, and object detection. Used in image classification, object recognition, and scene understanding. <p>\ud83d\udd0d Low-level features lay the foundation by detecting shapes and patterns, while high-level features bring context and meaning to an image. Together, they power modern computer vision applications! \ud83d\ude80</p>"},{"location":"computer-vision-unit%201/#edge-detection","title":"Edge Detection","text":""},{"location":"computer-vision-unit%201/#sharpening-spatial-filters","title":"Sharpening Spatial Filters","text":"<p>\ud83d\uddbc\ufe0f Purpose: - Removes blurring and enhances edges in images. - Highlights intensity transitions using spatial differentiation. - Image gradients measure the rate of change in pixel intensity, crucial for detecting edges.</p>"},{"location":"computer-vision-unit%201/#image-gradients","title":"Image Gradients","text":"<p>\ud83d\udccc Fundamental for computer vision &amp; image processing \ud83d\udd39 Used for: \u2705 Edge detection \u2705 Finding object contours \u2705 Outlining shapes</p> <p>\ud83d\udd39 Computes: - Gradient Magnitude (Strength of the edge) - Gradient Orientation (Direction of the edge)</p> <p>\u2728 Popular techniques built on image gradients: - Histogram of Oriented Gradients (HOG) - Scale-Invariant Feature Transform (SIFT)</p>"},{"location":"computer-vision-unit%201/#edge-detection-using-image-gradients","title":"Edge Detection Using Image Gradients","text":"<p>\ud83d\udca1 Gradient computation is a key pre-processing step for edge detection.</p>"},{"location":"computer-vision-unit%201/#computing-image-gradients","title":"Computing Image Gradients","text":"<p>The gradient of an image is calculated using finite differences: - Gradient along the vertical direction (\\(G_y\\)):   $$ G_y = f(r+1, c) - f(r-1, c) $$ - Gradient along the horizontal direction (\\(G_x\\)):   $$ G_x = f(r, c+1) - f(r, c-1) $$</p> <p>\ud83d\udccc Gradient masks (filters) for edge detection:</p> Filter Mask Vertical (\\(G_y\\)) Sobel Filter \\(\\begin{bmatrix} -1 &amp; 0 &amp; 1 \\end{bmatrix}\\) Horizontal (\\(G_x\\)) Sobel Filter \\(\\begin{bmatrix} -1 \\\\ 0 \\\\ 1 \\end{bmatrix}\\)"},{"location":"computer-vision-unit%201/#image-gradient-gradient-vector","title":"Image Gradient &amp; Gradient Vector","text":"<p>\ud83d\uddbc\ufe0f Purpose: - Computes rate of change in pixel intensity. - Gradient Magnitude (\\(M\\)) measures the strength of intensity change. - Gradient Orientation (\\(\\alpha\\)) determines direction of the edge. - The matrix size for magnitude and angle is the same as the original image.</p> <p>\ud83d\udd39 Mathematical Representation: - Gradient Angle (\\(\\alpha\\)):   $$ \\alpha = \\tan^{-1} \\left(\\frac{g_y}{g_x} \\right) $$ - Gradient Magnitude (\\(M\\)):   $$ M = \\sqrt{g_x^2 + g_y^2} $$</p> <p>\ud83d\udccc Where: - \\(g_x\\) = Gradient in the horizontal direction. - \\(g_y\\) = Gradient in the vertical direction. - \\(\\alpha\\) = Angle between the vertical axis and the edge direction.</p>"},{"location":"computer-vision-unit%201/#sobel-filter-for-edge-detection","title":"Sobel Filter for Edge Detection","text":"<p>\ud83d\udca1 Sobel filters compute image gradients using convolution masks.</p>"},{"location":"computer-vision-unit%201/#gradient-computation-with-sobel-operator","title":"Gradient Computation with Sobel Operator","text":"<p>\ud83d\udd39 Sobel Operator for Horizontal (\\(G_x\\)) and Vertical (\\(G_y\\)) Gradients:</p> Gradient Direction Filter Mask (Kernel) \\(G_x\\) (Horizontal Gradient) \\(\\begin{bmatrix} -1 &amp; 0 &amp; 1 \\\\ -2 &amp; 0 &amp; 2 \\\\ -1 &amp; 0 &amp; 1 \\end{bmatrix}\\) \\(G_y\\) (Vertical Gradient) \\(\\begin{bmatrix} -1 &amp; -2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix}\\) <p>\ud83d\udd39 Steps to Compute Edge Strength: 1\ufe0f\u20e3 Convolve the image with \\(G_x\\) to compute horizontal changes. 2\ufe0f\u20e3 Convolve the image with \\(G_y\\) to compute vertical changes. 3\ufe0f\u20e3 Compute gradient magnitude and angle using:    $$ M = \\sqrt{G_x^2 + G_y^2} $$    $$ \\alpha = \\tan^{-1} \\left(\\frac{G_y}{G_x} \\right) $$</p> <p>\ud83d\udccc Why Sobel Filters? \u2705 Enhances edges by detecting gradients in both directions. \u2705 Smooths noise while emphasizing high-frequency intensity changes. \u2705 Used in edge detection algorithms like Canny Edge Detector.</p>"},{"location":"computer-vision-unit%201/#gaussian-filter-for-image-smoothing","title":"Gaussian Filter for Image Smoothing","text":"<p>\ud83d\udd39 The Gaussian filter is a smoothing filter that reduces noise and detail in an image. \ud83d\udd39 It applies a Gaussian function to weight pixels, giving higher importance to the center pixel and gradually reducing weights outward.</p>"},{"location":"computer-vision-unit%201/#mathematical-representation","title":"Mathematical Representation","text":"<p>The Gaussian function for a 2D image is: $$ G_\\sigma(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}} $$ where: - \\( \\sigma \\) = Standard deviation (controls blurring strength) - \\( x, y \\) = Pixel coordinates</p> <p>\ud83d\udccc Higher \\( \\sigma \\) \u2192 More blur \ud83d\udccc Lower \\( \\sigma \\) \u2192 Less blur, preserves more details</p>"},{"location":"computer-vision-unit%201/#gaussian-filter-kernels","title":"Gaussian Filter Kernels","text":"Filter Size Kernel Matrix (Normalized) 3\u00d73 (\u03c3 = 1) \\( \\frac{1}{16} \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 2 &amp; 4 &amp; 2 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix} \\) 5\u00d75 (\u03c3 = 1) \\( \\frac{1}{330} \\begin{bmatrix} 1 &amp; 4 &amp; 7 &amp; 4 &amp; 1 \\\\ 4 &amp; 20 &amp; 33 &amp; 20 &amp; 4 \\\\ 7 &amp; 33 &amp; 54 &amp; 33 &amp; 7 \\\\ 4 &amp; 20 &amp; 33 &amp; 20 &amp; 4 \\\\ 1 &amp; 4 &amp; 7 &amp; 4 &amp; 1 \\end{bmatrix} \\) 5\u00d75 (\u03c3 = 2) \\( \\frac{1}{34} \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 \\\\ 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 \\\\ 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix} \\) <p>\ud83d\udccc Larger filter size \u2192 More blur &amp; smoothing \ud83d\udccc Smaller filter size \u2192 Preserves more details</p>"},{"location":"computer-vision-unit%201/#laplacian-filter-for-edge-detection","title":"Laplacian Filter for Edge Detection","text":"<p>\ud83d\udd39 The Laplacian filter is a second-order derivative filter used for edge detection. \ud83d\udd39 It highlights regions of rapid intensity change by computing the second derivative of an image.</p>"},{"location":"computer-vision-unit%201/#mathematical-representation_1","title":"Mathematical Representation","text":"<p>The Laplacian operator is given by:</p> \\[ \\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}\\] <p>where \\( f(x, y) \\) is the image intensity at a given point.</p>"},{"location":"computer-vision-unit%201/#laplacian-filter-kernels","title":"Laplacian Filter Kernels","text":"Filter Type Kernel Matrix 4-Neighbor Laplacian \\( \\begin{bmatrix} 0 &amp; -1 &amp; 0 \\\\ -1 &amp; 4 &amp; -1 \\\\ 0 &amp; -1 &amp; 0 \\end{bmatrix} \\) 8-Neighbor Laplacian \\( \\begin{bmatrix} -1 &amp; -1 &amp; -1 \\\\ -1 &amp; 8 &amp; -1 \\\\ -1 &amp; -1 &amp; -1 \\end{bmatrix} \\) <p>\ud83d\udd39 The 4-neighbor Laplacian considers only direct neighbors, while the 8-neighbor Laplacian accounts for diagonal edges as well.</p>"},{"location":"computer-vision-unit%202/","title":"Computer vision unit 2","text":"Unit 1 Unit 2 Unit 3 Unit 4"},{"location":"computer-vision-unit%202/#feature-extraction","title":"Feature Extraction","text":""},{"location":"computer-vision-unit%202/#unit-2","title":"Unit 2","text":""},{"location":"computer-vision-unit%202/#image-features-in-computer-vision","title":"Image Features in Computer Vision","text":"<p>\ud83d\udd39 Image features are key elements that help in object recognition, segmentation, and analysis.</p>"},{"location":"computer-vision-unit%202/#types-of-image-features","title":"Types of Image Features","text":"<p>\u2705 Edges \u2013 Identifies boundaries between objects. \u2705 Color \u2013 Extracts information based on pixel intensity. \u2705 Texture \u2013 Analyzes surface patterns and structures. \u2705 Object Boundaries \u2013 Detects outlines and contours of objects. \u2705 Object Shape \u2013 Defines geometric properties of an object.</p> <p>\ud83d\udd39 Good Features Should Be: - \u2705 Unique &amp; Distinctive \u2013 Helps differentiate between objects. - \u2705 Non-redundant \u2013 Avoids duplicate or unnecessary information. - \u2705 Robust \u2013 Works well under noise and illumination changes. - \u2705 Global Representation \u2013 Captures scene-wide characteristics, not just local details.</p>"},{"location":"computer-vision-unit%202/#gradient-based-features","title":"Gradient-Based Features","text":"<p>Gradient-based techniques detect changes in pixel intensity, which highlight object edges and textures.</p> <p>\ud83d\udd39 Popular Techniques: - DoG (Difference of Gaussian) - LoG (Laplacian of Gaussian) - HoG (Histogram of Oriented Gradients) - SIFT (Scale-Invariant Feature Transform) - SURF (Speeded-Up Robust Features)</p> <p>\ud83d\udccc Advantages: \u2705 Invariant to small shifts &amp; rotations \u2013 Ensures stability under transformations. \u2705 Localized histograms \u2013 Offers better spatial information compared to global histograms. \u2705 Contrast normalization \u2013 Reduces the impact of variable illumination.</p>"},{"location":"computer-vision-unit%202/#difference-of-gaussian-dog","title":"Difference of Gaussian (DoG)","text":"<p>\ud83d\udccc A feature enhancement technique used for blob detection &amp; SIFT descriptors.</p>"},{"location":"computer-vision-unit%202/#how-dog-works","title":"How DoG Works:","text":"<p>1\ufe0f\u20e3 Apply Gaussian Blur \u2013 Smoothens the image using two Gaussian filters with different sigma values (\u03c3\u2081 &amp; \u03c3\u2082). 2\ufe0f\u20e3 Subtract the Two Blurred Images \u2013 Enhances regions with specific frequency details. 3\ufe0f\u20e3 Suppress High-Frequency Details \u2013 Reduces random noise but preserves important structures.</p> <p>\ud83d\udd39 Mathematical Representation: $$ DoG = G_{\\sigma_1} * I - G_{\\sigma_2} * I $$</p> <p>where: - \\( I \\) = Original grayscale image - \\( G_{\\sigma_1}, G_{\\sigma_2} \\) = Gaussian filters with different standard deviations</p> <p>\ud83d\udccc Pros &amp; Cons: \u2705 Reduces noise while preserving edges \u2705 Enhances spatial features \u274c Reduces overall image contrast</p>"},{"location":"computer-vision-unit%202/#laplacian-of-gaussian-log-edge-detection-feature-enhancement","title":"Laplacian of Gaussian (LoG) \u2013 Edge Detection &amp; Feature Enhancement","text":"<p>\ud83d\udd39 Laplacian of Gaussian (LoG) is a feature detection technique that combines: 1\ufe0f\u20e3 Gaussian Smoothing \u2013 Reduces noise in the image. 2\ufe0f\u20e3 Laplacian Operator \u2013 Detects edges and blobs by identifying intensity changes.</p>"},{"location":"computer-vision-unit%202/#how-log-works","title":"How LoG Works:","text":"<ol> <li>Apply a Gaussian filter to smooth the image and suppress noise.</li> <li>Compute the second derivative (Laplacian) to highlight regions with rapid intensity changes (edges).</li> <li>Detect zero-crossings in the Laplacian response to identify edges.</li> </ol>"},{"location":"computer-vision-unit%202/#mathematical-representation","title":"Mathematical Representation:","text":"<p>The LoG function is given by: $$ LoG(x, y) = \\nabla^2 G_{\\sigma} (x, y) * I(x, y) $$ where: - \\( G_{\\sigma} (x, y) \\) = Gaussian filter with standard deviation \\( \\sigma \\) - \\( \\nabla^2 \\) = Laplacian operator (second derivative) - \\( I(x, y) \\) = Input image</p>"},{"location":"computer-vision-unit%202/#key-features-of-log","title":"Key Features of LoG:","text":"<p>\u2705 Combines smoothing &amp; edge detection in one step. \u2705 Detects both fine and coarse details depending on \\( \\sigma \\). \u2705 Useful for blob detection in feature descriptors like SIFT. \u274c Sensitive to noise \u2013 Requires pre-smoothing for better results.</p> <p>\ud83d\ude80 LoG is commonly used in edge detection pipelines like the Marr-Hildreth operator and as a preprocessing step in Computer Vision applications! \ud83d\udd0d</p>"},{"location":"computer-vision-unit%202/#histogram-of-oriented-gradients-hog-feature-descriptor-for-object-detection","title":"Histogram of Oriented Gradients (HoG) \u2013 Feature Descriptor for Object Detection","text":"<p>\ud83d\udd39 Histogram of Oriented Gradients (HoG) is a feature descriptor used for object detection and image classification by analyzing gradient orientations in localized regions of an image.</p>"},{"location":"computer-vision-unit%202/#step-by-step-hog-computation","title":"Step-by-Step HoG Computation","text":"<p>\u2705 Step 1: Resize Image - Resize the image to an integer multiple of 8 (nearest to the original size). - Ensures uniform cell division and efficient computation.</p> <p>\u2705 Step 2: Divide Image into Cells - Split the image into small patches of equal size (e.g., 8\u00d78 pixels per cell). - Each cell will have its own gradient histogram.</p> <p>\u2705 Step 3: Compute Gradients - Calculate the gradient magnitude and orientation using Sobel filters:   [   M = \\sqrt{G_x^2 + G_y^2}, \\quad \\theta = \\tan^{-1} \\left(\\frac{G_y}{G_x} \\right)   ]   where \\( G_x, G_y \\) are gradients along horizontal and vertical directions.</p> <p>\u2705 Step 4: Compute Gradient Histograms (Per Cell) - For each 8\u00d78 cell, create a histogram of gradients (e.g., 9 bins for 0\u00b0-180\u00b0). - Assign gradient magnitudes to their corresponding orientation bins.</p> <p>\u2705 Step 5: Construct Feature Vector - Normalize the histograms across neighboring blocks (e.g., 2\u00d72 cells per block) for better illumination invariance. - Flatten the computed HoG features into a single feature vector for classification.</p> <p>\u2705 Step 6: Visualize HoG - HoG features are often visualized as a grid of arrows, where the length and direction represent gradient strength and orientation.</p> <p>\u2705 Step 7: Classify Images - Use machine learning models (SVM, Deep Learning) to classify objects using the extracted HoG feature vector.</p>"},{"location":"computer-vision-unit%202/#mathematical-representation_1","title":"Mathematical Representation:","text":"<ul> <li> <p>Gradient Magnitude (\\(M\\)): $$   M = \\sqrt{G_x^2 + G_y^2} $$</p> </li> <li> <p>Gradient Orientation (\\(\\theta\\)): $$   \\theta = \\tan^{-1} \\left(\\frac{G_y}{G_x} \\right) $$ where:</p> </li> <li>\\( G_x, G_y \\) = Gradients in horizontal &amp; vertical directions.</li> <li>\\( M \\) = Strength of edge response.</li> <li>\\( \\theta \\) = Edge direction (0\u00b0\u2013180\u00b0 or 0\u00b0\u2013360\u00b0 bins).</li> </ul>"},{"location":"computer-vision-unit%202/#key-features-of-hog","title":"Key Features of HoG:","text":"<p>\u2705 Invariance to Illumination &amp; Shadows \u2013 Normalization removes intensity variations. \u2705 Captures Local Shape Information \u2013 Focuses on edges and textures rather than pixel intensity. \u2705 Robust to Small Translations &amp; Rotations \u2013 Uses histograms instead of raw gradients. \u2705 Widely Used in Object Detection \u2013 Forms the basis of Dalal-Triggs pedestrian detection and is used in SVM-based image recognition. \u274c Computationally Expensive \u2013 Requires dense gradient computations across the entire image.</p> <p>\ud83d\ude80 HoG is widely used in Human &amp; Object Detection (e.g., Pedestrian Detection in self-driving cars) and Machine Learning-based Image Classification! \ud83d\udd0d</p>"},{"location":"computer-vision-unit%202/#feature-descriptors-in-computer-vision","title":"Feature Descriptors in Computer Vision","text":"<p>\ud83d\udd39 Feature descriptors help identify key points, edges, and corners in an image. \ud83d\udd39 These descriptors are used for object detection, image matching, and recognition.</p>"},{"location":"computer-vision-unit%202/#types-of-feature-descriptors","title":"Types of Feature Descriptors","text":""},{"location":"computer-vision-unit%202/#1-global-descriptors","title":"1. Global Descriptors \ud83c\udf0d","text":"<ul> <li>Represent the entire image.</li> <li>Examples:   \u2705 Histogram of Oriented Gradients (HoG)   \u2705 Difference of Gaussian (DoG)   \u2705 Histogram of Optical Flow (HOF)</li> <li>Limitations: Struggle with occlusions and profile variations since they analyze the whole image.</li> </ul>"},{"location":"computer-vision-unit%202/#2-local-descriptors","title":"2. Local Descriptors \ud83d\udd0d","text":"<ul> <li>Describe small patches within an image.</li> <li>More accurate &amp; robust for object detection, matching, and occlusion handling.</li> <li>Examples:   \u2705 SIFT (Scale-Invariant Feature Transform)   \u2705 SURF (Speeded-Up Robust Features)   \u2705 LBP (Local Binary Pattern)   \u2705 BRISK (Binary Robust Invariant Scalable Keypoints)   \u2705 MSER (Maximally Stable Extremal Regions)   \u2705 FREAK (Fast Retina Keypoint)</li> </ul> <p>\ud83d\udccc Local descriptors outperform global ones in real-world applications like facial recognition and object tracking! \ud83d\ude80</p>"},{"location":"computer-vision-unit%202/#how-to-define-an-interest-point","title":"How to Define an Interest Point?","text":"<p>\ud83d\udd39 Interest points are key locations (e.g., edges, corners) where features can be extracted.</p> <p>\u2705 Repeatability: - A feature should be detected consistently across multiple images, despite geometric &amp; photometric transformations.</p> <p>\u2705 Saliency: - Features should be distinct and unique to avoid mismatches.</p> <p>\u2705 Compactness: - Fewer features than the number of image pixels should effectively represent the image.</p> <p>\u2705 Efficiency: - Fast computation is essential for real-time applications like tracking &amp; detection.</p> <p>\u2705 Locality: - Features should occupy a small area and remain robust to clutter &amp; occlusion.</p> <p>\u2705 Covariance: - Features should be detectable despite geometric &amp; photometric variations (e.g., rotation, lighting changes).</p>"},{"location":"computer-vision-unit%202/#sift-algorithm-scale-invariant-feature-transform","title":"SIFT Algorithm \u2013 Scale-Invariant Feature Transform","text":"<p>SIFT is a feature detection algorithm that extracts scale and rotation-invariant keypoints for object recognition, tracking, and image matching.</p>"},{"location":"computer-vision-unit%202/#step-1-construct-a-scale-space","title":"Step 1: Construct a Scale Space","text":"<p>\ud83d\udccc Why? - Real-world objects appear different at various distances (scales). - A feature must be detectable at multiple scales to be useful in recognition.</p> <p>\ud83d\udd39 How it Works: 1. The original image is repeatedly blurred using a Gaussian filter. 2. Octaves are created by downsampling the image (reducing its size by half). 3. Within each octave, multiple blurred images are generated with increasing sigma values (\u03c3). 4. This scale-space representation ensures features are scale-independent.</p> <p>\ud83d\udd39 Mathematical Formulation (Gaussian Blur): [ G(x, y, \\sigma) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}} ] where: - \\( G(x, y, \\sigma) \\) = Gaussian function. - \\( \\sigma \\) = Standard deviation (controls blurring). - \\( x, y \\) = Pixel coordinates.</p> <p>\ud83d\udd39 Example: - Octave 1: Original image + multiple blurred versions. - Octave 2: Image resized to half and blurred again. - Repeats for multiple octaves (typically 4-5 octaves).</p> <p>\ud83d\udccc Outcome: - A collection of images at different scales and resolutions.</p>"},{"location":"computer-vision-unit%202/#step-2-compute-difference-of-gaussian-dog","title":"Step 2: Compute Difference of Gaussian (DoG)","text":"<p>\ud83d\udccc Why? - Identifies keypoints by enhancing edges and texture features. - The Gaussian Blur removes noise, and the DoG highlights changes in intensity.</p> <p>\ud83d\udd39 How it Works: 1. Compute DoG images by subtracting two consecutive Gaussian-blurred images:    [    DoG(x, y, \\sigma) = G(x, y, k\\sigma) - G(x, y, \\sigma)    ]    where \\( k \\) is a constant (typically \\( k = \\sqrt{2} \\)). 2. This process is repeated across all octaves. 3. The resulting DoG images enhance edges, blobs, and texture details.</p> <p>\ud83d\udccc Outcome: - A set of DoG images that highlight regions of interest (potential keypoints).</p>"},{"location":"computer-vision-unit%202/#step-3-keypoint-localization","title":"Step 3: Keypoint Localization","text":"<p>\ud83d\udccc Why? - Identify stable keypoints while removing weak or false detections.</p> <p>\ud83d\udd39 How it Works: 1. Each pixel in the DoG images is compared with 26 neighboring pixels (8 in the same image, 9 in the scale above, and 9 in the scale below). 2. If a pixel is the local maximum or minimum, it is marked as a potential keypoint. 3. Low-contrast keypoints are discarded using a threshold (typically 0.03). 4. Edges are removed using the Hessian matrix determinant to avoid unstable keypoints.</p> <p>\ud83d\udd39 Mathematical Filtering (Hessian Matrix): [ H = \\begin{bmatrix} I_{xx} &amp; I_{xy} \\ I_{xy} &amp; I_{yy} \\end{bmatrix} ] - Compute corner response:   [   \\frac{(\\text{Trace}(H))^2}{\\text{Det}(H)} &lt; 12.1   ]   If the value is greater than 12.1, the keypoint is rejected.</p> <p>\ud83d\udccc Outcome: - A set of highly stable, contrast-rich keypoints that can be used for further processing.</p>"},{"location":"computer-vision-unit%202/#scale-invariant-feature-transform-sift","title":"Scale-Invariant Feature Transform (SIFT)","text":"<p>SIFT is an algorithm used to detect distinct key points or features in an image. These key points are robust to changes in scale, rotation, and affine transformations, making SIFT widely used in object recognition, image stitching, and 3D reconstruction.</p>"},{"location":"computer-vision-unit%202/#advantages-of-sift-detector","title":"Advantages of SIFT Detector","text":"<p>Note</p> <p>SIFT provides a highly distinctive feature descriptor, making it useful for matching objects in large databases.</p> Advantage Description Locality Features are local and robust to occlusion. Does not require segmentation of objects. Distinctiveness Features can be matched to a large database of objects. Quantity Generates many features, even for small objects. Efficiency Close to real-time performance. Extensibility Easily extends to various feature types. <p></p> <p>The image above illustrates SIFT algorithm.</p>"},{"location":"computer-vision-unit%202/#integral-image","title":"Integral Image","text":"<p>An integral image is a technique that allows for the fast computation of the sum of pixel values over a rectangular region.</p>"},{"location":"computer-vision-unit%202/#key-properties","title":"Key Properties","text":"<ul> <li>Speeds up sum calculations for box-type filters.</li> <li>Reduces computational cost for large-scale image processing.</li> </ul>"},{"location":"computer-vision-unit%202/#mathematical-representation_2","title":"Mathematical Representation","text":"<p>For an input image \\( I(x,y) \\), the integral image \\( I_{Int}(x,y) \\) at a location \\( (x,y) \\) is computed as:</p> \\[ I_{Int}(x, y) = \\sum_{i=0}^{x} \\sum_{j=0}^{y} I(i, j) \\] <p></p>"},{"location":"computer-vision-unit%202/#use-of-integral-image","title":"Use of Integral Image","text":"<p>The sum of all pixel values in a region can be quickly computed using four values:</p> \\[ S = A - B - C + D \\] <p>where: - \\( A, B, C, \\) and \\( D \\) are elements of the integral image at the corners of the selected region.</p> <p>Note</p> <p>Even if size of filter increases, number of computations (3 additions/subtractions) does not increase</p>"},{"location":"computer-vision-unit%202/#comparison-of-sift-and-surf","title":"Comparison of SIFT and SURF","text":"Feature SIFT (Scale-Invariant Feature Transform) SURF (Speeded-Up Robust Features) Dimensionality High-dimensional feature descriptor Lower dimensional, more compact descriptor Accuracy Reduction in dimensionality decreases accuracy More efficient without significant accuracy loss Keypoint Detection Approximates Laplacian of Gaussian (LoG) using Difference of Gaussian (DoG) Approximates LoG using Box Filters Computation Uses determinant and trace of the Hessian matrix Uses only determinant of Hessian matrix Speed Computationally expensive Faster due to integral images and parallel convolution Real-Time Applications Not optimized for real-time processing Suitable for real-time tracking &amp; object recognition <p>Tip</p> <p>SURF is a faster alternative to SIFT, making it suitable for real-time applications while maintaining robustness.</p>"},{"location":"computer-vision-unit%202/#speeded-up-robust-features-surf-algorithm","title":"Speeded-Up Robust Features (SURF) Algorithm","text":""},{"location":"computer-vision-unit%202/#1-detector","title":"1. Detector","text":"<ol> <li>Construct Hessian matrix using box filters at each pixel to determine keypoints.</li> <li>Increase the size of box filters and repeat step 1.</li> <li>For each keypoint, select points within a radius of 6\u03c3 (where \u03c3 is the standard deviation of the keypoint's filter).</li> <li>Apply a Gaussian filter of 2.5\u03c3 on the keypoint.</li> <li>Use a Haar wavelet of size 4\u03c3 to determine the magnitude and direction of points.</li> <li>Draw a histogram with 6 bins to identify the orientation of the keypoint.</li> </ol>"},{"location":"computer-vision-unit%202/#2-descriptor","title":"2. Descriptor","text":"<ol> <li>Around each keypoint, select a square region of size (20\u03c3 \u00d7 20\u03c3).</li> <li>Divide the region into 16 sub-regions.</li> <li>For each sub-region, determine a vector of length 4.</li> <li>The final descriptor vector has a total length of 64.</li> </ol> <p>Tip</p> <p>SURF is significantly faster than SIFT due to its use of box filters and integral images, making it suitable for real-time applications.</p>"},{"location":"computer-vision-unit%202/#speeded-up-robust-features-surf-algorithm_1","title":"Speeded Up Robust Features (SURF) algorithm","text":""},{"location":"computer-vision-unit%202/#applications-of-feature-descriptors","title":"Applications of Feature Descriptors","text":"<p>Feature descriptors are powerful tools in computer vision for identifying and describing local features in images. They enable a wide range of applications:</p> <ol> <li>Image Matching</li> <li>Matches keypoints between different images of the same scene or object.</li> <li>Essential for applications like panorama stitching, where multiple images are combined into a wide-angle view.</li> <li>Object Recognition</li> <li>Identifies and locates objects within images by matching features between a known object and a scene.</li> <li>Widely used in robotics and automated inspection systems.</li> <li>3D Reconstruction</li> <li>Matches images taken from different viewpoints to reconstruct 3D models of objects or environments.</li> <li>Essential for applications in augmented reality (AR) and virtual reality (VR).</li> <li>Image Retrieval</li> <li>Enables content-based image retrieval by searching for and retrieving images based on visual content rather than metadata.</li> <li>Scene Recognition</li> <li>Analyzes the spatial arrangement of features to recognize and categorize scenes or environments.</li> <li>Useful in autonomous navigation and contextual AI systems.</li> <li>Robotic Vision</li> <li>Helps robots navigate, identify objects, and interact with their environment more effectively.</li> <li>Video Tracking</li> <li>Tracks objects or people in video sequences by matching keypoints frame-to-frame.</li> <li>Important for surveillance and motion analysis.</li> <li>Forgery Detection</li> <li>Used in digital forensics to detect tampered or forged images by identifying inconsistencies in local features.</li> </ol>"},{"location":"computer-vision-unit%202/#2d-gabor-filter-parameters-properties","title":"2D Gabor Filter \u2013 Parameters &amp; Properties","text":""},{"location":"computer-vision-unit%202/#overview","title":"Overview","text":"<p>The Gabor filter is a powerful tool used for feature extraction, especially in texture and edge detection. It is a bandpass filter that operates in both the spatial and frequency domains, mimicking the way the human visual system perceives textures.</p>"},{"location":"computer-vision-unit%202/#key-characteristics","title":"Key Characteristics","text":"<p>\u2705 Localized in both space &amp; frequency \u2013 Helps capture patterns effectively. \u2705 Combination of Gaussian &amp; Sinusoidal components \u2013 Provides smooth feature extraction. \u2705 Mimics human vision \u2013 Recognizes textures similar to human eyes.</p>"},{"location":"computer-vision-unit%202/#mathematical-representation_3","title":"Mathematical Representation","text":"<p>A 2D Gabor filter is defined as:</p> \\[ G(x,y) = \\exp\\left( -\\frac{x'^2 + \\gamma^2 y'^2}{2\\sigma^2} \\right) \\cos\\left( \\frac{2\\pi x'}{\\lambda} + \\psi \\right) \\] <p>where: - \\( x' = x \\cos\\theta + y \\sin\\theta \\) - \\( y' = -x \\sin\\theta + y \\cos\\theta \\)</p>"},{"location":"computer-vision-unit%202/#core-parameters-of-gabor-filter","title":"Core Parameters of Gabor Filter","text":"Parameter Symbol Description Wavelength \\( \\lambda \\) Controls the width of the stripes in the Gabor function. Orientation \\( \\theta \\) Defines the angle of the normal to the parallel stripes of the Gabor function. Phase Offset \\( \\psi \\) Determines the position of the sinusoidal function, affecting edge detection. Standard Deviation \\( \\sigma \\) Defines the spread of the Gaussian envelope, controlling the extent of localization. Aspect Ratio \\( \\gamma \\) Specifies the ellipticity of the Gabor function's support. Bandwidth \\( B \\) Controls the range of spatial frequencies covered by the filter."},{"location":"computer-vision-unit%202/#how-parameters-affect-the-gabor-filter","title":"How Parameters Affect the Gabor Filter","text":""},{"location":"computer-vision-unit%202/#1-wavelength-stripe-width","title":"1\ufe0f\u20e3 Wavelength (\u03bb) \u2013 Stripe Width","text":"<ul> <li>Controls the width of the sinusoidal pattern.</li> <li>Larger \u03bb \u2192 Wider stripes \u2192 Detects coarse textures.</li> <li>Smaller \u03bb \u2192 Narrower stripes \u2192 Detects fine textures.</li> </ul>"},{"location":"computer-vision-unit%202/#2-orientation-direction-of-features","title":"2\ufe0f\u20e3 Orientation (\u03b8) \u2013 Direction of Features","text":"<ul> <li>Determines the angle at which the filter responds best to edges.</li> <li>Example: A horizontal edge detector has \\( \\theta = 90^\\circ \\).</li> </ul>"},{"location":"computer-vision-unit%202/#3-phase-offset-sinusoidal-shift","title":"3\ufe0f\u20e3 Phase Offset (\u03c8) \u2013 Sinusoidal Shift","text":"<ul> <li>\\( \\psi = 0 \\) \u2192 Cosine Gabor (Even filter) \u2192 Detects bar-like structures.</li> <li>\\( \\psi = \\frac{\\pi}{2} \\) \u2192 Sine Gabor (Odd filter) \u2192 Detects line-like structures.</li> </ul>"},{"location":"computer-vision-unit%202/#4-standard-deviation-gaussian-spread","title":"4\ufe0f\u20e3 Standard Deviation (\u03c3) \u2013 Gaussian Spread","text":"<ul> <li>Determines the size of the receptive field.</li> <li>Large \\( \\sigma \\) \u2192 More blurred edges.</li> <li>Small \\( \\sigma \\) \u2192 More sharp edges.</li> </ul>"},{"location":"computer-vision-unit%202/#5-aspect-ratio-ellipticity","title":"5\ufe0f\u20e3 Aspect Ratio (\u03b3) \u2013 Ellipticity","text":"<ul> <li>Specifies the shape of the filter.</li> <li>Larger \\( \\gamma \\) \u2192 More elongated filter (stretches in one direction).</li> <li>Smaller \\( \\gamma \\) \u2192 More circular response.</li> </ul>"},{"location":"computer-vision-unit%202/#gray-level-co-occurrence-matrix-glcm-texture-analysis","title":"Gray Level Co-occurrence Matrix (GLCM) \u2013 Texture Analysis","text":""},{"location":"computer-vision-unit%202/#overview_1","title":"Overview","text":"<p>The Gray Level Co-occurrence Matrix (GLCM) is a powerful statistical method used in image processing and computer vision to analyze texture features by examining the spatial relationships between pixel intensities.</p> <p>\ud83d\udd39 Key Applications: \u2705 Texture Analysis \u2013 Identifies patterns in images. \u2705 Feature Extraction \u2013 Helps in classification tasks. \u2705 Medical Imaging \u2013 Detects abnormalities in scans. \u2705 Remote Sensing \u2013 Analyzes satellite imagery.</p>"},{"location":"computer-vision-unit%202/#glcm-how-it-works","title":"GLCM \u2013 How It Works","text":"<p>GLCM computes how often pairs of gray-level intensities occur at a specific spatial relationship (distance &amp; direction) within an image. This helps extract meaningful texture features.</p>"},{"location":"computer-vision-unit%202/#statistical-features-derived-from-glcm","title":"Statistical Features Derived from GLCM","text":"Feature Formula Description Contrast \\( \\sum_{i,j} (i - j)^2 p(i, j) \\) Measures intensity variation (higher contrast = more difference in pixel values). Dissimilarity ( \\sum_{i,j} i - j Energy \\( \\sum_{i,j} p(i, j)^2 \\) Sum of squared elements \u2192 Measures uniformity. Homogeneity ( \\sum_{i,j} \\frac{p(i, j)}{1 + i - j Entropy \\( \\sum_{i,j} -p(i, j) \\log_2(p(i, j)) \\) Measures randomness \u2192 Higher entropy = more complex textures. Correlation \\( \\sum_{i,j} \\frac{(i - \\mu_i)(j - \\mu_j) p(i, j)}{\\sigma_i \\sigma_j} \\) Measures linear dependency between pixel intensities."},{"location":"computer-vision-unit%202/#glcm-mean-variance","title":"GLCM Mean &amp; Variance","text":"<ul> <li> <p>GLCM Mean: Represents the average occurrence of a pixel intensity based on spatial relationships.  $$ \\mu_i = \\sum_{i,j} i p(i, j), \\quad \\mu_j = \\sum_{i,j} j p(i, j) $$</p> </li> <li> <p>GLCM Variance: Measures spread (dispersion) of pixel intensities around the mean.   $$   \\sigma_i^2 = \\sum_{i,j} p(i, j)(i - \\mu_i )^2, \\quad \\sigma_j^2 = \\sum_{i,j} p(i, j)(j - \\mu_j )^2  $$</p> </li> </ul>"},{"location":"computer-vision-unit%203/","title":"Computer vision unit 3","text":"Unit 1 Unit 2 Unit 3 Unit 4"},{"location":"computer-vision-unit%203/#image-segmentation","title":"Image Segmentation","text":""},{"location":"computer-vision-unit%203/#unit-3","title":"Unit 3","text":"<p>Image segmentation partitions an image into multiple regions based on pixel characteristics, grouping similar pixels into regions with assigned labels to identify objects and boundaries (lines, curves, etc.).</p>"},{"location":"computer-vision-unit%203/#key-points","title":"Key Points","text":"<p>Definition: Divides an image into regions where pixels share similar attributes (e.g., texture, color).</p> <p>Purpose: Locates objects and boundaries in images for applications like object detection and medical imaging.</p> <p>Algorithms:   - Divisive Clustering   - Hierarchical Clustering   - K-means Clustering   - Mean Shift Clustering   - Graph Cuts</p> <p>Categories:   - Region-Based Segmentation   - Edge Detection Based Segmentation   - Cluster-Based Segmentation   - CNN-Based Segmentation</p> <p>Applications:   - Object detection and recognition   - Medical imaging (e.g., MRI, CT scans)   - Texture segmentation   - Video tracking</p>"},{"location":"computer-vision-unit%203/#highlights","title":"Highlights","text":"<p>\ud83d\udca1 Tip: Use the Elbow Method to select the optimal number of clusters (<code>k</code>) in K-means clustering by identifying the \"knee\" in the WCSS plot.</p> <p>\u26a0\ufe0f Caution: K-means clustering is sensitive to the Random Initialization Trap, where poor centroid initialization can lead to suboptimal clustering.</p> <p>\ud83d\udca1 Tip: In Mean Shift, adjust the bandwidth parameter carefully\u2014smaller values yield finer segmentation, while larger values produce coarser results.</p>"},{"location":"computer-vision-unit%203/#k-means-clustering","title":"K-means Clustering","text":""},{"location":"computer-vision-unit%203/#overview","title":"Overview","text":"<p>K-means is an unsupervised algorithm that groups data points based on similarity (e.g., pixel values, texture).</p>"},{"location":"computer-vision-unit%203/#process","title":"Process","text":"<ol> <li>Randomly select <code>k</code> initial clusters.</li> <li>Assign each data point to one of the <code>k</code> clusters randomly.</li> <li>Calculate the centroid (mean) of each cluster.</li> <li>Compute the distance of each point from all centroids.</li> <li>Reassign points to the nearest centroid.</li> <li>Recalculate centroids for the new clusters.</li> <li>Repeat steps 4\u20136 until centroids stabilize, points stop changing clusters, or a set number of iterations is reached.</li> </ol>"},{"location":"computer-vision-unit%203/#elbow-method-for-optimal-k","title":"Elbow Method for Optimal <code>k</code>","text":"<p>To determine the best <code>k</code>, use the Within Cluster Sum of Squares (WCSS): <pre><code># Pseudo-code for calculating WCSS\ndef calculate_wcss(data, k):\n    wcss = 0\n    for each cluster in k_clusters:\n        centroid = compute_centroid(cluster)\n        for each point in cluster:\n            wcss += distance(point, centroid) ** 2\n    return wcss\n\n# Compute WCSS for different k values\nwcss_values = []\nfor k in range(1, max_k):\n    wcss_values.append(calculate_wcss(data, k))\n\n# Plot WCSS vs k to find the elbow\nplot(wcss_values)\n</code></pre></p>"},{"location":"computer-vision-unit%203/#pros","title":"Pros","text":"<ul> <li>Fast and suitable for large datasets.</li> <li>Low computational complexity.</li> </ul>"},{"location":"computer-vision-unit%203/#cons","title":"Cons","text":"<ul> <li>Requires choosing <code>k</code>.</li> <li>Sensitive to centroid initialization, rescaling, and outliers.</li> <li>Works best with spherical clusters, not complex shapes.</li> </ul>"},{"location":"computer-vision-unit%203/#mean-shift-algorithm","title":"Mean Shift Algorithm","text":""},{"location":"computer-vision-unit%203/#overview_1","title":"Overview","text":"<p>Mean Shift is an unsupervised clustering algorithm that identifies clusters without specifying the number of clusters beforehand. It shifts data points toward the regional mean in each iteration, grouping pixels that converge to the same mode.</p>"},{"location":"computer-vision-unit%203/#process_1","title":"Process","text":"<ol> <li>Convert Image to Feature Space:</li> <li>Use spatial (x, y) coordinates and color values (e.g., RGB, Lab) or texture features.</li> <li>Optionally use histogram backprojection for pixel distribution.</li> <li>Mean Shift Clustering:</li> <li>For each pixel, apply Mean Shift to move the kernel to the region of highest data density (mode).</li> <li>Assign Labels:</li> <li>Pixels converging to the same mode are assigned the same cluster label.</li> </ol>"},{"location":"computer-vision-unit%203/#key-concepts","title":"Key Concepts","text":"<ul> <li>Kernel Density Estimation (KDE):</li> <li>Uses a kernel window (circular or Gaussian) to calculate the mean of pixels within it.</li> <li>Updates pixel values to the new mean until convergence.</li> <li>Bandwidth Parameter:</li> <li>Controls kernel window size.</li> <li>Small bandwidth: More clusters, finer segmentation.</li> <li>Large bandwidth: Fewer clusters, coarser segmentation.</li> <li>Weighted Mean Function: <pre><code># Pseudo-code for weighted mean in Mean Shift\ndef weighted_mean(pixel, neighbors, sigma):\n    total_weight = 0\n    weighted_sum = 0\n    for neighbor in neighbors:\n        d = distance(pixel, neighbor)\n        weight = gaussian_weight(d, sigma)\n        weighted_sum += weight * neighbor\n        total_weight += weight\n    return weighted_sum / total_weight\n\ndef gaussian_weight(d, sigma):\n    return exp(-(d ** 2) / (2 * sigma ** 2))\n</code></pre></li> </ul>"},{"location":"computer-vision-unit%203/#pros_1","title":"Pros","text":"<ul> <li>Automatically determines the number of clusters.</li> <li>Robust to noise and outliers by focusing on high-density regions.</li> <li>Non-parametric, handling arbitrary cluster shapes.</li> </ul>"},{"location":"computer-vision-unit%203/#cons_1","title":"Cons","text":"<ul> <li>Sensitive to bandwidth choice, which can cause under- or over-segmentation.</li> <li>Computationally expensive, especially for high-resolution images.</li> <li>May identify noisy pixels as clusters.</li> <li>Slow due to iterative kernel movement for each pixel.</li> </ul>"},{"location":"computer-vision-unit%203/#segmentation-techniques","title":"Segmentation Techniques","text":""},{"location":"computer-vision-unit%203/#comparison-table","title":"Comparison Table","text":"Algorithm Description Advantages Limitations Region-Based Segmentation Separates objects using threshold value(s). Simple, fast, effective with high contrast. Struggles with low grayscale differences or overlapping pixel values. Edge Detection Segmentation Detects edges to define object boundaries. Good for high-contrast images. Not suitable for images with many edges or low contrast. Segmentation Based on Clustering Groups pixels into homogeneous clusters (e.g., K-means, Mean Shift). Effective for small datasets, produces excellent clusters. High computation time, not ideal for non-convex clusters. Mask R-CNN Outputs class, bounding box, and mask for each object. Flexible, state-of-the-art for segmentation. Requires significant training time."},{"location":"computer-vision-unit%203/#applications-of-image-segmentation","title":"Applications of Image Segmentation","text":"<ol> <li>Object Detection and Recognition:</li> <li>Groups similar pixels to identify distinct objects.</li> <li>Medical Imaging:</li> <li>Segments MRI, CT scans, or X-rays to highlight tumors, organs, or abnormalities.</li> <li>Texture Segmentation:</li> <li>Separates regions based on texture or color (e.g., landscape segmentation).</li> <li>Video Tracking:</li> <li>Tracks objects across video frames by clustering similar features.</li> </ol>"},{"location":"computer-vision-unit%204/","title":"Computer vision unit 4","text":"Unit 1 Unit 2 Unit 3 Unit 4"},{"location":"computer-vision-unit%204/#3d-vision-motion","title":"3D Vision Motion","text":""},{"location":"computer-vision-unit%204/#unit-4","title":"Unit 4","text":""},{"location":"computer-vision/","title":"Computer vision","text":""},{"location":"computer-vision/#unit-1","title":"Unit 1","text":""},{"location":"computer-vision/#introduction","title":"Introduction","text":"<ul> <li>Image Processing: Image in \u2192 Image out.  </li> <li>Computer Vision: Image/Video in \u2192 Interpretation out.  </li> <li>Objective: Enable computers to see and interpret objects like humans.  </li> </ul>"},{"location":"computer-vision/#human-vs-computer-vision","title":"Human vs. Computer Vision","text":"<ul> <li>Humans: Quick recognition, intelligent decision-making.  </li> <li>Computers: Require complex processing, pattern recognition, and AI.  </li> </ul>"},{"location":"computer-vision/#features-of-human-vision","title":"Features of Human Vision","text":"<ul> <li>Stereo Vision: Two eyes perceive depth using different distances.  </li> <li>Texture &amp; Color: Identifies objects based on patterns and colors.  </li> <li>Object Recognition: Recognizes objects despite illumination, viewpoint, or expression changes.  </li> <li>Context Awareness: Infers key information from a scene.  </li> </ul>"},{"location":"computer-vision/#limitations-of-human-vision","title":"Limitations of Human Vision","text":"<ul> <li>Memory Constraints: Limited ability to recall vast image data.  </li> <li>Restricted Spectrum: Limited to visible light.  </li> <li>Optical Illusions: Misinterpretations of size, shape, and perspective.  </li> </ul>"},{"location":"computer-vision/#computer-vision-vs-image-processing","title":"Computer Vision vs. Image Processing","text":"<ul> <li>Image Processing: Low-level operations (compression, restoration, enhancement).  </li> <li>Computer Vision: High-level understanding (object recognition, scene interpretation).  </li> </ul>"},{"location":"computer-vision/#applications-of-computer-vision","title":"Applications of Computer Vision","text":"<ul> <li>Self-driving Cars: Navigation and obstacle detection.  </li> <li>Facial Recognition: Identity verification.  </li> <li>Augmented Reality: Merging virtual objects with reality.  </li> <li>Medical Imaging: Detecting anomalies in X-rays and MRIs.  </li> <li>Manufacturing: Detecting defective products.  </li> <li>Retail &amp; Banking: OCR, fraud detection, and identity verification.</li> </ul>"},{"location":"computer-vision/#levels-of-processing-for-computer-vision","title":"\ud83d\udcdc Levels of processing for computer Vision","text":""},{"location":"computer-vision/#computer-vision-processing-levels","title":"Computer Vision Processing Levels","text":""},{"location":"computer-vision/#low-level-processing","title":"Low-Level Processing","text":"<ul> <li>Enhances image quality and extracts basic features like edges, corners, textures.  </li> <li>Works on raw pixel data without understanding objects.  </li> <li>Steps for low level processing:  </li> <li>Image Preprocessing: Contrast enhancement, noise reduction.  </li> <li>Feature Extraction: Edge detection (Canny, Sobel filters).  </li> <li>Segmentation: Divides an image into meaningful parts.  </li> <li>Super-Resolution: Converts low-resolution to high-resolution images.  </li> </ul> <p>Important</p> <p>Low-level processing extracts fundamental features such as edges, lines, corners, and salient points from an image. These features serve as the building blocks for higher-level processing, enabling pattern recognition, object detection, and scene understanding.</p> <p>How Low-Level Processing Helps:</p> <ul> <li>\u2705 Feature Extraction: Identifies edges, textures, and key points in an image.</li> <li>\u2705 Segmentation: Divides images into meaningful regions and shapes.</li> <li>\u2705 Noise Reduction: Enhances image clarity by removing unwanted distortions.</li> <li>\u2705 Super-Resolution: Generates higher-resolution images from fewer pixels.</li> <li>\u2705 Depth Perception: Uses stereo vision (left &amp; right cameras) to create disparity maps for estimating depth.</li> </ul>"},{"location":"computer-vision/#mid-level-processing","title":"Mid-Level Processing","text":"<ul> <li>Uses patterns and object features for recognition.  </li> <li>Works on segmented objects to classify, track, and detect motion.  </li> <li>Examples:  </li> <li>Object Detection: Recognizes and labels objects.  </li> <li>Image Classification: Assigns categories to images.  </li> <li>Image Matching &amp; Stitching: Used in panoramas.  </li> <li>Object Tracking: Predicts movement using optical flow.  </li> <li>Clustering (K-Means): Segments objects into groups.  </li> </ul>"},{"location":"computer-vision/#high-level-processing","title":"High-Level Processing","text":"<ul> <li>Involves complex scene understanding and AI-based interpretations.  </li> <li>Integrates low-level features for semantic meaning.  </li> <li>Examples:  </li> <li>Semantic Segmentation: Classifies pixels into categories (e.g., road, car, tree).  </li> <li>Instance Segmentation: Differentiates between multiple objects of the same type.  </li> <li>Panoptic Segmentation: Combines semantic + instance segmentation.  </li> <li>Deep Learning for Segmentation: Uses CNNs &amp; RNNs for precise object recognition.  </li> <li>Theme Understanding: Identifies scene context (e.g., marketplace vs. garden).  </li> <li>Visual Question Answering (VQA): AI interprets images + text-based queries.  </li> </ul>"},{"location":"computer-vision/#applications-of-computer-vision_1","title":"Applications of Computer Vision","text":"<ul> <li>Self-Driving Cars: Detects lanes, pedestrians, and traffic signs.  </li> <li>Facial Recognition: Matches faces for identity verification.  </li> <li>Medical Imaging: Detects diseases in X-rays &amp; MRIs.  </li> <li>Manufacturing: Identifies defective products.  </li> <li>Retail &amp; Banking: Uses OCR, fraud detection, and customer authentication.</li> </ul>"},{"location":"computer-vision/#deep-learning-for-image-segmentation","title":"Deep Learning for Image Segmentation","text":"<p>\ud83d\udd39 Convolutional Neural Networks (CNNs) play a crucial role in image segmentation, enabling computers to understand objects at a pixel level.</p> <p>How Deep Learning Works for Image Segmentation:</p> <ul> <li>1\ufe0f\u20e3 Feature Extraction with CNNs: CNNs process images and detect key features for segmentation.</li> <li>2\ufe0f\u20e3 Object Localization with Region Proposal Network (RPN): Identifies potential object locations and generates bounding boxes.</li> <li>3\ufe0f\u20e3 Refining Features from the Region of Interest (ROI): CNN extracts features within the bounding box.</li> <li>4\ufe0f\u20e3 Instance Segmentation using Fully Convolutional Networks (FCN): The extracted features are passed into an FCN, which learns to segment the object from its surroundings.</li> <li>5\ufe0f\u20e3 Binary Mask Output: The FCN produces a binary mask, highlighting which pixels belong to the object and which do not.</li> </ul> <p>\ud83d\ude80 From raw images to object masks, deep learning models enhance precision in image segmentation by combining feature extraction, region detection, and pixel-level classification! \ud83d\ude80</p>"},{"location":"computer-vision/#difference-between-low-level-and-high-level-features","title":"Difference Between Low-Level and High-Level Features","text":"Feature Type Low-Level Features \ud83d\uddbc\ufe0f High-Level Features \ud83e\udde0 Content Deals with raw pixel data, detecting edges, textures, and simple patterns. Focuses on object understanding, classification, and relationships. Sensitivity More sensitive to noise, lighting, and orientation changes. More robust, can interpret complex scenes despite variations. Scale Extracted from local regions (e.g., edges in a small part of the image). Global features\u2014considers the entire image for context. Resources Requires fewer system resources, as it focuses on simple features. Uses advanced AI models, requiring higher computation power. Use Cases Applied in image segmentation, feature matching, and object detection. Used in image classification, object recognition, and scene understanding. <p>\ud83d\udd0d Low-level features lay the foundation by detecting shapes and patterns, while high-level features bring context and meaning to an image. Together, they power modern computer vision applications! \ud83d\ude80</p>"},{"location":"computer-vision/#edge-detection","title":"Edge Detection","text":""},{"location":"computer-vision/#sharpening-spatial-filters","title":"Sharpening Spatial Filters","text":"<p>\ud83d\uddbc\ufe0f Purpose: - Removes blurring and enhances edges in images. - Highlights intensity transitions using spatial differentiation. - Image gradients measure the rate of change in pixel intensity, crucial for detecting edges.  </p>"},{"location":"computer-vision/#image-gradients","title":"Image Gradients","text":"<p>\ud83d\udccc Fundamental for computer vision &amp; image processing \ud83d\udd39 Used for: \u2705 Edge detection \u2705 Finding object contours \u2705 Outlining shapes </p> <p>\ud83d\udd39 Computes: - Gradient Magnitude (Strength of the edge) - Gradient Orientation (Direction of the edge)  </p> <p>\u2728 Popular techniques built on image gradients: - Histogram of Oriented Gradients (HOG) - Scale-Invariant Feature Transform (SIFT) </p>"},{"location":"computer-vision/#edge-detection-using-image-gradients","title":"Edge Detection Using Image Gradients","text":"<p>\ud83d\udca1 Gradient computation is a key pre-processing step for edge detection.  </p>"},{"location":"computer-vision/#computing-image-gradients","title":"Computing Image Gradients","text":"<p>The gradient of an image is calculated using finite differences: - Gradient along the vertical direction (\\(G_y\\)):   $$ G_y = f(r+1, c) - f(r-1, c) $$ - Gradient along the horizontal direction (\\(G_x\\)):   $$ G_x = f(r, c+1) - f(r, c-1) $$  </p> <p>\ud83d\udccc Gradient masks (filters) for edge detection: </p> Filter Mask Vertical (\\(G_y\\)) Sobel Filter \\(\\begin{bmatrix} -1 &amp; 0 &amp; 1 \\end{bmatrix}\\) Horizontal (\\(G_x\\)) Sobel Filter \\(\\begin{bmatrix} -1 \\\\ 0 \\\\ 1 \\end{bmatrix}\\)"},{"location":"computer-vision/#image-gradient-gradient-vector","title":"Image Gradient &amp; Gradient Vector","text":"<p>\ud83d\uddbc\ufe0f Purpose: - Computes rate of change in pixel intensity. - Gradient Magnitude (\\(M\\)) measures the strength of intensity change. - Gradient Orientation (\\(\\alpha\\)) determines direction of the edge. - The matrix size for magnitude and angle is the same as the original image.  </p> <p>\ud83d\udd39 Mathematical Representation: - Gradient Angle (\\(\\alpha\\)):   $$ \\alpha = \\tan^{-1} \\left(\\frac{g_y}{g_x} \\right) $$ - Gradient Magnitude (\\(M\\)):   $$ M = \\sqrt{g_x^2 + g_y^2} $$  </p> <p>\ud83d\udccc Where: - \\(g_x\\) = Gradient in the horizontal direction. - \\(g_y\\) = Gradient in the vertical direction. - \\(\\alpha\\) = Angle between the vertical axis and the edge direction.  </p>"},{"location":"computer-vision/#sobel-filter-for-edge-detection","title":"Sobel Filter for Edge Detection","text":"<p>\ud83d\udca1 Sobel filters compute image gradients using convolution masks.  </p>"},{"location":"computer-vision/#gradient-computation-with-sobel-operator","title":"Gradient Computation with Sobel Operator","text":"<p>\ud83d\udd39 Sobel Operator for Horizontal (\\(G_x\\)) and Vertical (\\(G_y\\)) Gradients: </p> Gradient Direction Filter Mask (Kernel) \\(G_x\\) (Horizontal Gradient) \\(\\begin{bmatrix} -1 &amp; 0 &amp; 1 \\\\ -2 &amp; 0 &amp; 2 \\\\ -1 &amp; 0 &amp; 1 \\end{bmatrix}\\) \\(G_y\\) (Vertical Gradient) \\(\\begin{bmatrix} -1 &amp; -2 &amp; -1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix}\\) <p>\ud83d\udd39 Steps to Compute Edge Strength: 1\ufe0f\u20e3 Convolve the image with \\(G_x\\) to compute horizontal changes. 2\ufe0f\u20e3 Convolve the image with \\(G_y\\) to compute vertical changes. 3\ufe0f\u20e3 Compute gradient magnitude and angle using:    $$ M = \\sqrt{G_x^2 + G_y^2} $$    $$ \\alpha = \\tan^{-1} \\left(\\frac{G_y}{G_x} \\right) $$  </p> <p>\ud83d\udccc Why Sobel Filters? \u2705 Enhances edges by detecting gradients in both directions. \u2705 Smooths noise while emphasizing high-frequency intensity changes. \u2705 Used in edge detection algorithms like Canny Edge Detector.  </p>"},{"location":"computer-vision/#gaussian-filter-for-image-smoothing","title":"Gaussian Filter for Image Smoothing","text":"<p>\ud83d\udd39 The Gaussian filter is a smoothing filter that reduces noise and detail in an image. \ud83d\udd39 It applies a Gaussian function to weight pixels, giving higher importance to the center pixel and gradually reducing weights outward.  </p>"},{"location":"computer-vision/#mathematical-representation","title":"Mathematical Representation","text":"<p>The Gaussian function for a 2D image is: $$ G_\\sigma(x, y) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}} $$ where: - \\( \\sigma \\) = Standard deviation (controls blurring strength) - \\( x, y \\) = Pixel coordinates  </p> <p>\ud83d\udccc Higher \\( \\sigma \\) \u2192 More blur \ud83d\udccc Lower \\( \\sigma \\) \u2192 Less blur, preserves more details </p>"},{"location":"computer-vision/#gaussian-filter-kernels","title":"Gaussian Filter Kernels","text":"Filter Size Kernel Matrix (Normalized) 3\u00d73 (\u03c3 = 1) \\( \\frac{1}{16} \\begin{bmatrix} 1 &amp; 2 &amp; 1 \\\\ 2 &amp; 4 &amp; 2 \\\\ 1 &amp; 2 &amp; 1 \\end{bmatrix} \\) 5\u00d75 (\u03c3 = 1) \\( \\frac{1}{330} \\begin{bmatrix} 1 &amp; 4 &amp; 7 &amp; 4 &amp; 1 \\\\ 4 &amp; 20 &amp; 33 &amp; 20 &amp; 4 \\\\ 7 &amp; 33 &amp; 54 &amp; 33 &amp; 7 \\\\ 4 &amp; 20 &amp; 33 &amp; 20 &amp; 4 \\\\ 1 &amp; 4 &amp; 7 &amp; 4 &amp; 1 \\end{bmatrix} \\) 5\u00d75 (\u03c3 = 2) \\( \\frac{1}{34} \\begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\\\ 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 \\\\ 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 \\\\ 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 \\\\ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\end{bmatrix} \\) <p>\ud83d\udccc Larger filter size \u2192 More blur &amp; smoothing \ud83d\udccc Smaller filter size \u2192 Preserves more details </p>"},{"location":"computer-vision/#laplacian-filter-for-edge-detection","title":"Laplacian Filter for Edge Detection","text":"<p>\ud83d\udd39 The Laplacian filter is a second-order derivative filter used for edge detection. \ud83d\udd39 It highlights regions of rapid intensity change by computing the second derivative of an image.  </p>"},{"location":"computer-vision/#mathematical-representation_1","title":"Mathematical Representation","text":"<p>The Laplacian operator is given by:  </p> \\[ \\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}\\] <p>where \\( f(x, y) \\) is the image intensity at a given point.</p>"},{"location":"computer-vision/#laplacian-filter-kernels","title":"Laplacian Filter Kernels","text":"Filter Type Kernel Matrix 4-Neighbor Laplacian \\( \\begin{bmatrix} 0 &amp; -1 &amp; 0 \\\\ -1 &amp; 4 &amp; -1 \\\\ 0 &amp; -1 &amp; 0 \\end{bmatrix} \\) 8-Neighbor Laplacian \\( \\begin{bmatrix} -1 &amp; -1 &amp; -1 \\\\ -1 &amp; 8 &amp; -1 \\\\ -1 &amp; -1 &amp; -1 \\end{bmatrix} \\) <p>\ud83d\udd39 The 4-neighbor Laplacian considers only direct neighbors, while the 8-neighbor Laplacian accounts for diagonal edges as well.</p>"},{"location":"computer-vision/#unit-2","title":"Unit 2","text":""},{"location":"computer-vision/#image-features-in-computer-vision","title":"Image Features in Computer Vision","text":"<p>\ud83d\udd39 Image features are key elements that help in object recognition, segmentation, and analysis.  </p>"},{"location":"computer-vision/#types-of-image-features","title":"Types of Image Features","text":"<p>\u2705 Edges \u2013 Identifies boundaries between objects. \u2705 Color \u2013 Extracts information based on pixel intensity. \u2705 Texture \u2013 Analyzes surface patterns and structures. \u2705 Object Boundaries \u2013 Detects outlines and contours of objects. \u2705 Object Shape \u2013 Defines geometric properties of an object.  </p> <p>\ud83d\udd39 Good Features Should Be: - \u2705 Unique &amp; Distinctive \u2013 Helps differentiate between objects. - \u2705 Non-redundant \u2013 Avoids duplicate or unnecessary information. - \u2705 Robust \u2013 Works well under noise and illumination changes. - \u2705 Global Representation \u2013 Captures scene-wide characteristics, not just local details.  </p>"},{"location":"computer-vision/#gradient-based-features","title":"Gradient-Based Features","text":"<p>Gradient-based techniques detect changes in pixel intensity, which highlight object edges and textures.  </p> <p>\ud83d\udd39 Popular Techniques: - DoG (Difference of Gaussian) - LoG (Laplacian of Gaussian) - HoG (Histogram of Oriented Gradients) - SIFT (Scale-Invariant Feature Transform) - SURF (Speeded-Up Robust Features) </p> <p>\ud83d\udccc Advantages: \u2705 Invariant to small shifts &amp; rotations \u2013 Ensures stability under transformations. \u2705 Localized histograms \u2013 Offers better spatial information compared to global histograms. \u2705 Contrast normalization \u2013 Reduces the impact of variable illumination.  </p>"},{"location":"computer-vision/#difference-of-gaussian-dog","title":"Difference of Gaussian (DoG)","text":"<p>\ud83d\udccc A feature enhancement technique used for blob detection &amp; SIFT descriptors.  </p>"},{"location":"computer-vision/#how-dog-works","title":"How DoG Works:","text":"<p>1\ufe0f\u20e3 Apply Gaussian Blur \u2013 Smoothens the image using two Gaussian filters with different sigma values (\u03c3\u2081 &amp; \u03c3\u2082). 2\ufe0f\u20e3 Subtract the Two Blurred Images \u2013 Enhances regions with specific frequency details. 3\ufe0f\u20e3 Suppress High-Frequency Details \u2013 Reduces random noise but preserves important structures.  </p> <p>\ud83d\udd39 Mathematical Representation: $$ DoG = G_{\\sigma_1} * I - G_{\\sigma_2} * I $$</p> <p>where: - \\( I \\) = Original grayscale image - \\( G_{\\sigma_1}, G_{\\sigma_2} \\) = Gaussian filters with different standard deviations  </p> <p>\ud83d\udccc Pros &amp; Cons: \u2705 Reduces noise while preserving edges \u2705 Enhances spatial features \u274c Reduces overall image contrast </p>"},{"location":"computer-vision/#laplacian-of-gaussian-log-edge-detection-feature-enhancement","title":"Laplacian of Gaussian (LoG) \u2013 Edge Detection &amp; Feature Enhancement","text":"<p>\ud83d\udd39 Laplacian of Gaussian (LoG) is a feature detection technique that combines: 1\ufe0f\u20e3 Gaussian Smoothing \u2013 Reduces noise in the image. 2\ufe0f\u20e3 Laplacian Operator \u2013 Detects edges and blobs by identifying intensity changes.  </p>"},{"location":"computer-vision/#how-log-works","title":"How LoG Works:","text":"<ol> <li>Apply a Gaussian filter to smooth the image and suppress noise.  </li> <li>Compute the second derivative (Laplacian) to highlight regions with rapid intensity changes (edges).  </li> <li>Detect zero-crossings in the Laplacian response to identify edges.  </li> </ol>"},{"location":"computer-vision/#mathematical-representation_2","title":"Mathematical Representation:","text":"<p>The LoG function is given by: $$ LoG(x, y) = \\nabla^2 G_{\\sigma} (x, y) * I(x, y) $$ where: - \\( G_{\\sigma} (x, y) \\) = Gaussian filter with standard deviation \\( \\sigma \\) - \\( \\nabla^2 \\) = Laplacian operator (second derivative) - \\( I(x, y) \\) = Input image </p>"},{"location":"computer-vision/#key-features-of-log","title":"Key Features of LoG:","text":"<p>\u2705 Combines smoothing &amp; edge detection in one step. \u2705 Detects both fine and coarse details depending on \\( \\sigma \\). \u2705 Useful for blob detection in feature descriptors like SIFT. \u274c Sensitive to noise \u2013 Requires pre-smoothing for better results.  </p> <p>\ud83d\ude80 LoG is commonly used in edge detection pipelines like the Marr-Hildreth operator and as a preprocessing step in Computer Vision applications! \ud83d\udd0d</p>"},{"location":"computer-vision/#histogram-of-oriented-gradients-hog-feature-descriptor-for-object-detection","title":"Histogram of Oriented Gradients (HoG) \u2013 Feature Descriptor for Object Detection","text":"<p>\ud83d\udd39 Histogram of Oriented Gradients (HoG) is a feature descriptor used for object detection and image classification by analyzing gradient orientations in localized regions of an image.  </p>"},{"location":"computer-vision/#step-by-step-hog-computation","title":"Step-by-Step HoG Computation","text":"<p>\u2705 Step 1: Resize Image - Resize the image to an integer multiple of 8 (nearest to the original size). - Ensures uniform cell division and efficient computation.  </p> <p>\u2705 Step 2: Divide Image into Cells - Split the image into small patches of equal size (e.g., 8\u00d78 pixels per cell). - Each cell will have its own gradient histogram.  </p> <p>\u2705 Step 3: Compute Gradients - Calculate the gradient magnitude and orientation using Sobel filters:   [   M = \\sqrt{G_x^2 + G_y^2}, \\quad \\theta = \\tan^{-1} \\left(\\frac{G_y}{G_x} \\right)   ]   where \\( G_x, G_y \\) are gradients along horizontal and vertical directions.  </p> <p>\u2705 Step 4: Compute Gradient Histograms (Per Cell) - For each 8\u00d78 cell, create a histogram of gradients (e.g., 9 bins for 0\u00b0-180\u00b0). - Assign gradient magnitudes to their corresponding orientation bins.  </p> <p>\u2705 Step 5: Construct Feature Vector - Normalize the histograms across neighboring blocks (e.g., 2\u00d72 cells per block) for better illumination invariance. - Flatten the computed HoG features into a single feature vector for classification.  </p> <p>\u2705 Step 6: Visualize HoG - HoG features are often visualized as a grid of arrows, where the length and direction represent gradient strength and orientation.  </p> <p>\u2705 Step 7: Classify Images - Use machine learning models (SVM, Deep Learning) to classify objects using the extracted HoG feature vector.  </p>"},{"location":"computer-vision/#mathematical-representation_3","title":"Mathematical Representation:","text":"<ul> <li> <p>Gradient Magnitude (\\(M\\)): $$   M = \\sqrt{G_x^2 + G_y^2} $$ </p> </li> <li> <p>Gradient Orientation (\\(\\theta\\)): $$   \\theta = \\tan^{-1} \\left(\\frac{G_y}{G_x} \\right) $$  where:  </p> </li> <li>\\( G_x, G_y \\) = Gradients in horizontal &amp; vertical directions.  </li> <li>\\( M \\) = Strength of edge response.  </li> <li>\\( \\theta \\) = Edge direction (0\u00b0\u2013180\u00b0 or 0\u00b0\u2013360\u00b0 bins).  </li> </ul>"},{"location":"computer-vision/#key-features-of-hog","title":"Key Features of HoG:","text":"<p>\u2705 Invariance to Illumination &amp; Shadows \u2013 Normalization removes intensity variations. \u2705 Captures Local Shape Information \u2013 Focuses on edges and textures rather than pixel intensity. \u2705 Robust to Small Translations &amp; Rotations \u2013 Uses histograms instead of raw gradients. \u2705 Widely Used in Object Detection \u2013 Forms the basis of Dalal-Triggs pedestrian detection and is used in SVM-based image recognition. \u274c Computationally Expensive \u2013 Requires dense gradient computations across the entire image.  </p> <p>\ud83d\ude80 HoG is widely used in Human &amp; Object Detection (e.g., Pedestrian Detection in self-driving cars) and Machine Learning-based Image Classification! \ud83d\udd0d</p>"},{"location":"computer-vision/#feature-descriptors-in-computer-vision","title":"Feature Descriptors in Computer Vision","text":"<p>\ud83d\udd39 Feature descriptors help identify key points, edges, and corners in an image. \ud83d\udd39 These descriptors are used for object detection, image matching, and recognition.  </p>"},{"location":"computer-vision/#types-of-feature-descriptors","title":"Types of Feature Descriptors","text":""},{"location":"computer-vision/#1-global-descriptors","title":"1. Global Descriptors \ud83c\udf0d","text":"<ul> <li>Represent the entire image.  </li> <li>Examples:   \u2705 Histogram of Oriented Gradients (HoG)   \u2705 Difference of Gaussian (DoG)   \u2705 Histogram of Optical Flow (HOF) </li> <li>Limitations: Struggle with occlusions and profile variations since they analyze the whole image.  </li> </ul>"},{"location":"computer-vision/#2-local-descriptors","title":"2. Local Descriptors \ud83d\udd0d","text":"<ul> <li>Describe small patches within an image.  </li> <li>More accurate &amp; robust for object detection, matching, and occlusion handling.  </li> <li>Examples:   \u2705 SIFT (Scale-Invariant Feature Transform)   \u2705 SURF (Speeded-Up Robust Features)   \u2705 LBP (Local Binary Pattern)   \u2705 BRISK (Binary Robust Invariant Scalable Keypoints)   \u2705 MSER (Maximally Stable Extremal Regions)   \u2705 FREAK (Fast Retina Keypoint) </li> </ul> <p>\ud83d\udccc Local descriptors outperform global ones in real-world applications like facial recognition and object tracking! \ud83d\ude80  </p>"},{"location":"computer-vision/#how-to-define-an-interest-point","title":"How to Define an Interest Point?","text":"<p>\ud83d\udd39 Interest points are key locations (e.g., edges, corners) where features can be extracted.  </p> <p>\u2705 Repeatability: - A feature should be detected consistently across multiple images, despite geometric &amp; photometric transformations.  </p> <p>\u2705 Saliency: - Features should be distinct and unique to avoid mismatches.  </p> <p>\u2705 Compactness: - Fewer features than the number of image pixels should effectively represent the image.  </p> <p>\u2705 Efficiency: - Fast computation is essential for real-time applications like tracking &amp; detection.  </p> <p>\u2705 Locality: - Features should occupy a small area and remain robust to clutter &amp; occlusion.  </p> <p>\u2705 Covariance: - Features should be detectable despite geometric &amp; photometric variations (e.g., rotation, lighting changes).  </p>"},{"location":"computer-vision/#sift-algorithm-scale-invariant-feature-transform","title":"SIFT Algorithm \u2013 Scale-Invariant Feature Transform","text":"<p>SIFT is a feature detection algorithm that extracts scale and rotation-invariant keypoints for object recognition, tracking, and image matching.  </p>"},{"location":"computer-vision/#step-1-construct-a-scale-space","title":"Step 1: Construct a Scale Space","text":"<p>\ud83d\udccc Why? - Real-world objects appear different at various distances (scales). - A feature must be detectable at multiple scales to be useful in recognition.  </p> <p>\ud83d\udd39 How it Works: 1. The original image is repeatedly blurred using a Gaussian filter. 2. Octaves are created by downsampling the image (reducing its size by half). 3. Within each octave, multiple blurred images are generated with increasing sigma values (\u03c3). 4. This scale-space representation ensures features are scale-independent.  </p> <p>\ud83d\udd39 Mathematical Formulation (Gaussian Blur): [ G(x, y, \\sigma) = \\frac{1}{2\\pi\\sigma^2} e^{-\\frac{x^2 + y^2}{2\\sigma^2}} ] where: - \\( G(x, y, \\sigma) \\) = Gaussian function. - \\( \\sigma \\) = Standard deviation (controls blurring). - \\( x, y \\) = Pixel coordinates.  </p> <p>\ud83d\udd39 Example: - Octave 1: Original image + multiple blurred versions. - Octave 2: Image resized to half and blurred again. - Repeats for multiple octaves (typically 4-5 octaves).  </p> <p>\ud83d\udccc Outcome: - A collection of images at different scales and resolutions.  </p>"},{"location":"computer-vision/#step-2-compute-difference-of-gaussian-dog","title":"Step 2: Compute Difference of Gaussian (DoG)","text":"<p>\ud83d\udccc Why? - Identifies keypoints by enhancing edges and texture features. - The Gaussian Blur removes noise, and the DoG highlights changes in intensity.  </p> <p>\ud83d\udd39 How it Works: 1. Compute DoG images by subtracting two consecutive Gaussian-blurred images:    [    DoG(x, y, \\sigma) = G(x, y, k\\sigma) - G(x, y, \\sigma)    ]    where \\( k \\) is a constant (typically \\( k = \\sqrt{2} \\)). 2. This process is repeated across all octaves. 3. The resulting DoG images enhance edges, blobs, and texture details.  </p> <p>\ud83d\udccc Outcome: - A set of DoG images that highlight regions of interest (potential keypoints).  </p>"},{"location":"computer-vision/#step-3-keypoint-localization","title":"Step 3: Keypoint Localization","text":"<p>\ud83d\udccc Why? - Identify stable keypoints while removing weak or false detections.  </p> <p>\ud83d\udd39 How it Works: 1. Each pixel in the DoG images is compared with 26 neighboring pixels (8 in the same image, 9 in the scale above, and 9 in the scale below). 2. If a pixel is the local maximum or minimum, it is marked as a potential keypoint. 3. Low-contrast keypoints are discarded using a threshold (typically 0.03). 4. Edges are removed using the Hessian matrix determinant to avoid unstable keypoints.  </p> <p>\ud83d\udd39 Mathematical Filtering (Hessian Matrix): [ H = \\begin{bmatrix} I_{xx} &amp; I_{xy} \\ I_{xy} &amp; I_{yy} \\end{bmatrix} ] - Compute corner response:   [   \\frac{(\\text{Trace}(H))^2}{\\text{Det}(H)} &lt; 12.1   ]   If the value is greater than 12.1, the keypoint is rejected.  </p> <p>\ud83d\udccc Outcome: - A set of highly stable, contrast-rich keypoints that can be used for further processing.  </p>"},{"location":"cv-m2/","title":"Scale-Invariant Feature Transform (SIFT)","text":"<p>SIFT is an algorithm used to detect distinct key points or features in an image. These key points are robust to changes in scale, rotation, and affine transformations, making SIFT widely used in object recognition, image stitching, and 3D reconstruction.</p>"},{"location":"cv-m2/#advantages-of-sift-detector","title":"Advantages of SIFT Detector","text":"<p>Note</p> <p>SIFT provides a highly distinctive feature descriptor, making it useful for matching objects in large databases.</p> Advantage Description Locality Features are local and robust to occlusion. Does not require segmentation of objects. Distinctiveness Features can be matched to a large database of objects. Quantity Generates many features, even for small objects. Efficiency Close to real-time performance. Extensibility Easily extends to various feature types. <p> </p> <p>The image above illustrates SIFT algorithm.</p>"},{"location":"cv-m2/#integral-image","title":"Integral Image","text":"<p>An integral image is a technique that allows for the fast computation of the sum of pixel values over a rectangular region.</p>"},{"location":"cv-m2/#key-properties","title":"Key Properties","text":"<ul> <li>Speeds up sum calculations for box-type filters.</li> <li>Reduces computational cost for large-scale image processing.</li> </ul>"},{"location":"cv-m2/#mathematical-representation","title":"Mathematical Representation","text":"<p>For an input image \\( I(x,y) \\), the integral image \\( I_{Int}(x,y) \\) at a location \\( (x,y) \\) is computed as:</p> \\[ I_{Int}(x, y) = \\sum_{i=0}^{x} \\sum_{j=0}^{y} I(i, j) \\] <p></p>"},{"location":"cv-m2/#use-of-integral-image","title":"Use of Integral Image","text":"<p>The sum of all pixel values in a region can be quickly computed using four values:</p> \\[ S = A - B - C + D \\] <p>where: - \\( A, B, C, \\) and \\( D \\) are elements of the integral image at the corners of the selected region.</p> <p>Note</p> <p>Even if size of filter increases, number of computations (3 additions/subtractions) does not increase</p>"},{"location":"cv-m2/#comparison-of-sift-and-surf","title":"Comparison of SIFT and SURF","text":"Feature SIFT (Scale-Invariant Feature Transform) SURF (Speeded-Up Robust Features) Dimensionality High-dimensional feature descriptor Lower dimensional, more compact descriptor Accuracy Reduction in dimensionality decreases accuracy More efficient without significant accuracy loss Keypoint Detection Approximates Laplacian of Gaussian (LoG) using Difference of Gaussian (DoG) Approximates LoG using Box Filters Computation Uses determinant and trace of the Hessian matrix Uses only determinant of Hessian matrix Speed Computationally expensive Faster due to integral images and parallel convolution Real-Time Applications Not optimized for real-time processing Suitable for real-time tracking &amp; object recognition <p>Tip</p> <p>SURF is a faster alternative to SIFT, making it suitable for real-time applications while maintaining robustness.</p>"},{"location":"cv-m2/#speeded-up-robust-features-surf-algorithm","title":"Speeded-Up Robust Features (SURF) Algorithm","text":""},{"location":"cv-m2/#1-detector","title":"1. Detector","text":"<ol> <li>Construct Hessian matrix using box filters at each pixel to determine keypoints.  </li> <li>Increase the size of box filters and repeat step 1.  </li> <li>For each keypoint, select points within a radius of 6\u03c3 (where \u03c3 is the standard deviation of the keypoint's filter).  </li> <li>Apply a Gaussian filter of 2.5\u03c3 on the keypoint.  </li> <li>Use a Haar wavelet of size 4\u03c3 to determine the magnitude and direction of points.  </li> <li>Draw a histogram with 6 bins to identify the orientation of the keypoint.  </li> </ol>"},{"location":"cv-m2/#2-descriptor","title":"2. Descriptor","text":"<ol> <li>Around each keypoint, select a square region of size (20\u03c3 \u00d7 20\u03c3).  </li> <li>Divide the region into 16 sub-regions.  </li> <li>For each sub-region, determine a vector of length 4.  </li> <li>The final descriptor vector has a total length of 64.  </li> </ol> <p>Tip</p> <p>SURF is significantly faster than SIFT due to its use of box filters and integral images, making it suitable for real-time applications.  </p>"},{"location":"cv-m2/#speeded-up-robust-features-surf-algorithm_1","title":"Speeded Up Robust Features (SURF) algorithm","text":""},{"location":"cv-m2/#applications-of-feature-descriptors","title":"Applications of Feature Descriptors","text":"<p>Feature descriptors are powerful tools in computer vision for identifying and describing local features in images. They enable a wide range of applications:</p> <ol> <li>Image Matching Matches keypoints between different images of the same scene or object. Essential for applications like panorama stitching, where multiple images are combined into a wide-angle view.</li> <li>Object Recognition Identifies and locates objects within images by matching features between a known object and a scene. Widely used in robotics and automated inspection systems.</li> <li>3D Reconstruction Matches images taken from different viewpoints to reconstruct 3D models of objects or environments. Essential for applications in augmented reality (AR) and virtual reality (VR).</li> <li>Image Retrieval Enables content-based image retrieval by searching for and retrieving images based on visual content rather than metadata.</li> <li>Scene Recognition Analyzes the spatial arrangement of features to recognize and categorize scenes or environments. Useful in autonomous navigation and contextual AI systems.</li> <li>Robotic Vision Helps robots navigate, identify objects, and interact with their environment more effectively.</li> <li>Video Tracking Tracks objects or people in video sequences by matching keypoints frame-to-frame. Important for surveillance and motion analysis.</li> <li>Forgery Detection Used in digital forensics to detect tampered or forged images by identifying inconsistencies in local features.</li> </ol>"},{"location":"cv-m2/#2d-gabor-filter-parameters-properties","title":"2D Gabor Filter \u2013 Parameters &amp; Properties","text":""},{"location":"cv-m2/#overview","title":"Overview","text":"<p>The Gabor filter is a powerful tool used for feature extraction, especially in texture and edge detection. It is a bandpass filter that operates in both the spatial and frequency domains, mimicking the way the human visual system perceives textures.  </p>"},{"location":"cv-m2/#key-characteristics","title":"Key Characteristics","text":"<p>\u2705 Localized in both space &amp; frequency \u2013 Helps capture patterns effectively. \u2705 Combination of Gaussian &amp; Sinusoidal components \u2013 Provides smooth feature extraction. \u2705 Mimics human vision \u2013 Recognizes textures similar to human eyes.  </p>"},{"location":"cv-m2/#mathematical-representation_1","title":"Mathematical Representation","text":"<p>A 2D Gabor filter is defined as:  </p> \\[ G(x,y) = \\exp\\left( -\\frac{x'^2 + \\gamma^2 y'^2}{2\\sigma^2} \\right) \\cos\\left( \\frac{2\\pi x'}{\\lambda} + \\psi \\right) \\] <p>where: - \\( x' = x \\cos\\theta + y \\sin\\theta \\) - \\( y' = -x \\sin\\theta + y \\cos\\theta \\) </p>"},{"location":"cv-m2/#core-parameters-of-gabor-filter","title":"Core Parameters of Gabor Filter","text":"Parameter Symbol Description Wavelength \\( \\lambda \\) Controls the width of the stripes in the Gabor function. Orientation \\( \\theta \\) Defines the angle of the normal to the parallel stripes of the Gabor function. Phase Offset \\( \\psi \\) Determines the position of the sinusoidal function, affecting edge detection. Standard Deviation \\( \\sigma \\) Defines the spread of the Gaussian envelope, controlling the extent of localization. Aspect Ratio \\( \\gamma \\) Specifies the ellipticity of the Gabor function's support. Bandwidth \\( B \\) Controls the range of spatial frequencies covered by the filter."},{"location":"cv-m2/#how-parameters-affect-the-gabor-filter","title":"How Parameters Affect the Gabor Filter","text":""},{"location":"cv-m2/#1-wavelength-stripe-width","title":"1\ufe0f\u20e3 Wavelength (\u03bb) \u2013 Stripe Width","text":"<ul> <li>Controls the width of the sinusoidal pattern.  </li> <li>Larger \u03bb \u2192 Wider stripes \u2192 Detects coarse textures.  </li> <li>Smaller \u03bb \u2192 Narrower stripes \u2192 Detects fine textures.  </li> </ul>"},{"location":"cv-m2/#2-orientation-direction-of-features","title":"2\ufe0f\u20e3 Orientation (\u03b8) \u2013 Direction of Features","text":"<ul> <li>Determines the angle at which the filter responds best to edges.  </li> <li>Example: A horizontal edge detector has \\( \\theta = 90^\\circ \\).  </li> </ul>"},{"location":"cv-m2/#3-phase-offset-sinusoidal-shift","title":"3\ufe0f\u20e3 Phase Offset (\u03c8) \u2013 Sinusoidal Shift","text":"<ul> <li>\\( \\psi = 0 \\) \u2192 Cosine Gabor (Even filter) \u2192 Detects bar-like structures.  </li> <li>\\( \\psi = \\frac{\\pi}{2} \\) \u2192 Sine Gabor (Odd filter) \u2192 Detects line-like structures.  </li> </ul>"},{"location":"cv-m2/#4-standard-deviation-gaussian-spread","title":"4\ufe0f\u20e3 Standard Deviation (\u03c3) \u2013 Gaussian Spread","text":"<ul> <li>Determines the size of the receptive field.  </li> <li>Large \\( \\sigma \\) \u2192 More blurred edges.  </li> <li>Small \\( \\sigma \\) \u2192 More sharp edges.  </li> </ul>"},{"location":"cv-m2/#5-aspect-ratio-ellipticity","title":"5\ufe0f\u20e3 Aspect Ratio (\u03b3) \u2013 Ellipticity","text":"<ul> <li>Specifies the shape of the filter.  </li> <li>Larger \\( \\gamma \\) \u2192 More elongated filter (stretches in one direction).  </li> <li>Smaller \\( \\gamma \\) \u2192 More circular response.  </li> </ul>"},{"location":"cv-m2/#gray-level-co-occurrence-matrix-glcm-texture-analysis","title":"Gray Level Co-occurrence Matrix (GLCM) \u2013 Texture Analysis","text":""},{"location":"cv-m2/#overview_1","title":"Overview","text":"<p>The Gray Level Co-occurrence Matrix (GLCM) is a powerful statistical method used in image processing and computer vision to analyze texture features by examining the spatial relationships between pixel intensities.  </p> <p>\ud83d\udd39 Key Applications: \u2705 Texture Analysis \u2013 Identifies patterns in images. \u2705 Feature Extraction \u2013 Helps in classification tasks. \u2705 Medical Imaging \u2013 Detects abnormalities in scans. \u2705 Remote Sensing \u2013 Analyzes satellite imagery.  </p>"},{"location":"cv-m2/#glcm-how-it-works","title":"GLCM \u2013 How It Works","text":"<p>GLCM computes how often pairs of gray-level intensities occur at a specific spatial relationship (distance &amp; direction) within an image. This helps extract meaningful texture features.</p>"},{"location":"cv-m2/#statistical-features-derived-from-glcm","title":"Statistical Features Derived from GLCM","text":"Feature Formula Description Contrast \\( \\sum_{i,j} (i - j)^2 p(i, j) \\) Measures intensity variation (higher contrast = more difference in pixel values). Dissimilarity ( \\sum_{i,j} i - j Energy \\( \\sum_{i,j} p(i, j)^2 \\) Sum of squared elements \u2192 Measures uniformity. Homogeneity ( \\sum_{i,j} \\frac{p(i, j)}{1 + i - j Entropy \\( \\sum_{i,j} -p(i, j) \\log_2(p(i, j)) \\) Measures randomness \u2192 Higher entropy = more complex textures. Correlation \\( \\sum_{i,j} \\frac{(i - \\mu_i)(j - \\mu_j) p(i, j)}{\\sigma_i \\sigma_j} \\) Measures linear dependency between pixel intensities."},{"location":"cv-m2/#glcm-mean-variance","title":"GLCM Mean &amp; Variance","text":"<ul> <li> <p>GLCM Mean: Represents the average occurrence of a pixel intensity based on spatial relationships.  $$ \\mu_i = \\sum_{i,j} i p(i, j), \\quad \\mu_j = \\sum_{i,j} j p(i, j) $$  </p> </li> <li> <p>GLCM Variance: Measures spread (dispersion) of pixel intensities around the mean.   $$   \\sigma_i^2 = \\sum_{i,j} p(i, j)(i - \\mu_i )^2, \\quad \\sigma_j^2 = \\sum_{i,j} p(i, j)(j - \\mu_j )^2  $$</p> </li> </ul>"},{"location":"index-copy/","title":"Index copy","text":""},{"location":"index-copy/#nmims-notes-bti-25","title":"NMIMS Notes - BTI 25'","text":"0 1 1 Days 0 1 1 Hours 0 1 1 Minutes 0 1 1 Seconds Days Hours Minutes Seconds"},{"location":"mc-m2/","title":"Mc m2","text":""},{"location":"mc-m2/#unit-4-ipv6","title":"Unit 4: IPv6","text":""},{"location":"mc-m2/#understanding-ipv4","title":"Understanding IPv4","text":"<p>An IP address (Internet Protocol address) is a unique identifier assigned to each device connected to a network using the Internet Protocol. It serves two main purposes:</p> <ul> <li>Identification: Uniquely identifies a device on a network.</li> <li>Location Addressing: Indicates where a device is located within a network, enabling data routing.</li> </ul> <p>Note</p> <p>IP addresses are essential for devices to communicate over the internet, ensuring proper identification and data transmission.</p>"},{"location":"mc-m2/#ipv4-format","title":"IPv4 Format","text":"<p>IPv4 (Internet Protocol Version 4) is the most widely used system for identifying devices on a network. It uses a 32-bit addressing scheme, represented as four numbers separated by periods.</p>"},{"location":"mc-m2/#example","title":"Example:","text":"<pre><code>192.168.0.1\n</code></pre> <p>Each number (octet) can range from 0 to 255.</p> <p>Tip</p> <p>IPv4 supports approximately 4.3 billion unique addresses, which is why IPv6 was introduced to handle the growing number of devices.</p>"},{"location":"mc-m2/#mobile-ipv4","title":"Mobile IPv4","text":"<p>Mobile IPv4 is a protocol that enables devices to maintain their IP address and network connectivity while moving between different networks.</p>"},{"location":"mc-m2/#key-benefits","title":"Key Benefits:","text":"<ul> <li>Ensures continuous network connections when a device changes its network (e.g., switching from Wi-Fi to cellular data).</li> <li>Maintains seamless communication for mobile users.</li> </ul> <p>Warning</p> <p>Without Mobile IPv4, devices would lose their network sessions when changing networks, leading to dropped connections and data loss.</p>"},{"location":"mc-m2/#agent-advertisement","title":"Agent Advertisement","text":"<p>Agent Advertisement is a process where Home Agents (HA) and Foreign Agents (FA) periodically send advertisement messages into their physical subnets.</p>"},{"location":"mc-m2/#how-it-works","title":"How It Works:","text":"<ul> <li>HA/FA broadcast advertisement messages (ICMP messages) into the subnet.</li> <li>These messages act as beacons to notify Mobile Nodes (MN) of available networks.</li> <li>Packet Details:</li> <li>TTL (Time To Live): Set to <code>1</code> to prevent forwarding.</li> <li>Destination Address:<ul> <li><code>224.0.0.1</code> (Multicast Address) or</li> <li><code>255.255.255.255</code> (Broadcast Address)</li> </ul> </li> <li>Mobile Node (MN) Actions:</li> <li>Listens for advertisement messages.</li> <li>Detects if it's in a home or foreign network.</li> <li>Reads a Care-of Address (COA) from FA advertisement messages.</li> </ul> Field Value TTL 1 (Prevents forwarding) Destination Address <code>224.0.0.1</code> (Multicast) Destination Address <code>255.255.255.255</code> (Broadcast) <p>Note</p> <p>The Care-of Address (COA) allows the mobile device to register its new location while roaming, ensuring uninterrupted communication.</p> <p></p>"},{"location":"mc-m2/#mobile-ip-basic-operation","title":"Mobile IP: Basic Operation","text":""},{"location":"mc-m2/#agent-solicitation","title":"Agent Solicitation","text":"<p>If no agent advertisements are present, or if the time between two advertisements is too high, the mobile node must send an Agent Solicitation message.</p> <ul> <li>The solicitation message should not flood the network.</li> <li>A mobile node can send up to three solicitations per second upon entering a foreign network.</li> <li>If no response is received, the solicitation rate decreases exponentially to avoid network congestion.</li> <li>Agent discovery allows the mobile node to establish a better connection.</li> <li>Once an agent is discovered, the mobile node obtains a Care-of Address (COA).</li> </ul>"},{"location":"mc-m2/#registration-request","title":"Registration Request","text":"<p>Registration requests use UDP packets with the following structure:</p> <ul> <li>Source Address: Mobile Node (MN) IP address.</li> <li>Destination Address: Home Agent (HA) or Foreign Agent (FA) IP address (depending on COA location).</li> <li>Type Field: Set to <code>1</code> to indicate a registration request.</li> <li>Flags:</li> <li><code>S</code> \u2013 Request Home Agent to retain previous mobility binding.</li> <li><code>B</code> \u2013 Request to receive broadcast packets from the home network.</li> <li><code>D</code> \u2013 Mobile Node will handle decapsulation at the tunnel (if COA is located at MN).</li> <li><code>M/G</code> \u2013 Defines encapsulation type.</li> <li><code>T</code> \u2013 Enables reverse tunneling.</li> <li>Lifetime: Defines the validity of the registration (in seconds).</li> <li>Home Address: Fixed IP address of the Mobile Node.</li> <li>Home Agent: IP address of the Home Agent.</li> <li>COA (Care-of Address): Represents the tunnel endpoint.</li> <li>Identification: 64-bit identifier generated by MN to match registration requests and replies, preventing replay attacks.</li> </ul>"},{"location":"mc-m2/#_1","title":"Mc m2","text":""},{"location":"mc-m2/#registration-reply","title":"Registration Reply","text":"<p>Once a registration request is processed, a registration reply is sent back using UDP packets:</p> <ul> <li>Type Field: Set to <code>3</code> to indicate a registration reply.</li> <li>Code Field: Specifies the result of the registration request.</li> </ul> <p>Tip</p> <p>Registration replies confirm whether a Mobile Node's registration was successful and provide status codes for troubleshooting.</p> <p>I've refined and structured this section to align with the rest of your document for better readability and clarity:</p>"},{"location":"mc-m2/#types-of-encapsulation","title":"Types of Encapsulation","text":"<p>Encapsulation is essential in Mobile IP to ensure packets reach the Care-of Address (COA). The Home Agent (HA) takes the original packet (with the Mobile Node (MN) as the destination), places it inside the data portion of a new packet, and sets a new IP header so that it is correctly routed to the COA. </p> <p>The newly added IP header is called the outer header.</p>"},{"location":"mc-m2/#encapsulation-methods","title":"Encapsulation Methods:","text":"<p>There are three primary types of encapsulation:</p> <ol> <li>IP-in-IP Encapsulation</li> <li>Minimal Encapsulation</li> <li>Generic Routing Encapsulation (GRE)</li> </ol>"},{"location":"mc-m2/#1-ip-in-ip-encapsulation","title":"1. IP-in-IP Encapsulation","text":"<ul> <li>Defined in RFC 2003 (Mandatory)</li> <li>Creates a tunnel between the Home Agent (HA) and the COA.</li> <li>The entire original IP packet is encapsulated within a new IP header.</li> <li>Used when the MN is using a foreign agent COA.</li> </ul>"},{"location":"mc-m2/#2-minimal-encapsulation","title":"2. Minimal Encapsulation","text":"<ul> <li>Reduces redundancy present in IP-in-IP encapsulation.</li> <li>Only essential fields from the original header are included.</li> <li>Helps in reducing overhead, improving efficiency.</li> </ul>"},{"location":"mc-m2/#3-generic-routing-encapsulation-gre","title":"3. Generic Routing Encapsulation (GRE)","text":"<ul> <li>Unlike IP-in-IP and Minimal Encapsulation, which work only for IP packets, GRE supports other network layer protocols.</li> <li>Allows encapsulation of different protocol suites into the payload portion of a packet.</li> <li>Uses an outer IP header, with TTL and TOS values copied from the original header.</li> <li>Provides flexibility for non-IP protocols to be transported over an IP network.</li> </ul> <p>Note</p> <p>GRE is widely used in VPNs and multicast routing to carry non-IP traffic efficiently over an IP-based network.</p> <p></p> <p></p>"},{"location":"mc-m2/#mobile-ip-and-ipv6","title":"Mobile IP and IPv6","text":""},{"location":"mc-m2/#key-features-of-mobile-ip-in-ipv6","title":"Key Features of Mobile IP in IPv6","text":"<ul> <li>Integrated Security: Unlike IPv4, security is built into IPv6 rather than being an add-on. Authentication for registration is included.  </li> <li>Auto-Configuration of COA:  </li> <li>IPv6 supports automatic configuration of the Care-of Address (COA).  </li> <li>DHCPv6 can be used for dynamic COA assignment.  </li> <li>Every IPv6 node has built-in address auto-configuration.  </li> <li>No Need for a Foreign Agent (FA):  </li> <li>In IPv6, all routers perform router advertisements, eliminating the need for a dedicated Foreign Agent.  </li> <li>Direct COA Signaling (Route Optimization):  </li> <li>The Mobile Node (MN) can directly inform a sender of its COA, bypassing the Home Agent (HA).  </li> <li>This enables automatic path optimization, reducing latency.  </li> <li>Soft Handovers (Seamless Mobility):  </li> <li>IPv6 supports smooth handovers without packet loss between subnets.  </li> <li>The MN sends its new COA to the old router.  </li> <li>The old router encapsulates and forwards packets to the new COA.  </li> <li>Authentication remains intact throughout the process.  </li> </ul>"},{"location":"mc-m2/#dynamic-host-configuration-protocol-dhcp","title":"Dynamic Host Configuration Protocol (DHCP)","text":""},{"location":"mc-m2/#overview-of-dhcp","title":"Overview of DHCP","text":"<ul> <li>DHCP is a standardized networking protocol used by servers to dynamically allocate IP addresses to computers in a network.  </li> <li>Primary Purpose: Automates IP configuration without requiring a network administrator.  </li> </ul>"},{"location":"mc-m2/#how-dhcp-works","title":"How DHCP Works","text":"<ol> <li>IP Address Allocation </li> <li>DHCP assigns IP addresses from a predefined range stored in a server database.  </li> <li> <p>Each IP is assigned for a lease period, after which the device must renew or acquire a new address.  </p> </li> <li> <p>Full Network Integration </p> </li> <li>DHCP provides additional configuration details:  <ul> <li>DNS Server Address </li> <li>Default Gateway (Router) </li> <li>Subnet Mask </li> <li>Domain Name </li> <li>IP Address </li> </ul> </li> </ol>"},{"location":"mc-m2/#dhcp-client-server-model","title":"DHCP Client-Server Model","text":"<ul> <li>DHCP follows a client/server model where clients request IP configurations from servers.  </li> <li>Clients send broadcast requests using MAC addresses to find available DHCP servers.  </li> <li>A DHCP relay agent forwards requests if servers are in a different network segment.  </li> </ul>"},{"location":"mc-m2/#dhcp-process","title":"DHCP Process","text":"<ol> <li>Client broadcasts a DHCPDISCOVER to find available DHCP servers.  </li> <li>DHCP servers respond with DHCPOFFER, listing available configurations.  </li> <li>Client sends a DHCPREQUEST to accept one configuration and reject others.  </li> <li>Selected server sends a DHCPACK, confirming the lease.  </li> <li>If the client leaves the subnet, it sends a DHCPRELEASE to free the assigned IP.  </li> </ol>"},{"location":"mc-m2/#dhcp-in-mobile-ip","title":"DHCP in Mobile IP","text":"<ul> <li>DHCP is a strong candidate for Care-of Address (COA) assignment in Mobile IP.  </li> <li>Security Concern: Without authentication, neither the Mobile Node (MN) nor the DHCP server can trust each other.  </li> </ul>"},{"location":"mc-m2/#mobile-transport-layer","title":"Mobile Transport Layer","text":""},{"location":"mc-m2/#why-transport-layer-support-is-needed-for-mobility","title":"Why Transport Layer Support is Needed for Mobility","text":"<ul> <li>Mobile networks introduce challenges beyond just network-layer mobility.  </li> <li>The Transport Layer plays a critical role in:  </li> <li>Checksumming over user data.  </li> <li>Multiplexing/Demultiplexing data to and from applications.  </li> </ul>"},{"location":"mc-m2/#udp-user-datagram-protocol","title":"UDP (User Datagram Protocol)","text":"<ul> <li>Simple addressing mechanism.  </li> <li>Connectionless (No established connection).  </li> <li>No reliability guarantees (No retransmission, no in-order delivery).  </li> </ul>"},{"location":"mc-m2/#udp-vs-tcp-in-mobile-networks","title":"UDP vs. TCP in Mobile Networks","text":"Feature UDP TCP Connection Type Connectionless Connection-oriented Reliability No reliability Reliable (retransmissions, acknowledgments) Congestion Control None Reduces speed in case of network congestion Order of Delivery No guarantee Ensures in-order delivery Usage in Mobility Suitable for real-time applications Requires adaptation for mobile networks"},{"location":"mc-m2/#challenges-of-tcp-in-mobile-networks","title":"Challenges of TCP in Mobile Networks","text":"<ul> <li>TCP assumes packet loss is due to network congestion, reducing the transmission rate unnecessarily.  </li> <li>Mobile networks require optimized TCP for 3G, 4G, and 5G environments.  </li> </ul>"},{"location":"mc-m2/#traditional-tcp-and-congestion-control","title":"Traditional TCP and Congestion Control","text":"<p>TCP was originally designed for fixed networks with stable end-systems where:</p> <ul> <li>Hardware introduces minimal transmission errors.  </li> <li>Packet loss typically occurs due to network congestion.  </li> <li>Routers drop packets when overloaded.  </li> </ul>"},{"location":"mc-m2/#how-does-the-sender-detect-packet-loss","title":"How Does the Sender Detect Packet Loss?","text":"<ul> <li>Missing Acknowledgements (ACKs).</li> </ul>"},{"location":"mc-m2/#incorrect-approach","title":"Incorrect Approach:","text":"<p>Simply retransmitting the missing packet without adjusting the transmission rate.</p>"},{"location":"mc-m2/#correct-approach","title":"Correct Approach:","text":"<p>TCP slows down dramatically using congestion control mechanisms.</p>"},{"location":"mc-m2/#tcp-slow-start","title":"TCP Slow Start","text":"<p>After detecting congestion, TCP enters Slow Start mode:</p> <ul> <li>The congestion window (<code>cwnd</code>) begins at 1 segment.</li> <li>For every successful ACK, <code>cwnd</code> doubles (exponential growth).</li> <li>Growth continues until reaching a threshold (ssthresh).</li> <li>After reaching <code>ssthresh</code>, TCP switches to linear increase.</li> </ul>"},{"location":"mc-m2/#conditions-for-stopping-growth","title":"Conditions for Stopping Growth:","text":"<ol> <li>Time-out due to missing ACK. </li> <li>Multiple ACKs for the same packet (duplicate ACKs).</li> </ol>"},{"location":"mc-m2/#tcp-congestion-control-steps","title":"TCP Congestion Control Steps","text":"Condition Action Taken First packet drop detected Reduce <code>ssthresh</code> to half Restart slow start Reset <code>cwnd</code> to 1 segment Continue with linear increase Until new loss occurs"},{"location":"mc-m2/#fast-retransmit-and-fast-recovery","title":"Fast Retransmit and Fast Recovery","text":""},{"location":"mc-m2/#fast-retransmit","title":"Fast Retransmit:","text":"<ul> <li>If multiple duplicate ACKs are received before a timeout, the sender immediately retransmits the lost packet.</li> <li>Avoids waiting for the retransmission timer.</li> </ul>"},{"location":"mc-m2/#fast-recovery","title":"Fast Recovery:","text":"<ul> <li>Instead of resetting to slow start, TCP continues with the current congestion window.</li> <li>This prevents unnecessary performance degradation.</li> </ul> <p>Tip</p> <p>Fast retransmit helps avoid unnecessary delays and ensures smoother TCP performance.</p>"},{"location":"mc-m2/#implications-of-tcp-on-mobility","title":"Implications of TCP on Mobility","text":"<p>TCP performs poorly in mobile environments due to incorrect assumptions.</p>"},{"location":"mc-m2/#incorrect-assumptions","title":"Incorrect Assumptions:","text":"<ul> <li>Packet loss = Network congestion (but mobile networks lose packets due to handovers).</li> <li>Wireless error rates = Wired error rates (wireless links are more error-prone).</li> </ul>"},{"location":"mc-m2/#mobile-ip-issue","title":"Mobile IP Issue:","text":"<ul> <li>Packets in transit to the old Foreign Agent (FA) are lost when the Mobile Node (MN) moves.</li> <li>TCP cannot differentiate between congestion-based and mobility-based packet losses.</li> </ul> <p>Warning</p> <p>TCP uses error control mechanisms to handle network congestion, which is not ideal for mobile networks.</p>"},{"location":"mc-m2/#tcp-improvements-indirect-tcp-i-tcp","title":"TCP Improvements: Indirect TCP (I-TCP)","text":""},{"location":"mc-m2/#how-i-tcp-works","title":"How I-TCP Works:","text":"<ul> <li>Keeps standard TCP for fixed networks.</li> <li>Uses an optimized TCP for mobile devices.</li> <li>Splits the TCP connection at the Foreign Agent (FA) into two separate connections.</li> </ul>"},{"location":"mc-m2/#process","title":"Process:","text":"<ol> <li>Correspondent host sends a packet.  </li> <li>Foreign Agent acknowledges and forwards it to the Mobile Node.  </li> <li>Any packet loss in the wireless network is handled by the Foreign Agent.  </li> <li>If handover occurs, socket state (sequence numbers, ports, etc.) is migrated.  </li> </ol>"},{"location":"mc-m2/#advantages-of-i-tcp","title":"Advantages of I-TCP","text":"<ul> <li>No changes needed in existing TCP implementations.  </li> <li>Wireless errors don\u2019t affect fixed networks.  </li> <li>Faster packet loss recovery (shorter wireless delays).  </li> <li>Allows different transport protocols between FA and MN.  </li> </ul> <p>Note</p> <p>I-TCP enhances TCP performance in wireless environments without altering fixed-network implementations.</p>"},{"location":"mc-m2/#disadvantages-of-i-tcp","title":"Disadvantages of I-TCP","text":"<ul> <li>Loses TCP\u2019s end-to-end reliability if FA crashes.  </li> <li>Increased handover latency due to buffering at FA.  </li> <li>Security risks: FA must be trusted, especially for encrypted data.  </li> </ul> <p>Warning</p> <p>If the Foreign Agent crashes, the entire session might fail, causing disruptions.</p>"},{"location":"mc-m2/#summary-of-tcp-enhancements","title":"Summary of TCP Enhancements","text":"Feature Standard TCP Fast Retransmit I-TCP Handles congestion Yes Yes Yes Works in mobile networks No No Yes Requires protocol changes No No Yes Improves packet loss recovery No Yes Yes Preserves end-to-end connection Yes Yes No <p>Tip</p> <p>I-TCP is a powerful improvement for mobile networks, but it compromises end-to-end reliability.</p>"},{"location":"mc-m2/#tcp-improvements","title":"TCP Improvements","text":""},{"location":"mc-m2/#snooping-tcp","title":"Snooping TCP","text":"<p>One of the drawbacks of I-TCP is the segmentation of the TCP connection, which violates end-to-end TCP semantics. Snooping TCP offers a transparent extension of TCP at the Foreign Agent (FA) to mitigate this issue.</p>"},{"location":"mc-m2/#how-snooping-tcp-works","title":"How Snooping TCP Works","text":"<ul> <li>The Foreign Agent (FA) buffers packets sent to the mobile host (MH) until an ACK is received.</li> <li>FA monitors (snoops) the packet flow in both directions.</li> <li>If a packet is lost on the wireless link, FA immediately retransmits it (local retransmission).</li> <li>The FA filters duplicate ACKs and prevents unnecessary congestion control actions in the fixed network.</li> </ul>"},{"location":"mc-m2/#data-transfer-mechanism","title":"Data Transfer Mechanism","text":"<ul> <li>To the Mobile Host:  </li> <li>FA buffers data until it receives an ACK from MH.  </li> <li>If a duplicate ACK or timeout occurs, FA quickly retransmits the packet.</li> <li>From the Mobile Host:  </li> <li>FA detects lost packets via sequence numbers.  </li> <li>FA sends a Negative Acknowledgment (NACK) to MH for quick retransmission.  </li> </ul>"},{"location":"mc-m2/#integration-with-mac-layer","title":"Integration with MAC Layer","text":"<ul> <li>The MAC layer already detects duplicate packets due to retransmissions.</li> <li>This prevents redundant retransmissions by TCP.</li> </ul>"},{"location":"mc-m2/#advantages-of-snooping-tcp","title":"Advantages of Snooping TCP","text":"<ul> <li>Preserves end-to-end semantics (FA does not acknowledge data on behalf of MH).</li> <li>Reduces packet loss impact on wireless links.</li> <li>No changes required in the fixed network.</li> </ul>"},{"location":"mc-m2/#mobile-tcp-m-tcp","title":"Mobile TCP (M-TCP)","text":""},{"location":"mc-m2/#why-m-tcp","title":"Why M-TCP?","text":"<p>M-TCP improves overall TCP performance in mobile environments by: - Maintaining end-to-end TCP semantics. - Reducing delay in case of handovers. - Enhancing throughput and handling frequent disconnections.</p>"},{"location":"mc-m2/#how-m-tcp-works","title":"How M-TCP Works","text":"<p>Like I-TCP, M-TCP splits the TCP connection, but with key differences: - Uses a Supervisory Host (SH) instead of a Foreign Agent. - SH does not cache or retransmit packets. - If disconnection is detected, SH sets sender window size to 0. - The sender goes into persistent mode, preventing unnecessary retransmissions. - When connectivity is restored, SH restores the sender window to its original value.</p>"},{"location":"mc-m2/#advantages-of-m-tcp","title":"Advantages of M-TCP","text":"<ul> <li>Preserves end-to-end TCP semantics (SH does not modify ACKs).</li> <li>Handles disconnections efficiently without slow starts.</li> <li>No buffering at SH, reducing memory usage.</li> </ul>"},{"location":"mc-m2/#disadvantages-of-m-tcp","title":"Disadvantages of M-TCP","text":"<ul> <li>Packet loss on wireless links affects the fixed network.</li> <li>Requires modifications to both MH protocol stack and network infrastructure.</li> </ul>"},{"location":"mc-m2/#fast-retransmit-fast-recovery","title":"Fast Retransmit / Fast Recovery","text":"<p>This approach forces TCP\u2019s Fast Retransmit mechanism to handle handovers efficiently.</p>"},{"location":"mc-m2/#how-it-works_1","title":"How It Works","text":"<ul> <li>When the mobile host (MH) moves to a new Foreign Agent (FA), it immediately sends duplicate ACKs to the Correspondent Host (CH).</li> <li>Sending three duplicate ACKs triggers Fast Retransmit at CH.</li> <li>This prevents Slow Start, improving handover performance.</li> </ul>"},{"location":"mc-m2/#advantages","title":"Advantages","text":"<ul> <li>Simple to implement.</li> <li>Faster recovery from handover-related losses.</li> </ul>"},{"location":"mc-m2/#disadvantages","title":"Disadvantages","text":"<ul> <li>Retransmitted packets still travel through the entire network.</li> <li>If handover takes too long, CH may initiate retransmissions prematurely.</li> <li>This approach does not address wireless link issues.</li> </ul>"},{"location":"mc-m2/#transmission-timeout-freezing","title":"Transmission / Timeout Freezing","text":"<p>TCP performance degrades in long interruptions (e.g., tunnels, no coverage areas). Timeout Freezing prevents unnecessary retransmissions.</p>"},{"location":"mc-m2/#how-it-works_2","title":"How It Works","text":"<ul> <li>The MAC layer detects connection loss early.</li> <li>TCP pauses timers and freezes the congestion window.</li> <li>Once connectivity is restored, TCP resumes from the exact point it was stopped.</li> </ul>"},{"location":"mc-m2/#advantages_1","title":"Advantages","text":"<ul> <li>Prevents unnecessary retransmissions during long disconnections.</li> <li>Maintains TCP state without requiring modifications in the fixed network.</li> <li>Works independently of acknowledgments or sequence numbers.</li> </ul>"},{"location":"mc-m2/#disadvantages_1","title":"Disadvantages","text":"<ul> <li>Relies on MAC layer to detect interruptions accurately.</li> <li>Encryption mechanisms with time-dependent keys may cause issues.</li> </ul>"},{"location":"mc-m2/#selective-retransmission","title":"Selective Retransmission","text":""},{"location":"mc-m2/#why-its-needed","title":"Why It\u2019s Needed","text":"<p>Standard TCP cumulatively acknowledges packets. If a single packet is lost, TCP retransmits all subsequent packets, wasting bandwidth.</p>"},{"location":"mc-m2/#how-selective-retransmission-works","title":"How Selective Retransmission Works","text":"<ul> <li>The receiver requests only the lost packets.</li> <li>The sender sends the missing packets instead of retransmitting everything.</li> </ul>"},{"location":"mc-m2/#advantages_2","title":"Advantages","text":"<ul> <li>Minimizes retransmission overhead, especially in wireless networks.</li> <li>Improves efficiency on low-bandwidth connections.</li> </ul>"},{"location":"mc-m2/#disadvantages_2","title":"Disadvantages","text":"<ul> <li>Requires additional buffer space at the receiver.</li> <li>More complex implementation compared to standard TCP.</li> </ul>"},{"location":"mc-m2/#transaction-oriented-tcp","title":"Transaction-Oriented TCP","text":""},{"location":"mc-m2/#problem-with-traditional-tcp","title":"Problem with Traditional TCP","text":"<p>For short-lived requests, such as a mobile host sending a single request to a server, TCP\u2019s connection setup overhead is too high.</p>"},{"location":"mc-m2/#issues-with-standard-tcp-for-transactions","title":"Issues with Standard TCP for Transactions","text":"<ul> <li>Three-way handshake for connection setup.</li> <li>Multiple packets needed for transmission.</li> <li>Three more packets for connection teardown.</li> <li>If the data fits in one packet, TCP still requires seven packets.</li> </ul>"},{"location":"mc-m2/#solution-transaction-oriented-tcp","title":"Solution: Transaction-Oriented TCP","text":"<ul> <li>Reduces TCP overhead for short transactions.</li> <li>Uses minimal packet exchanges.</li> </ul> <ul> <li>T/TCP can combine packets for connection establishment and connection release with user data packets.  = This can reduce the number of packets down to two instead of seven.</li> </ul>"},{"location":"mc-m2/#advantage-for-certain-applications-is-the-reduction-in-the-overhead-which-standard-tcp-has-for-connection-setup-and-connection-release","title":"Advantage for certain applications is the reduction in the overhead which standard TCP has for connection setup and connection release.","text":"<ul> <li>T/TCP is not the original TCP anymore, so it requires changes in the mobile host and all correspondent hosts, which is a major disadvantage. </li> </ul>"},{"location":"mc-m2/#tcp-enhancements-for-wireless-and-mobile-networks","title":"TCP Enhancements for Wireless and Mobile Networks","text":""},{"location":"mc-m2/#introduction","title":"Introduction","text":"<p>Transmission Control Protocol (TCP) was originally designed for wired networks, where packet loss is primarily due to congestion. However, in wireless and mobile networks, factors such as high latency, jitter, and packet loss due to handovers or signal interference significantly degrade TCP performance. This document explores various TCP improvements tailored for wireless environments.</p>"},{"location":"mc-m2/#1-snooping-tcp","title":"1. Snooping TCP","text":"<p>Note</p> <p>Snooping TCP is a transparent extension of TCP within the foreign agent (FA) to optimize performance in mobile networks.</p>"},{"location":"mc-m2/#how-it-works_3","title":"How It Works","text":"<ul> <li>The foreign agent (FA) buffers packets destined for the mobile host (MH) until an acknowledgment (ACK) is received.  </li> <li>If a packet is lost on the wireless link, the FA retransmits it locally instead of relying on the original sender.  </li> <li>The FA snoops acknowledgments and filters duplicate ACKs, reducing unnecessary retransmissions.  </li> </ul>"},{"location":"mc-m2/#advantages_3","title":"Advantages","text":"<ul> <li>Preserves end-to-end TCP semantics by acknowledging only when the MH responds.  </li> <li>Faster retransmissions as lost packets are handled locally.  </li> <li>Works transparently without modifications to the TCP sender.  </li> </ul>"},{"location":"mc-m2/#limitations","title":"Limitations","text":"<ul> <li>Requires modifications at the foreign agent.  </li> <li>Does not work with encrypted TCP headers (e.g., IPsec).</li> </ul>"},{"location":"mc-m2/#2-mobile-tcp-m-tcp","title":"2. Mobile TCP (M-TCP)","text":"<p>Tip</p> <p>M-TCP improves throughput while maintaining end-to-end TCP semantics and ensuring efficient handovers.</p>"},{"location":"mc-m2/#how-it-works_4","title":"How It Works","text":"<ul> <li>Supervisory Host (SH) monitors TCP traffic but does not cache or retransmit packets.  </li> <li>If the mobile host disconnects, the SH sets the sender\u2019s TCP window size to zero, preventing unnecessary retransmissions.  </li> <li>Once connectivity is restored, the window is reopened at the previous value, resuming normal data transfer.  </li> </ul>"},{"location":"mc-m2/#advantages_4","title":"Advantages","text":"<p>\u2705 Supports long disconnections without breaking connections. \u2705 Prevents slow start by maintaining the sender\u2019s state. \u2705 No buffering at the supervisory host, reducing overhead.  </p>"},{"location":"mc-m2/#limitations_1","title":"Limitations","text":"<p>\u274c Packet loss on the wireless link affects the fixed network. \u274c Requires modifications to the mobile host\u2019s TCP stack.  </p>"},{"location":"mc-m2/#3-fast-retransmit-fast-recovery","title":"3. Fast Retransmit &amp; Fast Recovery","text":"<p>Warning</p> <p>This method artificially triggers fast retransmission to prevent slow start during handovers.</p>"},{"location":"mc-m2/#how-it-works_5","title":"How It Works","text":"<ul> <li>When a mobile host moves to a new foreign agent, it sends three duplicate ACKs to the correspondent host.  </li> <li>This forces the correspondent host into fast retransmit mode without triggering slow start.  </li> </ul>"},{"location":"mc-m2/#advantages_5","title":"Advantages","text":"<ul> <li>Reduces delay during handovers. </li> <li>Simple to implement with minor modifications.  </li> </ul>"},{"location":"mc-m2/#limitations_2","title":"Limitations","text":"<ul> <li>Inefficient for networks with high latency.  </li> <li>If the handover is slow, the retransmitted packets may arrive too late.  </li> </ul> <pre><code>Example: Mobile host sends 3 duplicate ACKs -&gt; Fast retransmit triggered\n</code></pre>"},{"location":"mc-m2/#4-transmission-timeout-freezing","title":"4. Transmission Timeout Freezing","text":"<p>Note</p> <p>When a long disconnection (e.g., moving through a tunnel) is detected, TCP freezes its state to prevent timeouts.</p>"},{"location":"mc-m2/#how-it-works_6","title":"How It Works","text":"<ul> <li>The MAC layer detects a connection issue before TCP is interrupted.  </li> <li>TCP pauses timers and stops retransmissions, maintaining the congestion window state.  </li> <li>Once connectivity is restored, TCP resumes without triggering slow start.  </li> </ul>"},{"location":"mc-m2/#advantages_6","title":"Advantages","text":"<p>\u2705 Ideal for long interruptions (e.g., tunnels, network congestion). \u2705 Independent of TCP mechanisms like sequence numbers and acknowledgments.  </p>"},{"location":"mc-m2/#limitations_3","title":"Limitations","text":"<p>\u274c Requires MAC layer awareness of connection issues. \u274c Does not work with encryption methods that rely on timestamps.  </p>"},{"location":"mc-m2/#5-selective-retransmission","title":"5. Selective Retransmission","text":"<p>Tip</p> <p>Instead of retransmitting all unacknowledged packets, TCP resends only the lost ones using Selective Acknowledgment (SACK).</p>"},{"location":"mc-m2/#how-it-works_7","title":"How It Works","text":"<ul> <li>The receiver informs the sender exactly which packets were lost.  </li> <li>The sender only retransmits those specific packets.  </li> </ul>"},{"location":"mc-m2/#advantages_7","title":"Advantages","text":"<p>\u2705 Reduces bandwidth consumption, especially on wireless links. \u2705 Speeds up recovery from packet loss.  </p>"},{"location":"mc-m2/#limitations_4","title":"Limitations","text":"<p>\u274c Requires more complex receiver logic. \u274c Buffering overhead for out-of-order packets.  </p> <pre><code>Example: Lost packet #4 detected -&gt; Only #4 is retransmitted\n</code></pre>"},{"location":"mc-m2/#6-tcp-over-25g3g-networks","title":"6. TCP Over 2.5G/3G Networks","text":"<p>Warning</p> <p>TCP performance in 2.5G/3G networks is affected by high latency, jitter, and bandwidth fluctuations.</p>"},{"location":"mc-m2/#challenges-in-25g3g","title":"Challenges in 2.5G/3G","text":"Factor Impact on TCP Mitigation Latency Increases RTT due to error correction Use timestamp option for better RTT estimation Jitter Causes random delay spikes Enable Explicit Congestion Notification (ECN) Packet Loss Occurs during handovers Use Selective Acknowledgment (SACK) Bandwidth Oscillations Reduces throughput unpredictably Use large windows and limited transmit"},{"location":"mc-m2/#recommended-tcp-optimizations","title":"Recommended TCP Optimizations","text":"<ul> <li>Large TCP Window Size to adapt to higher latency.  </li> <li>Limited Transmit (RFC 3042) to improve performance for small data transmissions.  </li> <li>Explicit Congestion Notification (ECN) to signal congestion without dropping packets.  </li> <li>Selective Acknowledgment (SACK) for efficient retransmission.  </li> <li>Avoid TCP Header Compression (RFC 1144) as it performs poorly with packet loss.  </li> </ul>"},{"location":"mc-m2/#7-performance-enhancing-proxies-pep","title":"7. Performance-Enhancing Proxies (PEP)","text":"<p>Note</p> <p>Proxies are used to improve TCP performance in wireless networks by handling retransmissions locally.</p>"},{"location":"mc-m2/#how-it-works_8","title":"How It Works","text":"<ul> <li>Splits the connection between sender and mobile host.  </li> <li>Optimizes data flow by caching and retransmitting lost packets at the proxy level.  </li> </ul>"},{"location":"mc-m2/#advantages_8","title":"Advantages","text":"<p>\u2705 Reduces delay by handling retransmissions locally. \u2705 Improves throughput in high-latency wireless networks.  </p>"},{"location":"mc-m2/#limitations_5","title":"Limitations","text":"<p>\u274c Breaks end-to-end TCP semantics. \u274c Not compatible with IPsec encryption.  </p>"},{"location":"mc-m2/#unit-5-mobile-databases","title":"Unit 5: Mobile Databases","text":""},{"location":"mc-m2/#introduction-to-mobile-databases","title":"Introduction to Mobile Databases","text":"<p>Mobile databases are specialized data management systems designed for mobile devices. They address unique challenges such as:  </p> <ul> <li>Limited device resources \u2013 Optimizing power and storage usage.  </li> <li>Intermittent network connectivity \u2013 Ensuring seamless synchronization.  </li> <li>Data distribution \u2013 Managing access across multiple locations.  </li> </ul> <p>These databases enable:  </p> <ul> <li>Efficient data querying.  </li> <li>Offline operations.  </li> <li>Secure data handling.  </li> <li>Synchronization between mobile devices and central servers.  </li> </ul> <p>Note</p> <p>Mobile databases allow devices to function independently while staying connected to a broader data ecosystem.  </p>"},{"location":"mc-m2/#need-for-mobile-databases","title":"Need for Mobile Databases","text":"<p>Users require seamless access to their data and the ability to perform transactions securely on mobile devices.  </p>"},{"location":"mc-m2/#key-requirements","title":"Key requirements:","text":"<ul> <li>Transaction handling \u2013 Making secure payments, updating records.  </li> <li>Everyday convenience \u2013 Sending money, booking seats, trading stocks.  </li> <li>Continuous access \u2013 Uninterrupted availability of information.  </li> </ul> <p>Tip</p> <p>The demand for \"anytime, anywhere\" access makes mobile databases essential in modern applications.  </p>"},{"location":"mc-m2/#uses-of-mobile-databases","title":"Uses of Mobile Databases","text":"<p>Mobile databases empower developers to build and deploy applications for handheld devices.  </p>"},{"location":"mc-m2/#common-use-cases","title":"Common use cases:","text":"<ul> <li>Corporate Access: </li> <li>Employees connect to their company's network.  </li> <li>Data is downloaded for offline work.  </li> <li> <p>Updates sync back when connected.  </p> </li> <li> <p>Real-world example:   A food delivery app rider using mobile databases can:  </p> </li> <li>Accept new orders while on the move.  </li> <li>Track delivery locations and customer details offline.  </li> <li>Update delivery status in real-time.  </li> <li>Sync all completed deliveries to the restaurant\u2019s system.  </li> </ul> <p>Note</p> <p>Mobile databases ensure real-time tracking and offline functionality for critical applications.  </p>"},{"location":"mc-m2/#mobile-databases-design-issues","title":"Mobile Databases: Design Issues","text":"<p>Mobile databases must be built for mobility rather than adapted from traditional database systems.  </p>"},{"location":"mc-m2/#key-challenges","title":"Key challenges:","text":"Challenge Description Query Optimization Users move constantly, making it hard to determine the best way to process data requests. Time Management Mobile networks often charge based on connection time and data usage, requiring efficient retrieval. Power Efficiency Limited battery life demands minimal energy consumption for database operations. <p>Warning</p> <p>Poor optimization can lead to high costs, battery drain, and slow performance.  </p>"},{"location":"mc-m2/#problems-in-mobile-databases","title":"Problems in Mobile Databases","text":""},{"location":"mc-m2/#routing","title":"Routing","text":"<p>One of the biggest costs in wireless communication is connection time. Efficient routing reduces this expense.  </p>"},{"location":"mc-m2/#query-processing","title":"Query Processing","text":"<ul> <li>Mobile devices often disconnect for extended periods.  </li> <li>Users may issue queries or updates on cached data while offline.  </li> </ul>"},{"location":"mc-m2/#recoverability","title":"Recoverability","text":"<ul> <li>If a disconnected device fails, all locally stored updates may be lost permanently.  </li> </ul>"},{"location":"mc-m2/#consistency","title":"Consistency","text":"<ul> <li>Cached data can become outdated, and devices won\u2019t detect inconsistencies until they reconnect.  </li> <li>No updates can sync until the device is back online.  </li> </ul> <p>Tip</p> <p>Using synchronization mechanisms and conflict resolution strategies can mitigate these issues.  </p>"},{"location":"mc-m2/#introduction-to-coda","title":"Introduction to CODA","text":"<p>CODA is a distributed file system designed for high availability, scalability, and fault tolerance. It was developed as an extension of the Andrew File System (AFS) at Carnegie Mellon University. CODA ensures continuous data access even in the presence of network failures or server disconnections by using client-side caching, replication, and disconnected operation.  </p>"},{"location":"mc-m2/#mechanisms-of-the-coda-file-system","title":"Mechanisms of the CODA File System","text":""},{"location":"mc-m2/#1-server-replication","title":"1. Server Replication","text":"<p>Server replication ensures that data remains accessible by storing multiple read-write replicas across different servers.  </p> <ul> <li>Volumes have read-write replicas stored on multiple servers, forming a Volume Storage Group (VSG).  </li> <li>Clients track available servers through an Accessible Volume Storage Group (AVSG).  </li> <li>Venus (cache manager) ensures consistency by implementing a coherence protocol.  </li> <li>Servers notify clients whenever cached copies become stale or invalid.  </li> <li>Modifications are propagated simultaneously across all AVSG sites and later synced to missing VSG sites.  </li> </ul>"},{"location":"mc-m2/#2-disconnected-operation","title":"2. Disconnected Operation","text":"<p>CODA supports offline access by allowing clients to function independently when the network is unavailable.  </p> <ul> <li>Venus handles all file system requests using local cache data.  </li> <li>When the client reconnects, Venus syncs modifications to the server and returns to replication mode.  </li> <li>Ensures uninterrupted access for mobile users.  </li> </ul>"},{"location":"mc-m2/#3-client-side-caching","title":"3. Client-Side Caching","text":"<ul> <li>Uses Venus, the CODA client module, to cache frequently accessed files locally.  </li> <li>Improves performance by reducing the need for frequent server requests.  </li> <li>Cached files allow users to work offline and sync changes later.  </li> </ul>"},{"location":"mc-m2/#4-conflict-resolution","title":"4. Conflict Resolution","text":"<ul> <li>Automatic resolution for simple conflicts (e.g., appending to logs).  </li> <li>Manual intervention required for complex conflicts where two users modify the same file.  </li> <li>Uses resolution tools to merge conflicting versions.  </li> </ul>"},{"location":"mc-m2/#5-scalability-and-performance","title":"5. Scalability and Performance","text":"<ul> <li>Efficient handling of large-scale distributed systems.  </li> <li>Supports large numbers of clients with minimal performance degradation.  </li> <li>Balances workload using adaptive caching and replication strategies.  </li> </ul>"},{"location":"mc-m2/#6-security","title":"6. Security","text":"<ul> <li>Uses Kerberos authentication for secure access control.  </li> <li>Encrypts data transmissions to protect sensitive information.  </li> <li>Access control lists (ACLs) manage user permissions.  </li> </ul>"},{"location":"mc-m2/#venus-states-in-coda","title":"Venus States in CODA","text":"<p>Venus operates in three distinct states, depending on the network connection status.  </p>"},{"location":"mc-m2/#1-hoarding-preparation-phase","title":"1. Hoarding (Preparation Phase)","text":"<ul> <li>Venus proactively caches essential data before disconnection.  </li> <li>Frequently accessed files are prefetched while online.  </li> <li>Uses Least Recently Used (LRU) strategy to manage cache content efficiently.  </li> </ul>"},{"location":"mc-m2/#2-emulation-disconnected-operation","title":"2. Emulation (Disconnected Operation)","text":"<ul> <li>When disconnected, Venus operates as a pseudo-server, providing local file access.  </li> <li>Applications access cached files without needing server connectivity.  </li> <li>Venus tracks all changes and assigns temporary file IDs for new objects.  </li> <li>Conflict detection: After reconnection, file versions are compared, and conflicts are flagged for manual resolution.  </li> </ul>"},{"location":"mc-m2/#3-reintegration-reconnection-syncing","title":"3. Reintegration (Reconnection &amp; Syncing)","text":"<ul> <li>Venus propagates all changes made during disconnection back to the server.  </li> <li>The system updates cached files to reflect server changes.  </li> <li>Reintegration occurs automatically upon network reconnection.  </li> <li>If conflicting updates exist, files are stored as separate copies for manual integration.  </li> </ul>"},{"location":"mc-m2/#client-structure-in-coda","title":"Client Structure in CODA","text":"<p>CODA's client-side architecture is designed for flexibility and efficiency.  </p> <ul> <li>Venus runs at the user level, not the kernel level, allowing easier updates and flexibility.  </li> <li>A mini-cache inside the kernel filters frequent Venus-kernel interactions, improving performance.  </li> <li>File access process:  </li> <li>Applications request files via the Vnode interface.  </li> <li>If the mini-cache contains the file, the request is processed instantly.  </li> <li>If not, Venus fetches the file from the server and updates the cache.  </li> <li>After processing, control returns to the application.  </li> <li>Venus periodically updates the mini-cache to maintain consistency.  </li> </ul>"},{"location":"mc-m2/#design-rationale-of-coda-file-system","title":"Design Rationale of CODA File System","text":"<p>CODA was designed with specific goals in mind to support mobile and distributed computing.  </p> <p>\u2705 Standard Hardware Compatibility \u2192 Works on commercial systems without requiring special equipment. \u2705 Transparency \u2192 Users do not need to know where files are stored. \u2705 Scalability \u2192 Handles growing networks and large data volumes efficiently. \u2705 Mobile Computing Support \u2192 Built for portable workstations and remote access. \u2705 High Availability \u2192 Ensures continuous access even during network failures. \u2705 Strong Consistency \u2192 Synchronizes data accurately across all replicas.  </p>"},{"location":"mc-m2/#unit-6-wireless-communication","title":"Unit 6: Wireless Communication","text":""},{"location":"mc-m2/#introduction_1","title":"Introduction","text":"<p>Wireless communication refers to the transfer of information between two or more devices without physical cables or wires. It uses electromagnetic waves to transmit data over the airwaves.  </p> <p>Some common wireless communication technologies include:</p> <ul> <li>Wi-Fi: Uses radio waves to provide high-speed internet and network connections.  </li> <li>Bluetooth: Short-range wireless technology for connecting devices like smartphones, laptops, and headphones.  </li> <li>Cellular Networks: Enables voice and data communication using mobile devices.  </li> <li>Satellite Communication: Uses satellites to transmit data over long distances.  </li> <li>RFID (Radio Frequency Identification): Employs radio waves to identify and track objects.  </li> </ul> <p>Wireless communication has revolutionized connectivity and has enabled technologies like the Internet of Things (IoT), which relies on wireless networks to link devices and sensors.</p>"},{"location":"mc-m2/#components-of-wireless-communication-systems","title":"Components of Wireless Communication Systems","text":""},{"location":"mc-m2/#1-transmitters","title":"1. Transmitters","text":"<p>A transmitter encodes information into a modulated radio frequency signal and transmits it via an antenna. It generates an alternating current that is applied to the antenna, which then radiates radio waves.</p>"},{"location":"mc-m2/#2-receivers","title":"2. Receivers","text":"<p>A receiver detects transmitted signals using an antenna and demodulates them to extract the original information.</p>"},{"location":"mc-m2/#3-antennas","title":"3. Antennas","text":"<p>An antenna is responsible for transmitting and receiving radio frequency signals.  </p> <ul> <li>Converts electrical energy into electromagnetic waves (and vice versa).  </li> <li>Enhances signal quality and reduces interference.  </li> <li>High-gain antennas extend the range of communication.</li> </ul>"},{"location":"mc-m2/#4-filters","title":"4. Filters","text":"<p>Filters eliminate unwanted signals, reducing noise and interference to ensure that the transmitted or received signal is within the desired frequency range.</p>"},{"location":"mc-m2/#5-amplifiers","title":"5. Amplifiers","text":"<p>Amplifiers increase signal strength, allowing transmission over longer distances while maintaining quality. They also enhance receiver sensitivity.</p>"},{"location":"mc-m2/#6-mixers","title":"6. Mixers","text":"<p>Mixers convert signal frequency by combining two signals to produce a new signal with a frequency that is the sum or difference of the two input frequencies. This is essential in radio communication.</p> <p>Tip</p> <p>High-gain antennas and amplifiers can significantly extend the communication range in wireless systems.</p>"},{"location":"mc-m2/#bluetooth-technology","title":"Bluetooth Technology","text":"<p>Bluetooth is a short-range wireless technology that connects devices to form a Personal Area Network (PAN). It operates in the 2.4 GHz to 2.485 GHz range using ultra-high frequency (UHF) radio waves.  </p>"},{"location":"mc-m2/#bluetooth-applications","title":"Bluetooth Applications","text":"<ul> <li>Wireless laptops and PCs </li> <li>Mobile phones and PDAs  </li> <li>Printers </li> <li>Wireless headsets </li> <li>Personal and Local Area Networks (PANs &amp; LANs) </li> <li>Data transfer (files, videos, images, music)  </li> <li>Wireless peripheral devices (mouse, keyboards)  </li> </ul>"},{"location":"mc-m2/#bluetooth-protocol-stack","title":"Bluetooth Protocol Stack","text":"Protocol Layer Description Radio Defines air interface, frequency bands, and modulation techniques. Baseband Defines addressing, packet format, and power control algorithms. LMP (Link Manager Protocol) Establishes and maintains logical links, handles authentication and encryption. L2CAP (Logical Link Control and Adaptation Protocol) Provides adaptation between upper-layer frames and baseband format. SDP (Service Discovery Protocol) Handles service-related queries for device connections. <p>Warning</p> <p>Bluetooth operates on shared frequency bands, making it susceptible to interference from other wireless devices.  </p>"},{"location":"mc-m2/#protocols-in-the-bluetooth-protocol-stack","title":"Protocols in the Bluetooth Protocol Stack","text":""},{"location":"mc-m2/#core-protocols","title":"Core Protocols","text":"<p>Includes essential Bluetooth layers: - Bluetooth Radio - Baseband - Link Manager Protocol (LMP) - Logical Link Control and Adaptation Protocol (L2CAP) - Service Discovery Protocol (SDP) </p>"},{"location":"mc-m2/#cable-replacement-protocol","title":"Cable Replacement Protocol","text":"<ul> <li>RFComm (Radio Frequency Communications Protocol) \u2013 Provides a serial interface for replacing wired connections.  </li> </ul>"},{"location":"mc-m2/#adopted-protocols","title":"Adopted Protocols","text":"<p>Bluetooth integrates several standard networking protocols: - Point-to-Point Protocol (PPP) - Internet Protocol (IP) - User Datagram Protocol (UDP) - Transmission Control Protocol (TCP) - Wireless Application Protocol (WAP) </p>"},{"location":"mc-m2/#additional-protocols","title":"Additional Protocols","text":"<ul> <li>AT Commands \u2013 Command set for controlling Bluetooth devices.  </li> <li>Audio Protocol \u2013 Handles voice and sound transmission over Bluetooth.  </li> </ul>"},{"location":"mc-m2/#bluetooth-frame-structure","title":"Bluetooth Frame Structure","text":"<p>Bluetooth packets consist of three main components: Access Code, Packet Header, and Payload. Each field plays a crucial role in ensuring reliable communication within a Bluetooth network.  </p> Field Size (bits) Description Access Code 72 Used for timing synchronization, piconet identification, and error detection. Packet Header 54 Contains essential control information such as device address, type of packet, flow control, acknowledgment, sequence numbers, and error detection. Payload 0-2744 Carries actual data or voice, depending on the type of communication."},{"location":"mc-m2/#access-code-72-bits","title":"\ud83d\udd39 Access Code (72 bits)","text":"<p>The Access Code field is the first part of a Bluetooth packet and is primarily used for device identification and synchronization.  </p> Subfield Size (bits) Description Preamble 4 Helps receivers synchronize with the incoming packet. It consists of alternating bits (1010 or 0101). Synchronization 64 Uniquely identifies the piconet and is derived from the master's Bluetooth address. It allows a slave to recognize packets from its master. Trailer 4 Ensures correct signal detection and packet alignment. <p>Note</p> <ul> <li>The Synchronization field is crucial for filtering out unwanted Bluetooth signals from other nearby piconets.  </li> <li>The Access Code helps maintain collision avoidance and packet integrity.  </li> </ul>"},{"location":"mc-m2/#packet-header-54-bits","title":"\ud83d\udd39 Packet Header (54 bits)","text":"<p>The Packet Header carries control and management information necessary for maintaining Bluetooth connections. It contains six subfields:  </p> Subfield Size (bits) Description AM_ADDR (Active Member Address) 3 Identifies one of the seven active slaves in a piconet (0 is reserved for broadcast). Type 4 Specifies the type of Bluetooth packet (e.g., data, control, or voice packet). Flow 1 Flow control bit used for managing buffer overflow conditions. ARQN (Acknowledgment Number) 1 Acknowledges successful receipt of the last packet (1 = ACK, 0 = NACK). SEQN (Sequence Number) 1 Ensures correct packet order and detects duplicates in retransmission. HEC (Header Error Check) 8 Provides error detection for the header. It helps in identifying corrupt headers. <p>Tip</p> <ul> <li>The SEQN and ARQN fields work together to enable Bluetooth\u2019s Automatic Repeat reQuest (ARQ) mechanism for reliable transmission.  </li> <li>The HEC ensures that header corruption is detected before processing further.  </li> </ul>"},{"location":"mc-m2/#payload-0-2744-bits","title":"\ud83d\udd39 Payload (0-2744 bits)","text":"<p>The Payload is the data-carrying part of the packet. Its size varies based on the type of packet:  </p> Payload Type Size (bits) Purpose Voice Data Fixed 240 Used for real-time audio communication. No retransmission occurs. Asynchronous Data (ACL) 0-2744 Used for file transfer and general data communication. Supports error correction and retransmission. Synchronous Data (SCO/eSCO) 0-240 Used for streaming applications like audio calls, with limited retransmission. <p>Warning</p> <ul> <li>Voice packets (SCO) have no retransmission due to real-time constraints.  </li> <li>Data packets (ACL) support error correction and retransmission for reliability.  </li> </ul>"},{"location":"mc-m2/#error-handling-in-bluetooth-packets","title":"\ud83d\udd39 Error Handling in Bluetooth Packets","text":"<p>Bluetooth implements several error detection and correction mechanisms:  </p> <ol> <li>Header Error Check (HEC) \u2013 Detects corruption in the packet header.  </li> <li>Cyclic Redundancy Check (CRC) \u2013 Applied to payload data for error detection.  </li> <li>Forward Error Correction (FEC) \u2013 Helps correct errors in weak signals (1/3 and 2/3 FEC schemes).  </li> <li>Automatic Repeat reQuest (ARQ) \u2013 Retransmits packets when errors are detected.  </li> </ol> <p>Tip</p> <p>Bluetooth\u2019s robust error correction techniques ensure a balance between reliability and efficiency, making it suitable for both voice and data applications. </p>"},{"location":"mc-m2/#wi-fi-standards-ieee-80211-family-summary-notes","title":"Wi-Fi Standards (IEEE 802.11 Family) \u2013 Summary Notes","text":""},{"location":"mc-m2/#introduction_2","title":"Introduction","text":"<p>Wi-Fi standards (IEEE 802.11) define wireless communication protocols, improving speed, frequency bands, and features over time.  </p>"},{"location":"mc-m2/#major-wi-fi-standards-and-their-features","title":"Major Wi-Fi Standards and Their Features","text":"Standard Year Frequency Band Max Speed Key Features Also Known As 802.11 (Original) 1997 2.4 GHz 1-2 Mbps First wireless LAN standard using FHSS or DSSS - 802.11a 1999 5 GHz 54 Mbps Uses OFDM encoding scheme - 802.11b 1999 2.4 GHz 11 Mbps Uses DSSS, widely adopted first-gen Wi-Fi Wi-Fi (Original) 802.11g 2003 2.4 GHz 54 Mbps Combines features of 802.11a/b, backward compatible - 802.11e 2005 2.4 GHz &amp; 5 GHz Up to 54 Mbps Quality of Service (QoS) for better multimedia &amp; VoIP support WMM (Wi-Fi Multimedia) 802.11n 2009 2.4 GHz &amp; 5 GHz 600 Mbps Introduced MIMO for better speed &amp; range - 802.11ac 2013 5 GHz only 3.5 Gbps Improved 802.11n with wider channels &amp; better performance Wi-Fi 5 802.11ac Wave 2 ~2016 5 GHz only 6.93 Gbps Added MU-MIMO technology &amp; enhancements - 802.11ad 2012 60 GHz 7 Gbps High-speed, short-range (WiGig) WiGig 802.11ah 2017 Below 900 MHz Lower Extended range, better wall penetration Wi-Fi HaLow 802.11r - - - Fast BSS transition for VoIP handoff between access points Fast Roaming 802.1X - - - Security standard for network access control -"},{"location":"mc-m2/#key-takeaways","title":"Key Takeaways","text":"<p>\u2705 Higher Frequencies (5 GHz, 60 GHz) \u2192 Higher speeds but shorter range \u2705 Lower Frequencies (2.4 GHz, Below 900 MHz) \u2192 Better range and penetration but lower speed \u2705 Newer Standards (802.11ac, 802.11ax, etc.) \u2192 Improved speed, efficiency, and multi-device support \u2705 Wi-Fi 5 (802.11ac) \u2192 Popular high-speed standard used today \u2705 Wi-Fi 6 (802.11ax - Not in table) \u2192 Next-gen standard improving speed, efficiency, and congestion handling  </p>"},{"location":"mc-m2/#wireless-lan-wlan","title":"Wireless LAN (WLAN)","text":""},{"location":"mc-m2/#what-is-wlan","title":"What is WLAN?","text":"<ul> <li>WLAN (Wireless Local Area Network) allows mobile users to connect to a Local Area Network (LAN) wirelessly.  </li> <li>Also known as LAWN (Local Area Wireless Network).  </li> <li>Defined by IEEE 802.11 standards.  </li> <li>Uses Ethernet protocol and CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance) for communication.  </li> <li>Implements WEP (Wired Equivalent Privacy) encryption for security.  </li> <li>Provides high-speed data communication in small areas (offices, buildings, etc.).  </li> <li>Used to reduce costs and avoid cable installation, especially in public areas.  </li> </ul>"},{"location":"mc-m2/#advantages-of-wlans","title":"Advantages of WLANs","text":"<ol> <li>Flexibility \ud83d\udedc  </li> <li>Devices can communicate without physical connections.  </li> <li> <p>Radio waves penetrate walls, allowing hidden placements.  </p> </li> <li> <p>Easy Planning \ud83c\udfd7\ufe0f  </p> </li> <li> <p>Wireless ad-hoc networks do not require pre-planning like wired networks.  </p> </li> <li> <p>Compact Design \ud83d\udcf1  </p> </li> <li> <p>Allows development of small, portable devices (laptops, tablets, PDAs).  </p> </li> <li> <p>Disaster Resilience \ud83c\udf2a\ufe0f  </p> </li> <li> <p>Works even in natural disasters where wired infrastructure might fail.  </p> </li> <li> <p>Cost Efficiency \ud83d\udcb0  </p> </li> <li>Cheaper installation and maintenance than traditional wired LANs.  </li> <li> <p>No extra cost for adding users after initial setup.  </p> </li> <li> <p>Ease of Use \ud83c\udfaf  </p> </li> <li>Simple setup for users, requiring minimal technical knowledge.  </li> </ol>"},{"location":"mc-m2/#disadvantages-of-wlans","title":"Disadvantages of WLANs","text":"<ol> <li>Quality of Service (QoS) Issues \u26a0\ufe0f  </li> <li>Lower bandwidth due to radio transmission limitations.  </li> <li>Higher error rates from interference.  </li> <li> <p>Increased latency due to error correction.  </p> </li> <li> <p>Proprietary Solutions \ud83d\udd0f  </p> </li> <li>Slow standardization leads to different vendor-specific solutions.  </li> <li> <p>Most systems adhere to IEEE 802.11a/b.  </p> </li> <li> <p>Regulatory Restrictions \ud83d\udea6  </p> </li> <li> <p>Governments impose frequency restrictions to avoid interference.  </p> </li> <li> <p>Global Operation Issues \ud83c\udf0d  </p> </li> <li>Frequency regulations differ across countries.  </li> <li> <p>Devices must comply with international standards.  </p> </li> <li> <p>High Power Consumption \ud83d\udd0b  </p> </li> <li>Wireless devices consume more power than wired ones.  </li> <li> <p>Requires power-saving modes for efficiency.  </p> </li> <li> <p>Licensing Requirements \ud83d\udcdc  </p> </li> <li>Operators prefer license-free bands like 2.4 GHz ISM band for easier deployment.  </li> </ol>"},{"location":"mc-m2/#conclusion","title":"Conclusion","text":"<p>\u2714 WLANs provide mobility, flexibility, and cost-effectiveness. \u274c They suffer from QoS issues, power constraints, and regulatory challenges. \ud83d\udca1 IEEE 802.11 continues to evolve, improving performance and security.  </p> <p>Would you like me to summarize any specific aspect further? \ud83d\ude0a</p>"},{"location":"mc-viva/","title":"Mc viva","text":""},{"location":"mc-viva/#summary-of-mobile-generations","title":"Summary of Mobile Generations","text":"Generation Technology Used Speed Key Features 1G AMPS (Analog) 2.4 kbps Voice calls, poor quality, no data 2G GSM &amp; CDMA 144 kbps Digital voice, SMS, MMS, basic internet 2.5G GPRS 64 \u2013 144 kbps Always-on internet, emails, camera phones 2.75G EDGE Up to 384 kbps Faster browsing, video streaming 3G WCDMA, HSPA Up to 2 Mbps Video calls, multimedia, web-based apps 4G LTE, WiMAX 10 Mbps \u2013 1 Gbps HD streaming, VoLTE, broadband connectivity 5G mmWave, MIMO Up to 20 Gbps Ultra-fast speeds, IoT, AI-powered networks"},{"location":"mc-viva/#mobile-architecture","title":"Mobile Architecture","text":""},{"location":"mc-viva/#experiment-1","title":"Experiment 1","text":""},{"location":"mc-viva/#1-how-will-user-interfaces-evolve-beyond-touch-and-voice-could-thought-based-interaction-become-a-reality-what-role-might-augmented-reality-play-in-the-future-of-mobile-computing-interfaces","title":"1. How will user interfaces evolve beyond touch and voice? Could thought-based interaction become a reality? What role might augmented reality play in the future of mobile computing interfaces?","text":"<p>Thought-Based Interaction includes Brain-Computer Interfaces (BCIs), which are a promising area of research. Advances in neural decoding and wearable EEG devices suggest that thought-based interactions could become a reality, allowing users to control devices directly with their thoughts. Early applications might include accessibility tools for people with disabilities, gaming, and hands-free control in AR/VR environments.</p> <p>Augmented Reality (AR) could revolutionize interfaces by overlaying contextual information onto the real world. With AR glasses and contact lenses, mobile computing might seamlessly blend physical and digital spaces, enabling hands-free interactions, holographic displays, and real-time guidance for tasks.</p>"},{"location":"mc-viva/#2-could-we-develop-a-truly-decentralized-mobile-network-that-operates-without-any-central-infrastructure","title":"2. Could we develop a truly decentralized mobile network that operates without any central infrastructure?","text":"<p>A fully decentralized mobile network is conceivable using technologies like:</p> <ul> <li>Mesh Networking: Devices communicate directly with each other, forming a peer-to-peer network without relying on centralized infrastructure.</li> <li>Blockchain: Securely manage identity, transactions, and bandwidth sharing in a decentralized system.</li> <li>Edge Computing: Offload processing to local devices or micro-data centers, reducing dependence on centralized servers.</li> </ul>"},{"location":"mc-viva/#3-how-could-mobile-networks-be-designed-to-remain-functional-during-major-disasters-or-in-extreme-environments-like-underwater-or-in-space","title":"3. How could mobile networks be designed to remain functional during major disasters or in extreme environments like underwater or in space?","text":""},{"location":"mc-viva/#mobile-networks-for-extreme-conditions","title":"Mobile Networks for Extreme Conditions","text":"<ul> <li>Disaster Scenarios: Networks like FirstNet and mesh-based systems can provide emergency communication during disasters. Deployable base stations and satellite uplinks are critical.</li> <li>Underwater Communication: Acoustic and optical communication technologies are being developed for underwater mobile networks, albeit with limited range and speed compared to terrestrial systems.</li> <li>Space Communication: Inter-satellite communication networks (ISL) and high-throughput satellites like Starlink can create reliable networks in space.</li> </ul>"},{"location":"mc-viva/#4-how-might-6g-technology-evolve-beyond-5g-and-what-new-applications-could-emerge-from-its-potential-capabilities","title":"4. How might 6G technology evolve beyond 5G, and what new applications could emerge from its potential capabilities?","text":"<p>Beyond 5G, 6G aims to deliver terabit-level speeds, ultra-low latency (&lt;1ms), and high energy efficiency. 6G could offer speeds up to 100 times faster than 5G.</p>"},{"location":"mc-viva/#features-and-potential-applications","title":"Features and Potential Applications:","text":"<ul> <li>Holographic communications for immersive telepresence.</li> <li>High-precision IoT for smart cities and autonomous systems.</li> <li>Real-time, AI-driven decision-making in sectors like healthcare and finance.</li> <li>Advanced AR/VR experiences with tactile feedback and ultra-high-resolution visuals.</li> </ul>"},{"location":"mc-viva/#5-what-are-the-potential-implications-of-mobile-computing-on-personal-privacy-and-how-can-we-balance-convenience-with-security-in-future-mobile-technologies","title":"5. What are the potential implications of mobile computing on personal privacy, and how can we balance convenience with security in future mobile technologies?","text":""},{"location":"mc-viva/#implications","title":"Implications:","text":"<p>Increased data collection by mobile devices raises concerns about surveillance, misuse of personal information, and identity theft.</p>"},{"location":"mc-viva/#solutions","title":"Solutions:","text":"<ul> <li>Privacy-by-Design: Embedding privacy principles into technology development.</li> <li>Decentralized Identity Systems: Users retain control over their digital identities.</li> <li>Encryption: End-to-end encryption for all communications and data storage.</li> <li>Regulation and Transparency: Stronger data protection laws and transparent policies on data usage.</li> <li>User Education: Empower users with tools and knowledge to manage their data and privacy settings effectively.</li> </ul>"},{"location":"mc-viva/#network-architecture","title":"Network architecture","text":"<p>Questions of Curiosity: 1.  Virtualized Networks and Cloud-Native Architectures: With virtualization and cloud-native architectures, components like the Base Station Controller (BSC) and Mobile Switching Center (MSC) could be moved to the cloud, offering more flexibility, scalability, and easier management of resources without the need for dedicated physical hardware. 2.  Artificial Intelligence Integration: AI could be integrated into these components to predict traffic patterns, optimize resource allocation, automate network management, and improve decision-making, leading to more efficient and responsive network operations. 3.  Support for Emerging Technologies: To support IoT and machine-to-machine communication, these components will evolve to handle massive device connections, low-latency communication, and efficient data routing, ensuring that networks can manage a higher volume of devices and more diverse traffic. 4.  Security Challenges: The distributed nature of these components increases vulnerability to cyberattacks and data breaches. Future implementations could address this by incorporating advanced encryption, real-time monitoring, and decentralized security protocols to ensure data integrity and network protection.</p>"},{"location":"mc-viva/#cellular-architecture","title":"\ud83d\udce1 Cellular Architecture","text":"<p>The cellular network is structured in a hierarchical way to provide efficient communication across large geographical areas.  </p> <p> </p> <p>\ud83d\udd39 Key Components: \u2705 Mobile Device (User Equipment) \u2013 Phones, tablets, or IoT devices. \u2705 Base Transceiver Station (BTS) \u2013 Handles wireless communication with mobile devices. \u2705 Base Station Controller (BSC) \u2013 Manages multiple BTS and assigns frequencies. \u2705 Mobile Switching Center (MSC) \u2013 Connects mobile calls and manages handovers. \u2705 Public Switched Telephone Network (PSTN) \u2013 Traditional wired telephone network. \u2705 Packet Data Network (Internet) \u2013 Allows mobile data access and browsing. \u2705 Cell Towers \u2013 Divides the service area into small cells to provide coverage.  </p>"},{"location":"mc-viva/#mode-of-communications","title":"Mode of Communications","text":"<pre><code>graph TD;\n\n    subgraph Circuit-Switched Network\n        A((User A)) -- Dedicated Path --&gt; B((User B))\n    end\n\n    subgraph Packet-Switched Network\n        A1((User C)) -- Packet 1 --&gt; C1[Router] --&gt; D1((User D))\n        A1 -- Packet 2 --&gt; C2[Router] --&gt; D1\n        A1 -- Packet 3 --&gt; C3[Router] --&gt; D1\n    end</code></pre>"},{"location":"mc-viva/#questions-of-curiosity","title":"Questions of Curiosity","text":""},{"location":"mc-viva/#1-factors-affecting-call-blocking-probability","title":"1. Factors Affecting Call Blocking Probability","text":"<p>Call blocking probability (CBP) depends on network load, resource availability, user density, traffic patterns, call setup efficiency, and handover management. High congestion, inadequate spectrum, and poor mobility handling increase CBP, especially in urban areas.</p>"},{"location":"mc-viva/#2-impact-of-network-slicing-on-cbp","title":"2. Impact of Network Slicing on CBP","text":"<p>Network slicing optimizes resource allocation by creating virtual networks for different use cases. It ensures priority for critical services, enhances QoS, and isolates traffic, reducing congestion and minimizing call blocking.</p>"},{"location":"mc-viva/#3-industry-benchmarks-for-call-blocking","title":"3. Industry Benchmarks for Call Blocking","text":"<p>Industry standards, such as ITU and 3GPP, recommend CBP levels below 2% for quality service, with 4G networks aiming for ~1%. Newer technologies like 5G set even lower targets to ensure high reliability and low latency.</p>"},{"location":"mc-viva/#4-geographical-influence-on-cbp","title":"4. Geographical Influence on CBP","text":"<p>Urban areas experience high CBP due to user density, while rural areas suffer from inadequate infrastructure. Factors like peak-hour traffic, signal obstructions, and sparse cell coverage also impact call blocking rates.</p>"},{"location":"mc-viva/#5-strategies-to-reduce-cbp","title":"5. Strategies to Reduce CBP","text":"<p>Minimization strategies include: - Cell Load Balancing: Redistributes traffic to avoid congestion. - Advanced Technologies: Carrier aggregation, MIMO, and small cells improve spectrum efficiency. - Alternative Networks: Wi-Fi/5G offloading reduces macro network strain. - AI-Driven Optimization: Predictive resource management mitigates congestion proactively.</p>"},{"location":"mc-viva/#6-hidden-node-problem-and-avoidance-strategies","title":"6. Hidden Node Problem and Avoidance Strategies","text":""},{"location":"mc-viva/#what-are-the-ways-in-which-hidden-node-problems-are-avoided","title":"What are the ways in which hidden node problems are avoided?","text":"<ul> <li>RTS/CTS Mechanism: The Request To Send/Clear To Send (RTS/CTS) protocol helps prevent collisions by coordinating node transmissions.</li> <li>Increasing Transmission Power: Extending node communication range can reduce hidden node occurrences.</li> <li>Using Omnidirectional Antennas: Ensures better connectivity among nodes.</li> <li>Node Relocation: Physically repositioning nodes enhances communication.</li> <li>Protocol Enhancements: Polling and token-passing strategies improve medium access management.</li> </ul>"},{"location":"mc-viva/#what-is-the-exposed-node-problem-how-can-you-avoid-this","title":"What is the exposed node problem? How can you avoid this?","text":"<ul> <li>Definition: The exposed node problem occurs when a node refrains from sending packets due to perceived interference, even when transmission is possible.</li> <li>Avoidance Strategies:</li> <li>Carrier Sense Multiple Access (CSMA): Helps avoid unnecessary transmission blocking.</li> <li>RTS/CTS Mechanism: Coordinates transmissions to minimize interference.</li> </ul>"},{"location":"mc-viva/#how-does-the-hidden-node-problem-impact-different-types-of-network-traffic","title":"How does the hidden node problem impact different types of network traffic?","text":"<ul> <li>Real-time Video Traffic: Sensitive to delays and packet loss, leading to degraded quality.</li> <li>File Transfer Traffic: Collisions cause retransmissions, slowing down transfer rates.</li> </ul>"},{"location":"mc-viva/#what-role-does-transmission-power-control-play-in-mitigating-hidden-node-problems","title":"What role does transmission power control play in mitigating hidden node problems?","text":"<ul> <li>Adjusting power levels helps nodes detect each other, reducing hidden node occurrences while managing interference.</li> </ul>"},{"location":"mc-viva/#how-do-different-wireless-standards-80211abgnac-handle-the-hidden-node-problem-differently","title":"How do different wireless standards (802.11a/b/g/n/ac) handle the hidden node problem differently?","text":"Standard Handling Method 802.11a Uses RTS/CTS; limited effectiveness due to shorter range. 802.11b RTS/CTS implementation; better range but still vulnerable. 802.11g RTS/CTS support with backward compatibility; performance varies. 802.11n MIMO technology enhances range and mitigates hidden node issues. 802.11ac Beamforming and MIMO optimize signal paths, reducing problems."},{"location":"mc-viva/#1-if-we-modified-the-simulation-to-include-bidirectional-traffic-where-wireless-nodes-communicate-with-each-other-instead-of-just-with-node-1-how-would-this-affect-network-congestion-and-overall-performance-propose-a-test-setup-to-compare-unidirectional-vs-bidirectional-communication-patterns-with-the-same-number-of-nodes","title":"1. If we modified the simulation to include bidirectional traffic (where wireless nodes communicate with each other instead of just with Node 1), how would this affect network congestion and overall performance? Propose a test setup to compare unidirectional vs bidirectional communication patterns with the same number of nodes.","text":"<p>Effect: Bidirectional traffic would increase network congestion due to the added communication paths between nodes, leading to higher contention for bandwidth. It could also introduce delays due to more frequent collisions or retransmissions.</p> <p>Test Setup: Compare unidirectional vs. bidirectional traffic with the same number of nodes, measuring throughput, delay, and packet loss for both configurations. Use the same traffic load and node density in both setups to ensure a fair comparison.</p>"},{"location":"mc-viva/#2-how-would-implementing-different-packet-sizes-in-the-application-properties-affect-network-performance-across-the-varying-number-of-nodes-design-a-test-scenario-to-compare-the-impact-of-small-256-bytes-versus-large-1500-bytes-packet-sizes-on-throughput-and-delay","title":"2. How would implementing different packet sizes in the application properties affect network performance across the varying number of nodes? Design a test scenario to compare the impact of small (256 bytes) versus large (1500 bytes) packet sizes on throughput and delay.","text":"<p>Effect: Larger packet sizes (1500 bytes) would typically result in higher throughput but could cause longer delays due to increased transmission time. Smaller packets (256 bytes) result in lower throughput but might offer better responsiveness with reduced latency.</p> <p>Test Scenario: Set up two scenarios with varying packet sizes: one with 256-byte packets and the other with 1500-byte packets. Measure throughput and delay while increasing the number of nodes to observe the impact of packet size on network performance.</p>"},{"location":"mc-viva/#3-what-impact-would-environmental-factors-like-walls-interference-from-other-devices-or-distance-between-nodes-have-on-the-network-performance-if-we-had-enabled-path-loss-in-the-wireless-link-properties-how-does-this-relate-to-real-world-implementations","title":"3. What impact would environmental factors (like walls, interference from other devices, or distance between nodes) have on the network performance if we had enabled path loss in the wireless link properties? How does this relate to real-world implementations?","text":"<p>Effect: Environmental factors like walls, interference, or distance can significantly affect signal strength, leading to higher packet loss and reduced throughput. Path loss models simulate this by weakening the signal based on distance and obstacles.</p> <p>Real-world Relation: This mimics real-world wireless networks, where physical obstructions and interference reduce communication quality and range, thus affecting performance (e.g., in offices, homes, or urban areas).</p>"},{"location":"mc-viva/#4-why-was-tcp-disabled-in-the-transport-layer-for-this-experiment-how-would-the-results-differ-if-tcp-was-enabled-and-what-additional-network-characteristics-would-we-be-able-to-observe","title":"4. Why was TCP disabled in the transport layer for this experiment? How would the results differ if TCP was enabled, and what additional network characteristics would we be able to observe?","text":"<p>Reason for Disablement: TCP was likely disabled to focus on the raw performance of the network layer without the influence of transport layer reliability (e.g., retransmissions, congestion control).</p> <p>Effect of Enabling TCP: If TCP were enabled, we would see added overhead due to retransmissions and flow control, possibly lowering throughput but improving reliability and reducing packet loss. We could also observe network congestion more clearly.</p>"},{"location":"mc-viva/#5-if-we-enable-path-loss-in-wireless-link-properties-how-would-it-affect-the-number-of-successful-transmissions","title":"5. If we enable path loss in wireless link properties, how would it affect the number of successful transmissions?","text":"<p>Impact: Path loss would result in fewer successful transmissions as the signal strength diminishes with distance and obstacles. This would likely increase packet loss and require more retransmissions, reducing overall network efficiency.</p>"},{"location":"mc-viva/#network-performance-analysis","title":"Network Performance Analysis","text":""},{"location":"mc-viva/#1-effect-of-bidirectional-traffic-on-network-congestion-and-performance","title":"1. Effect of Bidirectional Traffic on Network Congestion and Performance","text":"<p>Effect: Bidirectional traffic would increase network congestion due to the added communication paths between nodes, leading to higher contention for bandwidth. It could also introduce delays due to more frequent collisions or retransmissions.</p> <p>Test Setup: Compare unidirectional vs. bidirectional traffic with the same number of nodes, measuring throughput, delay, and packet loss for both configurations. Use the same traffic load and node density in both setups to ensure a fair comparison.</p>"},{"location":"mc-viva/#2-impact-of-different-packet-sizes-on-network-performance","title":"2. Impact of Different Packet Sizes on Network Performance","text":"<p>Effect: Larger packet sizes (1500 bytes) would typically result in higher throughput but could cause longer delays due to increased transmission time. Smaller packets (256 bytes) result in lower throughput but might offer better responsiveness with reduced latency.</p> <p>Test Scenario: Set up two scenarios with varying packet sizes: one with 256-byte packets and the other with 1500-byte packets. Measure throughput and delay while increasing the number of nodes to observe the impact of packet size on network performance.</p>"},{"location":"mc-viva/#3-impact-of-environmental-factors-with-path-loss-enabled","title":"3. Impact of Environmental Factors with Path Loss Enabled","text":"<p>Effect: Environmental factors like walls, interference, or distance can significantly affect signal strength, leading to higher packet loss and reduced throughput. Path loss models simulate this by weakening the signal based on distance and obstacles.</p> <p>Real-world Relation: This mimics real-world wireless networks, where physical obstructions and interference reduce communication quality and range, thus affecting performance (e.g., in offices, homes, or urban areas).</p>"},{"location":"mc-viva/#4-disabling-tcp-in-the-transport-layer","title":"4. Disabling TCP in the Transport Layer","text":"<p>Reason for Disablement: TCP was likely disabled to focus on the raw performance of the network layer without the influence of transport layer reliability (e.g., retransmissions, congestion control).</p> <p>Effect of Enabling TCP: If TCP were enabled, we would see added overhead due to retransmissions and flow control, possibly lowering throughput but improving reliability and reducing packet loss. We could also observe network congestion more clearly.</p>"},{"location":"mc-viva/#5-effect-of-path-loss-on-successful-transmissions","title":"5. Effect of Path Loss on Successful Transmissions","text":"<p>Impact: Path loss would result in fewer successful transmissions as the signal strength diminishes with distance and obstacles. This would likely increase packet loss and require more retransmissions, reducing overall network efficiency.</p>"},{"location":"mobile-computing-copy/","title":"Mobile computing copy","text":""},{"location":"mobile-computing-copy/#unit-1","title":"Unit 1","text":""},{"location":"mobile-computing-copy/#mobile-computing","title":"Mobile Computing","text":""},{"location":"mobile-computing-copy/#what-is-mobile-computing","title":"What is Mobile Computing?","text":"<p>Mobile computing is a technology that enables the wireless transmission of data, voice, and video through mobile devices without relying on fixed physical connections.  </p>"},{"location":"mobile-computing-copy/#main-components-of-mobile-computing","title":"Main Components of Mobile Computing","text":"<p>\u2705 Mobile Communication - Involves protocols, services, bandwidth, and portals that enable seamless connectivity. - Supports wireless communication over Wi-Fi, Cellular Networks (3G, 4G, 5G), and Bluetooth.  </p> <p>\u2705 Mobile Hardware - Includes portable devices that access mobility services:   - Smartphones \ud83d\udcf1   - Tablets   - Laptops   - Personal Digital Assistants (PDAs)   - Wearable Devices \u231a  </p> <p>\u2705 Mobile Software - Operating systems and applications that run on mobile devices. - Examples: Android, iOS, Windows Mobile, Mobile Web Browsers, and Apps. - Acts as the engine that powers mobile functionalities.  </p>"},{"location":"mobile-computing-copy/#applications-of-mobile-computing","title":"Applications of Mobile Computing","text":"<p>\u2705 Web &amp; Internet Access \u2013 Enables browsing, cloud computing, and real-time communication. \u2705 Global Positioning System (GPS) \u2013 Provides navigation, tracking, and geolocation services. \u2705 Emergency Services \u2013 Supports disaster response, medical alerts, and real-time rescue coordination. \u2705 Entertainment Services \u2013 Powers mobile gaming, streaming platforms, and digital media. \u2705 Educational Services \u2013 Supports e-learning, mobile classrooms, and virtual collaboration.  </p>"},{"location":"mobile-computing-copy/#evolution-of-mobile-computing","title":"Evolution of Mobile Computing","text":"<p>The evolution of mobile generations (G) marks advancements in speed, technology, frequency, data capacity, and latency, revolutionizing communication and connectivity.  </p>"},{"location":"mobile-computing-copy/#first-generation-1g-analog-communication","title":"\ud83d\udce1 First Generation (1G) \u2013 Analog Communication","text":"<p>\ud83d\udcc5 Introduced: 1980s \u2013 1990s \ud83d\udccc Technology Used: AMPS (Advanced Mobile Phone System), based on FDMA \u26a1 Speed: 2.4 kbps </p> <p>\u2705 Features: - Allowed voice calls but limited to one country. - Used analog signals, leading to poor voice quality and frequent call drops. - Weak battery life and limited network capacity. - No data services, only voice communication.  </p>"},{"location":"mobile-computing-copy/#second-generation-2g-digital-communication","title":"\ud83d\udcf2 Second Generation (2G) \u2013 Digital Communication","text":"<p>\ud83d\udcc5 Introduced: 1990s \ud83d\udccc Technology Used: GSM &amp; CDMA \u26a1 Speed: Up to 144 kbps </p> <p>\u2705 Features: - Digital signals replaced analog, improving voice clarity. - Introduced SMS &amp; MMS for text and picture messaging. - Enabled conference calling, call hold, and international roaming. - Used circuit-switched and packet-switched networks. - Introduced GPRS (General Packet Radio Service), achieving speeds of 50 kbps to 1 Mbps.  </p>"},{"location":"mobile-computing-copy/#transition-from-2g-to-3g-25g-275g","title":"\ud83d\udcf6 Transition from 2G to 3G: 2.5G &amp; 2.75G","text":""},{"location":"mobile-computing-copy/#25g-gprs-general-packet-radio-service","title":"2.5G (GPRS \u2013 General Packet Radio Service)","text":"<p>\ud83d\udccc Technology Used: GSM with GPRS \u26a1 Speed: 64 \u2013 144 kbps </p> <p>\u2705 Improvements Over 2G: - Introduced always-on internet access. - Enabled email, basic web browsing, and multimedia messaging (MMS). - Used packet-switched data, improving efficiency. - Lower latency than 2G. - Introduction of camera phones.  </p>"},{"location":"mobile-computing-copy/#275g-edge-enhanced-data-rates-for-gsm-evolution","title":"2.75G (EDGE \u2013 Enhanced Data rates for GSM Evolution)","text":"<p>\ud83d\udccc Technology Used: GSM with EDGE (Enhanced GPRS) \u26a1 Speed: Up to 384 kbps </p> <p>\u2705 Enhancements Over 2.5G: - Faster data transmission, enabling video streaming and online gaming. - More efficient spectrum usage, improving network performance. - Served as a stepping stone to 3G, enhancing mobile internet and multimedia communication.  </p> <p>\ud83d\ude80 2.5G and 2.75G bridged the gap between traditional mobile calling and the era of high-speed mobile internet! </p>"},{"location":"mobile-computing-copy/#third-generation-3g-high-speed-mobile-data","title":"\ud83d\udce1 Third Generation (3G) \u2013 High-Speed Mobile Data","text":"<p>\ud83d\udcc5 Introduced: 2000s \ud83d\udccc Technology Used: WCDMA, HSPA (High-Speed Packet Access) \u26a1 Speed: Up to 2 Mbps </p> <p>\u2705 Features: - Enabled web browsing, email, video downloads, and picture sharing. - Provided support for multimedia applications, including video calling. - Increased bandwidth and data transfer rates for improved web-based applications. - Improved voice clarity and reduced latency compared to 2G.  </p>"},{"location":"mobile-computing-copy/#fourth-generation-4g-high-speed-broadband-connectivity","title":"\u26a1 Fourth Generation (4G) \u2013 High-Speed Broadband Connectivity","text":"<p>\ud83d\udcc5 Introduced: 2010s \ud83d\udccc Technology Used: LTE (Long-Term Evolution), WiMAX \u26a1 Speed: 10 Mbps \u2013 1 Gbps </p> <p>\u2705 Features: - Ultra-fast data speeds with peak downloads of 100 Mbps. - Supported high-quality streaming for HD video and VoIP (Voice over IP). - Introduced IP-based telephony (VoLTE) for improved call quality. - Combination of Wi-Fi and WiMAX for broader coverage. - Enhanced security and reliability in mobile communication.  </p>"},{"location":"mobile-computing-copy/#fifth-generation-5g-the-future-of-mobile-connectivity","title":"\ud83d\udce1 Fifth Generation (5G) \u2013 The Future of Mobile Connectivity","text":"<p>\ud83d\udcc5 Introduced: 2020s \ud83d\udccc Technology Used: mmWave, Massive MIMO, Network Slicing \u26a1 Speed: Up to 20 Gbps </p> <p>\u2705 Key Advancements Over 4G: - Higher Data Rates \u2013 Up to 20 Gbps for ultra-fast downloads and real-time communication. - Lower Latency \u2013 Reduced response time, essential for real-time gaming, augmented reality (AR), and virtual reality (VR). - Increased Network Capacity \u2013 Supports massive IoT (Internet of Things) connections. - Improved Reliability \u2013 Network slicing allows dedicated networks for specific applications.  </p> <p>\ud83d\udccc Summary of Mobile Generations </p> Generation Technology Used Speed Key Features 1G AMPS (Analog) 2.4 kbps Voice calls, poor quality, no data 2G GSM &amp; CDMA 144 kbps Digital voice, SMS, MMS, basic internet 2.5G GPRS 64 \u2013 144 kbps Always-on internet, emails, camera phones 2.75G EDGE Up to 384 kbps Faster browsing, video streaming 3G WCDMA, HSPA Up to 2 Mbps Video calls, multimedia, web-based apps 4G LTE, WiMAX 10 Mbps \u2013 1 Gbps HD streaming, VoLTE, broadband connectivity 5G mmWave, MIMO Up to 20 Gbps Ultra-fast speeds, IoT, AI-powered networks"},{"location":"mobile-computing-copy/#cellular-architecture","title":"\ud83d\udce1 Cellular Architecture","text":"<p>The cellular network is structured in a hierarchical way to provide efficient communication across large geographical areas.  </p> <p> </p> <p>\ud83d\udd39 Key Components: \u2705 Mobile Device (User Equipment) \u2013 Phones, tablets, or IoT devices. \u2705 Base Transceiver Station (BTS) \u2013 Handles wireless communication with mobile devices. \u2705 Base Station Controller (BSC) \u2013 Manages multiple BTS and assigns frequencies. \u2705 Mobile Switching Center (MSC) \u2013 Connects mobile calls and manages handovers. \u2705 Public Switched Telephone Network (PSTN) \u2013 Traditional wired telephone network. \u2705 Packet Data Network (Internet) \u2013 Allows mobile data access and browsing. \u2705 Cell Towers \u2013 Divides the service area into small cells to provide coverage.  </p> <p>Note</p> <p>Mode of Communications</p> <pre><code>graph TD;\n\n    subgraph Circuit-Switched Network\n        A((User A)) -- Dedicated Path --&gt; B((User B))\n    end\n\n    subgraph Packet-Switched Network\n        A1((User C)) -- Packet 1 --&gt; C1[Router] --&gt; D1((User D))\n        A1 -- Packet 2 --&gt; C2[Router] --&gt; D1\n        A1 -- Packet 3 --&gt; C3[Router] --&gt; D1\n    end</code></pre>"},{"location":"mobile-computing-copy/#mobile-computing-architecture","title":"Mobile Computing Architecture","text":"<p>Mobile computing architecture ensures seamless communication, data management, and user interaction, making applications efficient and scalable.  </p>"},{"location":"mobile-computing-copy/#location-based-services-lbs","title":"\ud83d\udccd Location-Based Services (LBS)","text":"<p>\u2705 Location-Aware Services - Identify available services like printers, fax machines, phones, and servers in the local environment.  </p> <p>\u2705 Follow-On Services - Automatic call forwarding and workspace transmission to the user\u2019s current location.  </p> <p>\u2705 Information Services - Push: Automatic alerts (e.g., special offers in a supermarket). - Pull: User-requested data (e.g., where can I find my favorite pastry?).  </p> <p>\u2705 Support Services - Maintains cache, session state, and intermediate results, allowing smooth mobility.  </p> <p>\u2705 Privacy Management - Controls who has access to location information.  </p>"},{"location":"mobile-computing-copy/#three-tier-mobile-computing-architecture","title":"Three-Tier Mobile Computing Architecture","text":""},{"location":"mobile-computing-copy/#breakdown-of-the-three-tier-architecture","title":"\ud83d\udee0 Breakdown of the Three-Tier Architecture","text":"<p>\u2705 \ud83d\udcf2 Tier-1: Presentation Layer (User Interface) - Where users interact with the mobile app. - Handles buttons, menus, forms, and screens. - Supports multiple users simultaneously.  </p> <p>\u2705 \ud83c\udf10 Connection Layer (Access Network) - Routes traffic between user devices and the backend system. - Adapts to different devices and network conditions. - Ensures efficient data transmission even if one route fails.  </p> <p>\u2705 \u2699\ufe0f Tier-2: Application Layer - Process Management \u2013 Organizes tasks and workflows (e.g., food ordering steps). - Business Logic \u2013 Enforces rules and decision-making (e.g., price calculations, discounts).  </p> <p>\u2705 \ud83d\udcbe Tier-3: Data Layer - Database Management \u2013 Organizes data storage and retrieval (like a librarian). - Data Store \u2013 The actual storage where information is kept (like a bookshelf).  </p>"},{"location":"mobile-computing-copy/#why-this-design","title":"\ud83d\udccc Why This Design?","text":"<p>\u2705 Scalability: More users can be handled by expanding any layer. \u2705 Reliability: If one component fails, others continue functioning. \u2705 Flexibility: Different layers can be updated or fixed independently. \u2705 Adaptability: Works well on various devices and network conditions.  </p>"},{"location":"mobile-computing-copy/#real-world-analogy-a-restaurant-setup","title":"\ud83d\udccd Real-World Analogy \u2013 A Restaurant Setup \ud83c\udf7d\ufe0f","text":"Layer Restaurant Example Presentation Tier The dining area where customers interact with waiters. Access Network The waiters who take orders to the kitchen. Application Tier The kitchen where food is prepared based on orders. Data Tier The pantry where ingredients are stored."},{"location":"mobile-computing-copy/#unit-2","title":"Unit 2","text":""},{"location":"mobile-computing-copy/#concept-of-multiplexing","title":"Concept of Multiplexing","text":"<p>Multiplexing is a key technique in communication systems that allows multiple users to share a single medium with minimal or no interference.</p>"},{"location":"mobile-computing-copy/#real-life-analogy","title":"Real-Life Analogy","text":"<p>Highways as a Shared Medium: - Multiple vehicles (users) travel on the same highway (medium) without interference. - Space Division Multiplexing (SDM): Cars use separate lanes. - Time Division Multiplexing (TDM): Cars use the same lane at different times.</p>"},{"location":"mobile-computing-copy/#medium-access-control-mac-protocols","title":"\ud83d\udee0 Medium Access Control (MAC) Protocols","text":"<ul> <li>\u2705 What is MAC?</li> </ul> <p>A sublayer of the Data Link Layer responsible for coordinating transmissions between multiple nodes.</p> <p></p> <p>Data link layer divided into two functionality-oriented sublayers</p>"},{"location":"mobile-computing-copy/#the-mac-problem-in-wireless-networks","title":"\u26a1 The MAC Problem in Wireless Networks","text":"<p>\ud83d\udccc When multiple nodes transmit simultaneously, their signals collide, causing:</p> <p>Lost data and wasted bandwidth.</p> <p>Increased retransmissions, leading to higher delays and lower efficiency.</p> <p>\ud83d\udccc Solution? Use a protocol to manage access to the shared medium.</p> <p>\u2705 What MAC Protocols Must Do:</p> <ul> <li>Minimize Collisions to optimize bandwidth usage.</li> <li>Decide when a station can transmit to avoid conflicts.</li> <li>Handle busy channels by deciding whether to wait or retransmit.</li> <li>Resolve collisions efficiently to ensure smooth data transmission.</li> </ul> <p>Here is the Mermaid diagram representation of Multiple Access Protocols along with a brief explanation for each type:  </p> <pre><code>graph TD;\n\n    A[Multiple-Access Protocols] --&gt; B[Random Access Protocols]\n    A --&gt; C[Controlled-Access Protocols]\n    A --&gt; D[Channelization Protocols]\n\n    B --&gt; B1[ALOHA]\n    B --&gt; B2[CSMA]\n    B --&gt; B3[CSMA/CD]\n    B --&gt; B4[CSMA/CA]\n\n    C --&gt; C1[Reservation]\n    C --&gt; C2[Polling]\n    C --&gt; C3[Token Passing]\n\n    D --&gt; D1[FDMA]\n    D --&gt; D2[TDMA]\n    D --&gt; D3[CDMA]</code></pre> <p>\u2705 Random Access Protocols (No fixed control, contention-based): - ALOHA \u2013 Transmits data randomly; high collision rate. - CSMA (Carrier Sense Multiple Access) \u2013 Senses channel before sending data to reduce collisions. - CSMA/CD (Collision Detection) \u2013 Detects collisions and retransmits (used in Ethernet). - CSMA/CA (Collision Avoidance) \u2013 Avoids collisions before transmission (used in Wi-Fi).  </p> <p>\u2705 Controlled-Access Protocols (Centralized control, avoids collisions): - Reservation \u2013 Nodes reserve slots before transmission. - Polling \u2013 Central controller decides which node transmits. - Token Passing \u2013 A token circulates, granting transmission rights.  </p> <p>\u2705 Channelization Protocols (Divide channel into separate logical paths): - FDMA (Frequency Division Multiple Access) \u2013 Assigns different frequencies to users. - TDMA (Time Division Multiple Access) \u2013 Allocates time slots to users. - CDMA (Code Division Multiple Access) \u2013 Uses unique codes for simultaneous transmissions.  </p>"},{"location":"mobile-computing-copy/#medium-access-in-wireline-vs-wireless-networks","title":"Medium Access in Wireline vs. Wireless Networks","text":""},{"location":"mobile-computing-copy/#medium-access-in-wireline-networks-csmacd","title":"\ud83d\udce1 Medium Access in Wireline Networks (CSMA/CD)","text":"<p>\u2705 Assumptions: - Signal strength remains constant across the wire. - Same signal strength can be assumed throughout if the wire length is within standard limits. - Collisions can be detected by any node listening to the wire.  </p> <p>\u2705 CSMA/CD (Carrier Sense Multiple Access with Collision Detection) Operation: 1. Carrier Sense \u2013 Listen to the wire; if free, send data. 2. Collision Detection \u2013 If a collision is detected while transmitting, stop immediately and send a jam signal to notify all nodes.  </p> <p>\ud83d\udd39 Why CSMA/CD Works Well in Wired Networks? - The signal condition is the same across the medium. - Collisions are easily detectable, ensuring efficient retransmission.  </p>"},{"location":"mobile-computing-copy/#medium-access-in-wireless-networks-csmaca","title":"\ud83d\udcf6 Medium Access in Wireless Networks (CSMA/CA)","text":"<p>\u2705 Challenges in Wireless Medium: - Signal strength varies due to distance and obstacles. - Attenuation follows the inverse square law (\\( 1/d^2 \\)), weakening signals over distance. - Collisions at the receiver cannot be detected by simply listening to the medium.  </p> <p>\u2705 CSMA/CD Issues in Wireless: 1. Carrier Sense \u2013 The sender may detect an idle medium, but the receiver may still experience a collision. 2. Collision Detection \u2013 The sender cannot always detect a collision at the receiver\u2019s end.  </p> <p>\ud83d\udd39 Why CSMA/CD Fails in Wireless? - Wireless nodes have different perspectives of the medium. - The hidden terminal problem causes undetected collisions. - Instead, wireless networks use CSMA/CA (Collision Avoidance) to prevent collisions before they happen.  </p>"},{"location":"mobile-computing-copy/#wireless-medium-access-problems","title":"Wireless Medium Access Problems","text":"<p>Wireless networks face unique challenges due to signal interference, attenuation, and variable reception.  </p>"},{"location":"mobile-computing-copy/#hidden-terminal-problem","title":"Hidden Terminal Problem","text":"<p>Scenario: - A and C cannot hear each other but are both within B\u2019s range. - A starts transmitting to B. - C senses the medium as free (since it cannot hear A) and starts transmitting to B at the same time. - A collision occurs at B, but neither A nor C detects it.  </p> <p>Cause: - Other senders are hidden from the current sender, leading to undetected collisions.  </p> <p>Solution: - The RTS/CTS (Request to Send / Clear to Send) mechanism helps avoid hidden terminal issues by coordinating access.  </p> <p></p>"},{"location":"mobile-computing-copy/#exposed-terminal-problem","title":"Exposed Terminal Problem","text":"<p>Scenario: - B is transmitting to A. - C senses the medium as busy because B is transmitting. - However, C could have transmitted to D without causing a collision. - C unnecessarily defers its transmission, reducing network efficiency.  </p> <p>Cause: - The sender mistakenly assumes the medium is in use, leading to wasted transmission opportunities.  </p> <p>Solution: - Spatial reuse techniques allow simultaneous non-interfering transmissions.  </p> <pre><code>\nsequenceDiagram\n    participant R1 as R\u2081 (Receiver 1)\n    participant S1 as S\u2081 (Sender 1)\n    participant S2 as S\u2082 (Sender 2)\n    participant R2 as R\u2082 (Receiver 2)\n\n    Note over S1,R1: 1. Initial Communication Setup\n    S1-&gt;&gt;R1: Request to Send (RTS)\n    R1-&gt;&gt;S1: Clear to Send (CTS)\n\n    Note over S1,R1: 2. Data Transfer Begins\n    S1-&gt;&gt;R1: DATA Transmission\n\n    Note over S2,R2: Medium is Busy\n    S2--xR2: Waiting for Clear Medium\n\n    Note over S1,R1: 3. Successful Data Transfer\n    activate S1\n    activate R1\n    Note over S1,R1: Data Transfer Complete\n    deactivate S1\n    deactivate R1\n\n    Note over S2,R2: Medium is Now Clear</code></pre>"},{"location":"mobile-computing-copy/#nearfar-terminal-problem","title":"Near/Far Terminal Problem","text":"<p>Scenario: - B is closer to C than A. - B\u2019s stronger signal overpowers A\u2019s weaker signal at C. - C cannot receive A\u2019s transmission properly, causing data loss.  </p> <p>Cause: - Signal strength imbalance leads to weaker signals being drowned out by stronger ones.  </p> <p>Solution: - Power control mechanisms ensure all terminals are detectable at the base station. - GSM avoids the problem by using time slots (TDMA), preventing simultaneous transmission. - CDMA uses power control so all signals arrive at the receiver with equal strength.  </p> <p></p>"},{"location":"mobile-computing-copy/#multiplexing","title":"Multiplexing","text":"<p>Wireless channels can be multiplexed in four key dimensions:</p> <ol> <li>Time (t): A channel occupies the entire frequency spectrum for a specific time period.</li> <li>Space (s): The same frequency can be reused if base stations are sufficiently separated.</li> <li>Frequency (f): The spectrum is divided into smaller frequency bands.</li> <li>Code (c): Each channel is assigned a unique code for transmission.</li> </ol>"},{"location":"mobile-computing-copy/#space-division-multiplexing-sdm","title":"Space Division Multiplexing (SDM)","text":"<ul> <li>SDM involves separating channels in three dimensions: Code, Time, and Frequency.</li> <li>The Space dimension is represented by circles indicating interference ranges.</li> <li>To prevent overlap, channels are mapped to separate spaces (s1 to s3). This creates \"guard space\" between channels.</li> <li>Channels k1 to k3 are clearly separated, while additional spaces are needed for channels k4 to k6.</li> <li>This principle is similar to how old analog phone systems provided separate copper wires for each subscriber.</li> </ul>"},{"location":"mobile-computing-copy/#example-fm-radio","title":"Example: FM Radio","text":"<ul> <li>Multiple radio stations can use the same frequency without interference, as long as they are separated geographically.</li> </ul>"},{"location":"mobile-computing-copy/#key-takeaways","title":"Key Takeaways:","text":"<ul> <li>Guard space: Needed in all multiplexing schemes to prevent interference.</li> <li>SDM: Effective for localized transmissions like FM radio but not scalable for dense urban areas.</li> </ul> <p>Note</p> <p>If several radio stations want to broadcast in the same city - Solution?</p> <p>SDM not suitable </p> <p>Solution:</p> <p>Multiplexing through</p> <p>Frequency</p> <p>Time</p> <p>Code</p>"},{"location":"mobile-computing-copy/#frequency-division-multiplexing-fdm","title":"Frequency Division Multiplexing (FDM)","text":"<p>Frequency Division Multiplexing (FDM) divides the frequency dimension into several non-overlapping frequency bands. Each channel \\(k_i\\) is assigned a specific frequency band, which can be used continuously by the sender.</p> <ul> <li>Guard Spaces: Essential to prevent frequency band overlap (also called adjacent channel interference).</li> <li>Example: Used by radio stations within the same region, where each station broadcasts on its own frequency.</li> </ul> <p></p>"},{"location":"mobile-computing-copy/#how-fdm-works","title":"How FDM Works","text":"<ul> <li>Simple Scheme: The receiver only needs to tune into the specific frequency assigned to the sender.</li> <li>Usage: Common in systems like radio broadcasting, where multiple stations use different frequencies to avoid interference.</li> </ul>"},{"location":"mobile-computing-copy/#advantages-of-fdm","title":"Advantages of FDM","text":"<ul> <li>Simplicity: Very simple to implement, as it requires minimal coordination between the sender and receiver.</li> <li>Continuous Use: Each sender can use its frequency band continuously, making it suitable for applications like radio broadcasting.</li> </ul>"},{"location":"mobile-computing-copy/#disadvantages-of-fdm","title":"Disadvantages of FDM","text":"<ul> <li>Frequency Resource Waste: In mobile communication, where communication is short-term, dedicating an entire frequency band to each scenario would waste valuable frequency resources.</li> <li>Limited Flexibility: The fixed assignment of frequencies to senders makes the system inflexible, limiting the number of senders that can be supported.</li> </ul>"},{"location":"mobile-computing-copy/#time-division-multiplexing-tdm","title":"Time Division Multiplexing (TDM)","text":"<p>In Time Division Multiplexing (TDM), each channel \\(k_i\\) is allocated the entire bandwidth for a specific time period. Multiple senders use the same frequency but at different points in time.</p> <ul> <li>Guard Space: Time gaps between transmissions are required to prevent overlap.</li> <li>Co-channel Interference: Occurs if transmissions overlap in time, similar to cars colliding on a highway.</li> </ul> <p></p>"},{"location":"mobile-computing-copy/#how-tdm-works","title":"How TDM Works","text":"<ul> <li>Precise Synchronization: Senders must be precisely synchronized, which requires clocks or a method to distribute synchronization signals.</li> <li>Receiver Tuning: The receiver must not only adjust the frequency but also tune to the exact time slot for receiving data.</li> <li>Flexibility: TDM is flexible, allowing more time for senders with heavy traffic and less time for those with lighter loads.</li> </ul>"},{"location":"mobile-computing-copy/#disadvantages-of-tdm","title":"Disadvantages of TDM","text":"<ul> <li>Synchronization Requirement: All senders need to be synchronized, which adds complexity.</li> <li>Time Slot Coordination: A receiver must adjust both the frequency and the correct time slot.</li> <li>Co-channel Interference: If multiple senders choose the same frequency at the same time, interference occurs.</li> </ul>"},{"location":"mobile-computing-copy/#time-frequency-division-multiplexing-tdma-fdma","title":"Time + Frequency Division Multiplexing (TDMA + FDMA)","text":"<p>A combination of both TDM and FDM can be used, where each channel is allotted a specific frequency for a set time period.</p> <ul> <li>Guard Spaces: Required in both time and frequency dimensions.</li> <li>Example: GSM uses TDMA + FDMA for communication between mobile phones and base stations.</li> </ul>"},{"location":"mobile-computing-copy/#advantages-of-tdma-fdma","title":"Advantages of TDMA + FDMA","text":"<ul> <li>Robustness: Provides some protection against frequency selective interference.</li> <li>Protection Against Tapping: The sequence of frequencies must be known to intercept data, providing some protection.</li> </ul>"},{"location":"mobile-computing-copy/#disadvantages-of-tdma-fdma","title":"Disadvantages of TDMA + FDMA","text":"<ul> <li>Coordination: Coordination between senders is required for frequency and time management.</li> <li>Interference: If two senders use the same frequency at the same time, interference occurs. Frequency hopping can minimize this, reducing interference time.</li> </ul>"},{"location":"mobile-computing-copy/#key-takeaways_1","title":"Key Takeaways","text":"<ul> <li>TDM: Simple but requires precise synchronization, making it suitable for scenarios where each sender needs to transmit in defined time slots.</li> <li>TDMA + FDMA: Offers better robustness and protection, but requires complex coordination and management of both time and frequency.</li> </ul>"},{"location":"mobile-computing-copy/#code-division-multiplexing-cdm","title":"Code Division Multiplexing (CDM)","text":"<p>Code Division Multiplexing (CDM) is a relatively new scheme used in commercial communication systems, having been initially used in military applications due to its built-in security features.</p> <ul> <li>Working Principle: All channels \\(k_i\\) use the same frequency at the same time. Separation is achieved by assigning each channel its own unique \"code.\"</li> <li>Guard Space: This is ensured by using codes with a sufficient \"distance\" in the code space, such as orthogonal codes.</li> </ul>"},{"location":"mobile-computing-copy/#example-party-with-global-participants","title":"Example: Party with Global Participants","text":"<p>Imagine a party with many participants from different countries who communicate using the same frequency range (approx. 300\u20136000 Hz):</p> <ul> <li>Same Language (SDM): If everyone speaks the same language, space division multiplexing (SDM) is required to separate groups.</li> <li>Different Languages (CDM): As soon as another language is used, a new code (language) can be tuned into, clearly separating communication in different languages. Other languages appear as background noise.</li> </ul>"},{"location":"mobile-computing-copy/#cdm-security","title":"CDM Security","text":"<ul> <li> <p>Built-in Security: If the receiver doesn\u2019t know the code (or language), the signals are received but are essentially useless. This creates a secure channel in a potentially \"hostile\" environment, much like using a secret language at the party.</p> </li> <li> <p>Guard Space: Codes must be sufficiently distinct (e.g., Swedish and Finnish are orthogonal enough, but Swedish and Norwegian are too similar for separation).</p> </li> </ul>"},{"location":"mobile-computing-copy/#advantages-of-cdm","title":"Advantages of CDM","text":"<ul> <li> <p>Interference Protection: CDM provides strong protection against interference and tapping. The huge code space allows for easy assignment of unique codes to different senders without significant issues.</p> </li> <li> <p>Security: A secret code can create a secure channel, as only those with the correct code can decode the message.</p> </li> </ul>"},{"location":"mobile-computing-copy/#disadvantages-of-cdm","title":"Disadvantages of CDM","text":"<ul> <li> <p>Complex Receiver: The receiver must know the code and be able to decode the signal amidst background noise. This increases the complexity of the receiver.</p> </li> <li> <p>Synchronization Requirement: The receiver must be precisely synchronized with the transmitter for accurate decoding.</p> </li> <li> <p>Power Control: Signals must reach the receiver with equal strength. If signals are uneven, such as someone speaking too loudly near the receiver, the loud signal could drain the others, making it difficult for the receiver to decode other channels.</p> </li> </ul>"},{"location":"mobile-computing-copy/#key-takeaways_2","title":"Key Takeaways","text":"<ul> <li>CDM: Provides secure and interference-resistant communication but requires precise synchronization and power control.</li> <li>Security: Built-in security by using unique codes (or languages) for each communication channel.</li> <li>Complexity: High complexity due to the need for the receiver to decode signals accurately and maintain synchronization.</li> </ul>"},{"location":"mobile-computing-copy/#comparison-of-multiplexing-techniques","title":"Comparison of Multiplexing Techniques","text":"Approach SDMA (Space Division) TDMA (Time Division) FDMA (Frequency Division) CDMA (Code Division) Idea Segment space into cells/sectors Segment sending time into disjoint time-slots Divide the frequency band into sub-bands Spread the spectrum using orthogonal codes Terminals Only one terminal active per cell/sector All terminals share the same frequency but transmit in time slots Each terminal has its own dedicated frequency All terminals can be active simultaneously using unique codes Signal Separation Cell structure with directed antennas Synchronization in the time domain Filtering in the frequency domain Codes and special receivers Advantages Simple, increases capacity per km\u00b2 Fully digital, very flexible Simple, robust, and well-established Highly flexible, less planning needed, supports soft handover Disadvantages Inflexible, fixed antennas required Guard space needed, synchronization is complex Inflexible, limited by available frequencies Complex receivers, requires precise power control Comment Used in combination with TDMA, FDMA, or CDMA Standard in fixed networks, often combined with FDMA/SDMA in mobile networks Often combined with TDMA (frequency hopping patterns) and SDMA (frequency reuse) Used in 3G systems, requires integration with TDMA/FDMA"},{"location":"mobile-computing-copy/#unit-3","title":"Unit 3","text":""},{"location":"mobile-computing-copy/#logical-mobility","title":"Logical Mobility","text":"<p>Logical Mobility refers to the ability to transfer software components, code, or computational elements between different systems or devices.</p>"},{"location":"mobile-computing-copy/#types-of-logical-mobility","title":"Types of Logical Mobility:","text":"<ul> <li>Software Programs &amp; Applications: Moving entire applications between devices.</li> <li>Code Segments &amp; Modules: Transferring scripts or functions dynamically.</li> <li>Objects &amp; Data Structures: Migrating serialized objects or database entries.</li> <li>Computational Processes: Shifting active processing tasks to another system.</li> </ul>"},{"location":"mobile-computing-copy/#examples","title":"Examples:","text":"<ul> <li>App Downloads: Installing an application from an app store.</li> <li>Web Execution: A browser fetching and executing JavaScript from a server.</li> </ul>"},{"location":"mobile-computing-copy/#process-migration","title":"Process Migration","text":"<p>Process Migration is the transfer of an executing process from one computing system to another while maintaining its state.</p>"},{"location":"mobile-computing-copy/#key-aspects-of-process-migration","title":"Key Aspects of Process Migration:","text":"<ul> <li>Process = Program Under Execution</li> <li>State Transfer Includes:</li> <li>Address Space: Memory and allocated resources.</li> <li>Execution Point: CPU register contents.</li> <li>Communication State: Open files, message channels.</li> <li>OS-dependent States: Any system-specific data.</li> </ul>"},{"location":"mobile-computing-copy/#migration-process","title":"Migration Process:","text":"<ol> <li>Two Instances Exist: A source and destination process.</li> <li>Final Handoff: The destination instance takes over as the migrated process.</li> <li>Remote Execution: A process running on another machine is called a remote process.</li> </ol>"},{"location":"mobile-computing-copy/#example","title":"Example:","text":"<ul> <li>Watching a movie on a smart TV, then continuing playback on a tablet while traveling.</li> </ul>"},{"location":"mobile-computing-copy/#procss-migration","title":"Procss Migration:","text":""},{"location":"mobile-computing-copy/#step-1-migration-request-issued","title":"Step 1: Migration Request Issued","text":"<ul> <li>A migration request is sent to a remote node.</li> <li>After negotiation, the migration is accepted.</li> </ul>"},{"location":"mobile-computing-copy/#diagram","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#step-2-process-detachment","title":"Step 2: Process Detachment","text":"<ul> <li>The process is suspended on the source node.</li> <li>It is marked as \"migrating.\"</li> <li>Communication is temporarily redirected.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_1","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#_1","title":"Mobile computing copy","text":""},{"location":"mobile-computing-copy/#step-3-temporary-communication-redirection","title":"Step 3: Temporary Communication Redirection","text":"<ul> <li>Incoming messages are queued.</li> <li>Messages are delivered after migration.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_2","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#step-4-process-state-extraction","title":"Step 4: Process State Extraction","text":"<ul> <li>The process's memory, registers, communication state, and kernel context are extracted.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_3","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#_2","title":"Mobile computing copy","text":""},{"location":"mobile-computing-copy/#step-5-destination-process-instance-created","title":"Step 5: Destination Process Instance Created","text":"<ul> <li>A new process instance is initialized on the remote node.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_4","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#step-6-state-transfer","title":"Step 6: State Transfer","text":"<ul> <li>The extracted state is transferred to the destination node.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_5","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#step-7-forwarding-references","title":"Step 7: Forwarding References","text":"<ul> <li>References (e.g., file descriptors, network sockets) are updated to point to the new process instance.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_6","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#step-8-process-resumed","title":"Step 8: Process Resumed","text":"<ul> <li>The new process instance resumes execution on the remote node.</li> </ul>"},{"location":"mobile-computing-copy/#diagram_7","title":"Diagram:","text":""},{"location":"mobile-computing-copy/#advantages-of-process-migration","title":"Advantages of Process Migration","text":"<ol> <li>Dynamic Load Distribution </li> <li> <p>Balances the load by migrating processes from overloaded nodes to less loaded ones.</p> </li> <li> <p>Fault Resilience </p> </li> <li> <p>Ensures continuity by migrating processes from nodes that have partially failed or are at risk of failure.</p> </li> <li> <p>Improved System Administration </p> </li> <li> <p>Facilitates maintenance by moving processes from nodes that are about to be shut down or become unavailable.</p> </li> <li> <p>Data Access Locality </p> </li> <li> <p>Enhances efficiency by migrating processes closer to the data source, especially useful in mobile environments.</p> </li> <li> <p>Resource Sharing </p> </li> <li> <p>Allows access to specialized hardware by migrating a process to a node equipped with the required resources.</p> </li> <li> <p>Mobile Computing </p> </li> <li>Enables users to continue running applications seamlessly as they move between networks or devices.</li> </ol>"},{"location":"mobile-computing-copy/#applications-of-process-migration","title":"Applications of Process Migration","text":"<ul> <li>Parallelizable Applications \u2013 Distributing computational tasks across multiple nodes.</li> <li>Long-running Applications \u2013 Allowing execution across different nodes without interruption.</li> <li>Generic Multiuser Workloads \u2013 Managing distributed workloads effectively.</li> <li>Pre-emptable Applications \u2013 Processes that can be temporarily suspended and resumed elsewhere.</li> <li>Migration-aware Applications \u2013 Applications designed to adapt to migration scenarios.</li> <li>Network &amp; Mobile Computing Applications \u2013 Ensuring service continuity as devices move across networks.</li> </ul>"},{"location":"mobile-computing-copy/#alternatives-to-process-migration","title":"Alternatives to Process Migration","text":"<ol> <li>Remote Execution </li> <li>Executes code on a remote node instead of migrating the entire process.  </li> <li> <p>Faster than migration due to lower data transfer costs.</p> </li> <li> <p>Cloning </p> </li> <li>Creates a copy of the process on a different node using a remote fork mechanism.  </li> <li>Unlike migration, both instances continue running using distributed shared state.  </li> <li> <p>Higher complexity but useful when state inheritance is required.</p> </li> <li> <p>Mobile Agents </p> </li> <li>Uses Java, Tcl/Tk, or other technologies to move objects or scripts dynamically.  </li> <li>Achieved at the middleware level using frameworks like:<ul> <li>Common Object Request Broker Architecture (CORBA)</li> <li>Distributed Objects</li> </ul> </li> </ol>"},{"location":"mobile-computing-copy/#mobile-agents","title":"\ud83e\udd16 Mobile Agents","text":"<p>Mobile Agents are software entities that autonomously move between computers and continue execution on the destination machine.</p> <ul> <li>\ud83c\udfc3\u200d\u2642\ufe0f Self-driven: Can function independently, even if the user disconnects from the network.</li> <li>\ud83d\ude80 Transportable: They move dynamically across systems.</li> <li>\ud83d\udd04 Data-Carriers: Store information and operate without requiring continuous communication.</li> </ul>"},{"location":"mobile-computing-copy/#types-of-mobile-agents","title":"\ud83d\udee4\ufe0f Types of Mobile Agents","text":"<ol> <li>Agents with Pre-defined Path \ud83d\uddfa\ufe0f  </li> <li> <p>Follow a specific, predetermined route across nodes.</p> </li> <li> <p>Agents with Undefined Path (Roamer) \ud83c\udfde\ufe0f </p> </li> <li>Wander freely across the network, dynamically choosing destinations.</li> </ol>"},{"location":"mobile-computing-copy/#properties-of-mobile-agents","title":"\ud83e\udde0 Properties of Mobile Agents","text":"<p>A Mobile Agent is a software object that exists within an execution environment and possesses these key traits:</p>"},{"location":"mobile-computing-copy/#mandatory-properties","title":"\u2705 Mandatory Properties","text":"<ul> <li>\ud83d\udd04 Reactive \u2013 Responds to environmental changes.</li> <li>\ud83e\udd16 Autonomous \u2013 Controls its own actions.</li> <li>\ud83c\udfaf Goal-Driven \u2013 Works proactively towards objectives.</li> <li>\u23f3 Temporally Continuous \u2013 Runs indefinitely.</li> </ul>"},{"location":"mobile-computing-copy/#optional-properties","title":"\ud83d\udce1 Optional Properties","text":"<ul> <li>\ud83d\udde3 Communicative \u2013 Can interact with other agents.</li> <li>\ud83d\ude80 Mobile \u2013 Can migrate between hosts.</li> <li>\ud83d\udcc8 Learning \u2013 Adapts based on past experiences.</li> </ul>"},{"location":"mobile-computing-copy/#life-cycle-of-mobile-agents","title":"\ud83d\udd04 Life Cycle of Mobile Agents","text":"<p>\u2714\ufe0f Adapts to both home and foreign environments. \u2714\ufe0f Switches between nodes as needed. \u2714\ufe0f Focuses on achieving the final objective. \u2714\ufe0f Operates autonomously without external intervention.  </p>"},{"location":"mobile-computing-copy/#mobile-agent-platforms","title":"\ud83d\udda5\ufe0f Mobile Agent Platforms","text":"<ul> <li>\ud83d\udedc Specialized Servers interpret agent behavior and handle communication.</li> <li>\ud83d\ude80 Autonomous Navigation \u2013 Agents can choose and request migration.</li> <li>\u2699 Platform-Independent Execution \u2013 Can run on any machine without pre-installation.</li> <li>\u2615 Java-Based Execution \u2013 Uses Java Virtual Machine (JVM) to dynamically load code.</li> </ul> <p>\ud83e\udded Types of Mobile Agents: \u2705 One-hop Agents \u2013 Migrate to a single destination. \ud83c\udf0d Multi-hop Agents \u2013 Roam across multiple locations dynamically.</p>"},{"location":"mobile-computing-copy/#components-of-a-mobile-agent","title":"\ud83c\udfd7\ufe0f Components of a Mobile Agent","text":"<p>A Mobile Agent consists of two key components:</p> <ol> <li>\ud83d\udcdc Code \u2013 Instructions defining the agent\u2019s behavior.</li> <li>\ud83e\udde0 Execution State \u2013 The agent\u2019s progress and memory.</li> </ol> <p>\ud83d\udca1 Unlike regular programs where code is stored on disk and execution state is in RAM, mobile agents carry both together when migrating!  </p> <p>Migration Process: \ud83d\udd39 Agent moves \u2192 Carries both its code &amp; execution state \u2192 Resumes seamlessly at the new host.</p>"},{"location":"mobile-computing-copy/#characteristics-of-mobile-agents","title":"\ud83c\udf1f Characteristics of Mobile Agents","text":"<p>\u2714\ufe0f Unique Identity \u2013 Each agent has a distinct presence. \ud83d\udd0d \u2714\ufe0f Aware of Other Agents \u2013 Can detect and interact with other agents. \ud83e\udd1d \u2714\ufe0f Message Handling \u2013 Sends &amp; receives structured messages. \u2709\ufe0f \u2714\ufe0f Host Communication \u2013 Can communicate with its hosting environment. \ud83c\udfe1 \u2714\ufe0f Concurrent Execution \u2013 Supports multiple agents running simultaneously. \ud83d\udd04  </p>"},{"location":"mobile-computing-copy/#_3","title":"Mobile computing copy","text":"<p>Agent Architecture</p> <p></p>"},{"location":"mobile-computing-copy/#mobile-agents-vs-process-migration","title":"\ud83e\udd16 Mobile Agents vs. Process Migration","text":"Aspect \ud83d\ude80 Mobile Agents \ud83d\udd04 Process Migration Control Autonomous decision-making; agents decide when and where to move. System-controlled; OS or network manager decides movement. Intelligence Built-in intelligence to adapt behavior. No built-in intelligence; follows system instructions. Decision Basis Moves based on programmed objectives and current needs. Moves based on system load and resource availability. Flexibility Can change destinations dynamically; supports multi-hop movement. Fixed source-to-destination migration; single-hop only. State Management Carries both code &amp; state together as a package. State must be captured, transferred, and reconstructed. Interaction Can communicate with other agents and systems. No inter-process communication during migration."},{"location":"mobile-computing-copy/#clientserver-vs-mobile-agent-architectures","title":"\ud83c\udf10 Client/Server vs. Mobile Agent Architectures","text":"<p>\ud83d\udce1 Traditional Client/Server Model - Requires continuous communication between client and server. - Frequent request/response cycles increase network bandwidth usage.  </p> <p>\ud83d\ude80 Mobile Agent Architecture - Moves queries/transactions from client to server, reducing repetitive requests. - Works offline and syncs results when the system is back online. - Handles intermittent &amp; unreliable networks effectively.  </p>"},{"location":"mobile-computing-copy/#requirements-for-mobile-agent-systems","title":"\u2705 Requirements for Mobile Agent Systems","text":"<ol> <li>Portability \u2013 Must run on different platforms without modifications. \ud83d\udcbb  </li> <li>Ubiquity \u2013 Should be available across multiple network environments. \ud83c\udf0d  </li> <li>Network Communication \u2013 Needs efficient mechanisms for sending/receiving data. \ud83d\udce1  </li> <li>Server Security \u2013 Must prevent unauthorized agent execution on a host. \ud83d\udd10  </li> <li>Agent Security \u2013 Protects agents from external threats or modifications. \ud83d\udee1\ufe0f  </li> <li>Resource Accounting \u2013 Tracks resource consumption for optimization. \u2699\ufe0f  </li> </ol>"},{"location":"mobile-computing-copy/#diagram-mobile-agent-vs-client-server-communication","title":"\ud83d\udccc Diagram: Mobile Agent vs. Client-Server Communication","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Server\n    Client-&gt;&gt;Server: \ud83d\udd04 Request Data\n    Server--&gt;&gt;Client: \ud83d\udce9 Response\n    Client-&gt;&gt;Server: \ud83d\udd04 Another Request\n    Server--&gt;&gt;Client: \ud83d\udce9 Another Response\n</code></pre>"},{"location":"mobile-computing-copy/#aglets-java-based-mobile-agent-platform","title":"\ud83d\ude80 Aglets: Java-Based Mobile Agent Platform","text":"<p>Aglets are a Java-based framework for mobile agents, designed by IBM. They allow objects to move between hosts on a network while maintaining their execution state.</p>"},{"location":"mobile-computing-copy/#how-aglets-work","title":"\ud83d\udd04 How Aglets Work","text":"<ul> <li>\ud83c\udfc3 An Aglet can pause execution, move to a remote host, and resume execution.</li> <li>\ud83d\udce6 When an Aglet moves, it carries its code and object states to the new host.</li> <li>\ud83c\udf0d Multiple Aglets can run on a single node within different contexts.</li> </ul>"},{"location":"mobile-computing-copy/#aglet-context","title":"\ud83c\udfe2 Aglet Context","text":"<p>An Aglet Context is the workspace where Aglets operate.</p> <ul> <li>\ud83c\udfe0 Stationary Object \u2013 Provides a uniform execution environment.</li> <li>\ud83c\udf10 Hosts Multiple Contexts \u2013 A single network node can run multiple contexts.</li> </ul>"},{"location":"mobile-computing-copy/#aglet-proxy","title":"\ud83d\udee1 Aglet Proxy","text":"<p>A proxy is a representative of an Aglet that: - Shields the Aglet from direct access to its public methods. - Hides its real location, ensuring location transparency.</p>"},{"location":"mobile-computing-copy/#aglet-life-cycle","title":"\ud83d\udd04 Aglet Life Cycle","text":"\ud83c\udfd7\ufe0f Stage \ud83d\udd0d Description Creation \u2728 Aglet is created within a context, assigned an identifier, and initialized. Execution starts immediately. Cloning \ud83e\uddec Produces an identical copy of the Aglet in the same context, with a new identifier. Dispatching \ud83d\ude80 Moves the Aglet to another context, removing it from the current one. Execution restarts at the destination. Retraction \ud83d\udd04 Pulls the Aglet back to its original context after being dispatched. Deactivation \u23f8\ufe0f Temporarily removes an Aglet from execution and stores it in secondary storage. Activation \u25b6\ufe0f Restores a deactivated Aglet back into a context. Disposal \ud83d\uddd1\ufe0f Stops execution and removes the Aglet from the context permanently."},{"location":"mobile-computing-copy/#aglet-communication","title":"\ud83d\udce1 Aglet Communication","text":"<p>Aglets use messages and events to communicate and interact within their environment.</p> <ul> <li>\ud83d\udcec Message Communication </li> <li>\ud83d\udd04 Synchronous \u2013 Requires an immediate response.  </li> <li> <p>\ud83d\udce9 Asynchronous \u2013 Messages are sent without waiting for an immediate reply.  </p> </li> <li> <p>\ud83d\udce2 Event-Driven Communication </p> </li> <li>\ud83d\udd04 Used for reactive or proactive agents.  </li> <li> <p>\ud83d\udcc8 Example: An Aglet can listen for a stock price change event and act accordingly.</p> </li> <li> <p>\ud83d\udee0 Aglet API (Java-based) includes:  </p> </li> <li><code>Aglet</code> \u2013 Core agent class.  </li> <li><code>Aglet Proxy</code> \u2013 Ensures security and location transparency.  </li> <li><code>Aglet Context</code> \u2013 Execution environment for Aglets.  </li> <li><code>Message</code> \u2013 Communication mechanism.</li> </ul>"},{"location":"mobile-computing-copy/#applications-of-aglets","title":"\ud83c\udfdb\ufe0f Applications of Aglets","text":"<ul> <li>\ud83d\uded2 E-commerce \u2013 Mobile shopping assistants.  </li> <li>\ud83c\udf0d E-marketplaces \u2013 Automated price comparison &amp; negotiation.  </li> <li>\u2708\ufe0f Travel &amp; Tourism \u2013 Dynamic air-ticket booking &amp; package tour planning.  </li> </ul>"},{"location":"mobile-computing-copy/#aglet-event-model","title":"\ud83d\udd04 Aglet Event Model","text":"<p>Aglets operate in an event-driven programming model. There are three types of listeners that handle different events:</p> \ud83c\udfa7 Listener Type \ud83d\udccc Function Clone Listener \ud83e\uddec Handles events before, during, and after an Aglet is cloned. Mobility Listener \ud83d\ude80 Triggers actions before dispatching, during movement, and upon arrival at a new context. Persistence Listener \u23f3 Manages events before deactivation and after activation of an Aglet."},{"location":"mobile-computing-copy/#diagram-aglet-event-flow","title":"\ud83d\udccc Diagram: Aglet Event Flow","text":"<pre><code>graph TD\n    A[Aglet Running] --&gt;|Clone Event| B[Clone Listener]\n    A --&gt;|Migration Event| C[Mobility Listener]\n    A --&gt;|Deactivation Event| D[Persistence Listener]</code></pre>"},{"location":"mobile-computing-unit%201/","title":"Mobile computing unit 1","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%201/#mobile-computing","title":"Mobile Computing","text":""},{"location":"mobile-computing-unit%201/#what-is-mobile-computing","title":"What is Mobile Computing?","text":"<p>Mobile computing is a technology that enables the wireless transmission of data, voice, and video through mobile devices without relying on fixed physical connections.</p>"},{"location":"mobile-computing-unit%201/#main-components-of-mobile-computing","title":"Main Components of Mobile Computing","text":"<ul> <li> <p>Mobile Communication</p> </li> <li> <p>Involves protocols, services, bandwidth, and portals that enable seamless connectivity.</p> </li> <li> <p>Supports wireless communication over Wi-Fi, Cellular Networks (3G, 4G, 5G), and Bluetooth.</p> </li> <li> <p>Mobile Hardware</p> </li> <li> <p>Includes portable devices that access mobility services:</p> <ul> <li>Smartphones</li> <li>Tablets</li> <li>Laptops</li> <li>Personal Digital Assistants (PDAs)</li> <li>Wearable Devices</li> </ul> </li> <li> <p>Mobile Software</p> </li> <li> <p>Operating systems and applications that run on mobile devices.</p> </li> <li>Examples: Android, iOS, Windows Mobile, Mobile Web Browsers, and Apps.</li> <li>Acts as the engine that powers mobile functionalities.</li> </ul>"},{"location":"mobile-computing-unit%201/#applications-of-mobile-computing","title":"Applications of Mobile Computing","text":"<ul> <li>Web &amp; Internet Access \u2013 Enables browsing, cloud computing, and real-time communication.</li> <li>Global Positioning System (GPS) \u2013 Provides navigation, tracking, and geolocation services.</li> <li>Emergency Services \u2013 Supports disaster response, medical alerts, and real-time rescue coordination.</li> <li>Entertainment Services \u2013 Powers mobile gaming, streaming platforms, and digital media.</li> <li>Educational Services \u2013 Supports e-learning, mobile classrooms, and virtual collaboration.</li> </ul>"},{"location":"mobile-computing-unit%201/#evolution-of-mobile-computing","title":"Evolution of Mobile Computing","text":"<p>The evolution of mobile generations (G) marks advancements in speed, technology, frequency, data capacity, and latency, revolutionizing communication and connectivity.</p>"},{"location":"mobile-computing-unit%201/#first-generation-1g-analog-communication","title":"First Generation (1G) \u2013 Analog Communication","text":"<ul> <li> <p>Introduced: 1980s \u2013 1990s</p> </li> <li> <p>Technology Used: AMPS (Advanced Mobile Phone System), based on FDMA</p> </li> <li> <p>Speed: 2.4 kbps</p> </li> <li> <p>Features:</p> </li> <li> <p>Allowed voice calls but limited to one country.</p> </li> <li>Used analog signals, leading to poor voice quality and frequent call drops.</li> <li>Weak battery life and limited network capacity.</li> <li>No data services, only voice communication.</li> </ul>"},{"location":"mobile-computing-unit%201/#second-generation-2g-digital-communication","title":"Second Generation (2G) \u2013 Digital Communication","text":"<ul> <li> <p>Introduced: 1990s</p> </li> <li> <p>Technology Used: GSM &amp; CDMA</p> </li> <li> <p>Speed: Up to 144 kbps</p> </li> <li> <p>Features:</p> </li> <li> <p>Digital signals replaced analog, improving voice clarity.</p> </li> <li>Introduced SMS &amp; MMS for text and picture messaging.</li> <li>Enabled conference calling, call hold, and international roaming.</li> <li>Used circuit-switched and packet-switched networks.</li> <li>Introduced GPRS (General Packet Radio Service), achieving speeds of 50 kbps to 1 Mbps.</li> </ul>"},{"location":"mobile-computing-unit%201/#transition-from-2g-to-3g-25g-275g","title":"Transition from 2G to 3G: 2.5G &amp; 2.75G","text":""},{"location":"mobile-computing-unit%201/#25g-gprs-general-packet-radio-service","title":"2.5G (GPRS \u2013 General Packet Radio Service)","text":"<ul> <li> <p>Technology Used: GSM with GPRS</p> </li> <li> <p>Speed: 64 \u2013 144 kbps</p> </li> <li> <p>Improvements Over 2G:</p> </li> <li> <p>Introduced always-on internet access.</p> </li> <li>Enabled email, basic web browsing, and multimedia messaging (MMS).</li> <li>Used packet-switched data, improving efficiency.</li> <li>Lower latency than 2G.</li> <li>Introduction of camera phones.</li> </ul>"},{"location":"mobile-computing-unit%201/#275g-edge-enhanced-data-rates-for-gsm-evolution","title":"2.75G (EDGE \u2013 Enhanced Data rates for GSM Evolution)","text":"<ul> <li> <p>Technology Used: GSM with EDGE (Enhanced GPRS)</p> </li> <li> <p>Speed: Up to 384 kbps</p> </li> <li> <p>Enhancements Over 2.5G:</p> </li> <li> <p>Faster data transmission, enabling video streaming and online gaming.</p> </li> <li>More efficient spectrum usage, improving network performance.</li> <li> <p>Served as a stepping stone to 3G, enhancing mobile internet and multimedia communication.</p> </li> <li> <p>2.5G and 2.75G bridged the gap between traditional mobile calling and the era of high-speed mobile internet.</p> </li> </ul>"},{"location":"mobile-computing-unit%201/#third-generation-3g-high-speed-mobile-data","title":"Third Generation (3G) \u2013 High-Speed Mobile Data","text":"<ul> <li> <p>Introduced: 2000s</p> </li> <li> <p>Technology Used: WCDMA, HSPA (High-Speed Packet Access)</p> </li> <li> <p>Speed: Up to 2 Mbps</p> </li> <li> <p>Features:</p> </li> <li> <p>Enabled web browsing, email, video downloads, and picture sharing.</p> </li> <li>Provided support for multimedia applications, including video calling.</li> <li>Increased bandwidth and data transfer rates for improved web-based applications.</li> <li>Improved voice clarity and reduced latency compared to 2G.</li> </ul>"},{"location":"mobile-computing-unit%201/#fourth-generation-4g-high-speed-broadband-connectivity","title":"Fourth Generation (4G) \u2013 High-Speed Broadband Connectivity","text":"<ul> <li> <p>Introduced: 2010s</p> </li> <li> <p>Technology Used: LTE (Long-Term Evolution), WiMAX</p> </li> <li> <p>Speed: 10 Mbps \u2013 1 Gbps</p> </li> <li> <p>Features:</p> </li> <li> <p>Ultra-fast data speeds with peak downloads of 100 Mbps.</p> </li> <li>Supported high-quality streaming for HD video and VoIP (Voice over IP).</li> <li>Introduced IP-based telephony (VoLTE) for improved call quality.</li> <li>Combination of Wi-Fi and WiMAX for broader coverage.</li> <li>Enhanced security and reliability in mobile communication.</li> </ul>"},{"location":"mobile-computing-unit%201/#fifth-generation-5g-the-future-of-mobile-connectivity","title":"Fifth Generation (5G) \u2013 The Future of Mobile Connectivity","text":"<ul> <li> <p>Introduced: 2020s</p> </li> <li> <p>Technology Used: mmWave, Massive MIMO, Network Slicing</p> </li> <li> <p>Speed: Up to 20 Gbps</p> </li> <li> <p>Key Advancements Over 4G:</p> </li> <li> <p>Higher Data Rates \u2013 Up to 20 Gbps for ultra-fast downloads and real-time communication.</p> </li> <li>Lower Latency \u2013 Reduced response time, essential for real-time gaming, augmented reality (AR), and virtual reality (VR).</li> <li>Increased Network Capacity \u2013 Supports massive IoT (Internet of Things) connections.</li> <li>Improved Reliability \u2013 Network slicing allows dedicated networks for specific applications.</li> </ul>"},{"location":"mobile-computing-unit%201/#summary-of-mobile-generations","title":"Summary of Mobile Generations","text":"Generation Technology Used Speed Key Features 1G AMPS (Analog) 2.4 kbps Voice calls, poor quality, no data 2G GSM &amp; CDMA 144 kbps Digital voice, SMS, MMS, basic internet 2.5G GPRS 64 \u2013 144 kbps Always-on internet, emails, camera phones 2.75G EDGE Up to 384 kbps Faster browsing, video streaming 3G WCDMA, HSPA Up to 2 Mbps Video calls, multimedia, web-based apps 4G LTE, WiMAX 10 Mbps \u2013 1 Gbps HD streaming, VoLTE, broadband connectivity 5G mmWave, MIMO Up to 20 Gbps Ultra-fast speeds, IoT, AI-powered networks"},{"location":"mobile-computing-unit%201/#cellular-architecture","title":"Cellular Architecture","text":"<p>The cellular network is structured in a hierarchical way to provide efficient communication across large geographical areas.</p> <ul> <li>Key Components:</li> <li>Mobile Device (User Equipment) \u2013 Phones, tablets, or IoT devices.</li> <li>Base Transceiver Station (BTS) \u2013 Handles wireless communication with mobile devices.</li> <li>Base Station Controller (BSC) \u2013 Manages multiple BTS and assigns frequencies.</li> <li>Mobile Switching Center (MSC) \u2013 Connects mobile calls and manages handovers.</li> <li>Public Switched Telephone Network (PSTN) \u2013 Traditional wired telephone network.</li> <li>Packet Data Network (Internet) \u2013 Allows mobile data access and browsing.</li> <li>Cell Towers \u2013 Divides the service area into small cells to provide coverage.</li> </ul>"},{"location":"mobile-computing-unit%201/#note-mode-of-communications","title":"Note: Mode of Communications","text":"<pre><code>graph TD;\n\n    subgraph Circuit-Switched Network\n        A((User A)) -- Dedicated Path --&gt; B((User B))\n    end\n\n    subgraph Packet-Switched Network\n        A1((User C)) -- Packet 1 --&gt; C1[Router] --&gt; D1((User D))\n        A1 -- Packet 2 --&gt; C2[Router] --&gt; D1\n        A1 -- Packet 3 --&gt; C3[Router] --&gt; D1\n    end</code></pre>"},{"location":"mobile-computing-unit%201/#mobile-computing-architecture","title":"Mobile Computing Architecture","text":"<p>Mobile computing architecture ensures seamless communication, data management, and user interaction, making applications efficient and scalable.</p>"},{"location":"mobile-computing-unit%201/#location-based-services-lbs","title":"Location-Based Services (LBS)","text":"<ul> <li> <p>Location-Aware Services</p> </li> <li> <p>Identify available services like printers, fax machines, phones, and servers in the local environment.</p> </li> <li> <p>Follow-On Services</p> </li> <li> <p>Automatic call forwarding and workspace transmission to the user\u2019s current location.</p> </li> <li> <p>Information Services</p> </li> <li> <p>Push: Automatic alerts (e.g., special offers in a supermarket).</p> </li> <li> <p>Pull: User-requested data (e.g., where can I find my favorite pastry?).</p> </li> <li> <p>Support Services</p> </li> <li> <p>Maintains cache, session state, and intermediate results, allowing smooth mobility.</p> </li> <li> <p>Privacy Management</p> </li> <li> <p>Controls who has access to location information.</p> </li> </ul>"},{"location":"mobile-computing-unit%201/#three-tier-mobile-computing-architecture","title":"Three-Tier Mobile Computing Architecture","text":""},{"location":"mobile-computing-unit%201/#breakdown-of-the-three-tier-architecture","title":"Breakdown of the Three-Tier Architecture","text":"<ul> <li> <p>Tier-1: Presentation Layer (User Interface)</p> </li> <li> <p>Where users interact with the mobile app.</p> </li> <li>Handles buttons, menus, forms, and screens.</li> <li> <p>Supports multiple users simultaneously.</p> </li> <li> <p>Connection Layer (Access Network)</p> </li> <li> <p>Routes traffic between user devices and the backend system.</p> </li> <li>Adapts to different devices and network conditions.</li> <li> <p>Ensures efficient data transmission even if one route fails.</p> </li> <li> <p>Tier-2: Application Layer</p> </li> <li> <p>Process Management \u2013 Organizes tasks and workflows (e.g., food ordering steps).</p> </li> <li> <p>Business Logic \u2013 Enforces rules and decision-making (e.g., price calculations, discounts).</p> </li> <li> <p>Tier-3: Data Layer</p> </li> <li> <p>Database Management \u2013 Organizes data storage and retrieval (like a librarian).</p> </li> <li>Data Store \u2013 The actual storage where information is kept (like a bookshelf).</li> </ul>"},{"location":"mobile-computing-unit%201/#why-this-design","title":"Why This Design?","text":"<ul> <li>Scalability: More users can be handled by expanding any layer.</li> <li>Reliability: If one component fails, others continue functioning.</li> <li>Flexibility: Different layers can be updated or fixed independently.</li> <li>Adaptability: Works well on various devices and network conditions.</li> </ul>"},{"location":"mobile-computing-unit%201/#real-world-analogy-a-restaurant-setup","title":"Real-World Analogy \u2013 A Restaurant Setup","text":"Layer Restaurant Example Presentation Tier The dining area where customers interact with waiters. Access Network The waiters who take orders to the kitchen. Application Tier The kitchen where food is prepared based on orders. Data Tier The pantry where ingredients are stored."},{"location":"mobile-computing-unit%202/","title":"Mobile computing unit 2","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%202/#medium-access-control","title":"Medium Access Control","text":""},{"location":"mobile-computing-unit%202/#concept-of-multiplexing","title":"Concept of Multiplexing","text":"<p>Multiplexing is a key technique in communication systems that allows multiple users to share a single medium with minimal or no interference.</p>"},{"location":"mobile-computing-unit%202/#real-life-analogy","title":"Real-Life Analogy","text":"<p>Highways as a Shared Medium: - Multiple vehicles (users) travel on the same highway (medium) without interference. - Space Division Multiplexing (SDM): Cars use separate lanes. - Time Division Multiplexing (TDM): Cars use the same lane at different times.</p>"},{"location":"mobile-computing-unit%202/#medium-access-control-mac-protocols","title":"Medium Access Control (MAC) Protocols","text":""},{"location":"mobile-computing-unit%202/#what-is-mac","title":"What is MAC?","text":"<p>A sublayer of the Data Link Layer responsible for coordinating transmissions between multiple nodes.</p> <p></p> <p>Data link layer divided into two functionality-oriented sublayers</p>"},{"location":"mobile-computing-unit%202/#the-mac-problem-in-wireless-networks","title":"The MAC Problem in Wireless Networks","text":"<p>When multiple nodes transmit simultaneously, their signals collide, causing: - Lost data and wasted bandwidth. - Increased retransmissions, leading to higher delays and lower efficiency.</p> <p>Solution: Use a protocol to manage access to the shared medium.</p>"},{"location":"mobile-computing-unit%202/#what-mac-protocols-must-do","title":"What MAC Protocols Must Do:","text":"<ul> <li>Minimize collisions to optimize bandwidth usage.</li> <li>Decide when a station can transmit to avoid conflicts.</li> <li>Handle busy channels by deciding whether to wait or retransmit.</li> <li>Resolve collisions efficiently to ensure smooth data transmission.</li> </ul>"},{"location":"mobile-computing-unit%202/#multiple-access-protocols","title":"Multiple Access Protocols","text":"<p>Here is the Mermaid diagram representation of Multiple Access Protocols along with a brief explanation for each type:  </p> <pre><code>graph TD;\n\n    A[Multiple-Access Protocols] --&gt; B[Random Access Protocols]\n    A --&gt; C[Controlled-Access Protocols]\n    A --&gt; D[Channelization Protocols]\n\n    B --&gt; B1[ALOHA]\n    B --&gt; B2[CSMA]\n    B --&gt; B3[CSMA/CD]\n    B --&gt; B4[CSMA/CA]\n\n    C --&gt; C1[Reservation]\n    C --&gt; C2[Polling]\n    C --&gt; C3[Token Passing]\n\n    D --&gt; D1[FDMA]\n    D --&gt; D2[TDMA]\n    D --&gt; D3[CDMA]</code></pre>"},{"location":"mobile-computing-unit%202/#random-access-protocols-no-fixed-control-contention-based","title":"Random Access Protocols (No fixed control, contention-based):","text":"<ul> <li>ALOHA: Transmits data randomly; high collision rate.</li> <li>CSMA (Carrier Sense Multiple Access): Senses channel before sending data to reduce collisions.</li> <li>CSMA/CD (Collision Detection): Detects collisions and retransmits (used in Ethernet).</li> <li>CSMA/CA (Collision Avoidance): Avoids collisions before transmission (used in Wi-Fi).</li> </ul>"},{"location":"mobile-computing-unit%202/#controlled-access-protocols-centralized-control-avoids-collisions","title":"Controlled-Access Protocols (Centralized control, avoids collisions):","text":"<ul> <li>Reservation: Nodes reserve slots before transmission.</li> <li>Polling: Central controller decides which node transmits.</li> <li>Token Passing: A token circulates, granting transmission rights.</li> </ul>"},{"location":"mobile-computing-unit%202/#channelization-protocols-divide-channel-into-separate-logical-paths","title":"Channelization Protocols (Divide channel into separate logical paths):","text":"<ul> <li>FDMA (Frequency Division Multiple Access): Assigns different frequencies to users.</li> <li>TDMA (Time Division Multiple Access): Allocates time slots to users.</li> <li>CDMA (Code Division Multiple Access): Uses unique codes for simultaneous transmissions.</li> </ul>"},{"location":"mobile-computing-unit%202/#medium-access-in-wireline-vs-wireless-networks","title":"Medium Access in Wireline vs. Wireless Networks","text":""},{"location":"mobile-computing-unit%202/#medium-access-in-wireline-networks-csmacd","title":"Medium Access in Wireline Networks (CSMA/CD)","text":""},{"location":"mobile-computing-unit%202/#assumptions","title":"Assumptions:","text":"<ul> <li>Signal strength remains constant across the wire.</li> <li>Same signal strength can be assumed throughout if the wire length is within standard limits.</li> <li>Collisions can be detected by any node listening to the wire.</li> </ul>"},{"location":"mobile-computing-unit%202/#csmacd-carrier-sense-multiple-access-with-collision-detection-operation","title":"CSMA/CD (Carrier Sense Multiple Access with Collision Detection) Operation:","text":"<ol> <li>Carrier Sense: Listen to the wire; if free, send data.</li> <li>Collision Detection: If a collision is detected while transmitting, stop immediately and send a jam signal to notify all nodes.</li> </ol>"},{"location":"mobile-computing-unit%202/#why-csmacd-works-well-in-wired-networks","title":"Why CSMA/CD Works Well in Wired Networks?","text":"<ul> <li>The signal condition is the same across the medium.</li> <li>Collisions are easily detectable, ensuring efficient retransmission.</li> </ul>"},{"location":"mobile-computing-unit%202/#medium-access-in-wireless-networks-csmaca","title":"Medium Access in Wireless Networks (CSMA/CA)","text":""},{"location":"mobile-computing-unit%202/#challenges-in-wireless-medium","title":"Challenges in Wireless Medium:","text":"<ul> <li>Signal strength varies due to distance and obstacles.</li> <li>Attenuation follows the inverse square law (\\(1/d^2\\)), weakening signals over distance.</li> <li>Collisions at the receiver cannot be detected by simply listening to the medium.</li> </ul>"},{"location":"mobile-computing-unit%202/#csmacd-issues-in-wireless","title":"CSMA/CD Issues in Wireless:","text":"<ol> <li>Carrier Sense: The sender may detect an idle medium, but the receiver may still experience a collision.</li> <li>Collision Detection: The sender cannot always detect a collision at the receiver\u2019s end.</li> </ol>"},{"location":"mobile-computing-unit%202/#why-csmacd-fails-in-wireless","title":"Why CSMA/CD Fails in Wireless?","text":"<ul> <li>Wireless nodes have different perspectives of the medium.</li> <li>The hidden terminal problem causes undetected collisions.</li> <li>Instead, wireless networks use CSMA/CA (Collision Avoidance) to prevent collisions before they happen.</li> </ul>"},{"location":"mobile-computing-unit%202/#wireless-medium-access-problems","title":"Wireless Medium Access Problems","text":"<p>Wireless networks face unique challenges due to signal interference, attenuation, and variable reception.</p>"},{"location":"mobile-computing-unit%202/#hidden-terminal-problem","title":"Hidden Terminal Problem","text":""},{"location":"mobile-computing-unit%202/#scenario","title":"Scenario:","text":"<ul> <li>A and C cannot hear each other but are both within B\u2019s range.</li> <li>A starts transmitting to B.</li> <li>C senses the medium as free (since it cannot hear A) and starts transmitting to B at the same time.</li> <li>A collision occurs at B, but neither A nor C detects it.</li> </ul>"},{"location":"mobile-computing-unit%202/#cause","title":"Cause:","text":"<ul> <li>Other senders are hidden from the current sender, leading to undetected collisions.</li> </ul>"},{"location":"mobile-computing-unit%202/#solution","title":"Solution:","text":"<ul> <li>The RTS/CTS (Request to Send / Clear to Send) mechanism helps avoid hidden terminal issues by coordinating access.</li> </ul>"},{"location":"mobile-computing-unit%202/#exposed-terminal-problem","title":"Exposed Terminal Problem","text":""},{"location":"mobile-computing-unit%202/#scenario_1","title":"Scenario:","text":"<ul> <li>B is transmitting to A.</li> <li>C senses the medium as busy because B is transmitting.</li> <li>However, C could have transmitted to D without causing a collision.</li> <li>C unnecessarily defers its transmission, reducing network efficiency.</li> </ul>"},{"location":"mobile-computing-unit%202/#cause_1","title":"Cause:","text":"<ul> <li>The sender mistakenly assumes the medium is in use, leading to wasted transmission opportunities.</li> </ul>"},{"location":"mobile-computing-unit%202/#solution_1","title":"Solution:","text":"<ul> <li>Spatial reuse techniques allow simultaneous non-interfering transmissions.</li> </ul> <pre><code>sequenceDiagram\n    participant R1 as R\u2081 (Receiver 1)\n    participant S1 as S\u2081 (Sender 1)\n    participant S2 as S\u2082 (Sender 2)\n    participant R2 as R\u2082 (Receiver 2)\n\n    Note over S1,R1: 1. Initial Communication Setup\n    S1-&gt;&gt;R1: Request to Send (RTS)\n    R1-&gt;&gt;S1: Clear to Send (CTS)\n\n    Note over S1,R1: 2. Data Transfer Begins\n    S1-&gt;&gt;R1: DATA Transmission\n\n    Note over S2,R2: Medium is Busy\n    S2--xR2: Waiting for Clear Medium\n\n    Note over S1,R1: 3. Successful Data Transfer\n    activate S1\n    activate R1\n    Note over S1,R1: Data Transfer Complete\n    deactivate S1\n    deactivate R1\n\n    Note over S2,R2: Medium is Now Clear</code></pre>"},{"location":"mobile-computing-unit%202/#nearfar-terminal-problem","title":"Near/Far Terminal Problem","text":""},{"location":"mobile-computing-unit%202/#scenario_2","title":"Scenario:","text":"<ul> <li>B is closer to C than A.</li> <li>B\u2019s stronger signal overpowers A\u2019s weaker signal at C.</li> <li>C cannot receive A\u2019s transmission properly, causing data loss.</li> </ul>"},{"location":"mobile-computing-unit%202/#cause_2","title":"Cause:","text":"<ul> <li>Signal strength imbalance leads to weaker signals being drowned out by stronger ones.</li> </ul>"},{"location":"mobile-computing-unit%202/#solution_2","title":"Solution:","text":"<ul> <li>Power control mechanisms ensure all terminals are detectable at the base station.</li> <li>GSM avoids the problem by using time slots (TDMA), preventing simultaneous transmission.</li> <li>CDMA uses power control so all signals arrive at the receiver with equal strength.</li> </ul>"},{"location":"mobile-computing-unit%202/#multiplexing","title":"Multiplexing","text":"<p>Wireless channels can be multiplexed in four key dimensions: 1. Time (t): A channel occupies the entire frequency spectrum for a specific time period. 2. Space (s): The same frequency can be reused if base stations are sufficiently separated. 3. Frequency (f): The spectrum is divided into smaller frequency bands. 4. Code (c): Each channel is assigned a unique code for transmission.</p>"},{"location":"mobile-computing-unit%202/#space-division-multiplexing-sdm","title":"Space Division Multiplexing (SDM)","text":"<ul> <li>SDM involves separating channels in three dimensions: Code, Time, and Frequency.</li> <li>The Space dimension is represented by circles indicating interference ranges.</li> <li>To prevent overlap, channels are mapped to separate spaces (s1 to s3). This creates \"guard space\" between channels.</li> <li>Channels k1 to k3 are clearly separated, while additional spaces are needed for channels k4 to k6.</li> <li>This principle is similar to how old analog phone systems provided separate copper wires for each subscriber.</li> </ul>"},{"location":"mobile-computing-unit%202/#example-fm-radio","title":"Example: FM Radio","text":"<ul> <li>Multiple radio stations can use the same frequency without interference, as long as they are separated geographically.</li> </ul>"},{"location":"mobile-computing-unit%202/#key-takeaways","title":"Key Takeaways:","text":"<ul> <li>Guard space: Needed in all multiplexing schemes to prevent interference.</li> <li>SDM: Effective for localized transmissions like FM radio but not scalable for dense urban areas.</li> </ul> <p>Note: If several radio stations want to broadcast in the same city, SDM is not suitable. Solution: Multiplexing through Frequency, Time, or Code.</p>"},{"location":"mobile-computing-unit%202/#frequency-division-multiplexing-fdm","title":"Frequency Division Multiplexing (FDM)","text":"<p>Frequency Division Multiplexing (FDM) divides the frequency dimension into several non-overlapping frequency bands. Each channel \\(k_i\\) is assigned a specific frequency band, which can be used continuously by the sender.</p> <ul> <li>Guard Spaces: Essential to prevent frequency band overlap (also called adjacent channel interference).</li> <li>Example: Used by radio stations within the same region, where each station broadcasts on its own frequency.</li> </ul>"},{"location":"mobile-computing-unit%202/#how-fdm-works","title":"How FDM Works","text":"<ul> <li>Simple Scheme: The receiver only needs to tune into the specific frequency assigned to the sender.</li> <li>Usage: Common in systems like radio broadcasting, where multiple stations use different frequencies to avoid interference.</li> </ul>"},{"location":"mobile-computing-unit%202/#advantages-of-fdm","title":"Advantages of FDM","text":"<ul> <li>Simplicity: Very simple to implement, as it requires minimal coordination between the sender and receiver.</li> <li>Continuous Use: Each sender can use its frequency band continuously, making it suitable for applications like radio broadcasting.</li> </ul>"},{"location":"mobile-computing-unit%202/#disadvantages-of-fdm","title":"Disadvantages of FDM","text":"<ul> <li>Frequency Resource Waste: In mobile communication, where communication is short-term, dedicating an entire frequency band to each scenario would waste valuable frequency resources.</li> <li>Limited Flexibility: The fixed assignment of frequencies to senders makes the system inflexible, limiting the number of senders that can be supported.</li> </ul>"},{"location":"mobile-computing-unit%202/#time-division-multiplexing-tdm","title":"Time Division Multiplexing (TDM)","text":"<p>In Time Division Multiplexing (TDM), each channel \\(k_i\\) is allocated the entire bandwidth for a specific time period. Multiple senders use the same frequency but at different points in time.</p> <ul> <li>Guard Space: Time gaps between transmissions are required to prevent overlap.</li> <li>Co-channel Interference: Occurs if transmissions overlap in time, similar to cars colliding on a highway.</li> </ul>"},{"location":"mobile-computing-unit%202/#how-tdm-works","title":"How TDM Works","text":"<ul> <li>Precise Synchronization: Senders must be precisely synchronized, which requires clocks or a method to distribute synchronization signals.</li> <li>Receiver Tuning: The receiver must not only adjust the frequency but also tune to the exact time slot for receiving data.</li> <li>Flexibility: TDM is flexible, allowing more time for senders with heavy traffic and less time for those with lighter loads.</li> </ul>"},{"location":"mobile-computing-unit%202/#disadvantages-of-tdm","title":"Disadvantages of TDM","text":"<ul> <li>Synchronization Requirement: All senders need to be synchronized, which adds complexity.</li> <li>Time Slot Coordination: A receiver must adjust both the frequency and the correct time slot.</li> <li>Co-channel Interference: If multiple senders choose the same frequency at the same time, interference occurs.</li> </ul>"},{"location":"mobile-computing-unit%202/#time-frequency-division-multiplexing-tdma-fdma","title":"Time + Frequency Division Multiplexing (TDMA + FDMA)","text":"<p>A combination of both TDM and FDM can be used, where each channel is allotted a specific frequency for a set time period.</p> <ul> <li>Guard Spaces: Required in both time and frequency dimensions.</li> <li>Example: GSM uses TDMA + FDMA for communication between mobile phones and base stations.</li> </ul>"},{"location":"mobile-computing-unit%202/#advantages-of-tdma-fdma","title":"Advantages of TDMA + FDMA","text":"<ul> <li>Robustness: Provides some protection against frequency selective interference.</li> <li>Protection Against Tapping: The sequence of frequencies must be known to intercept data, providing some protection.</li> </ul>"},{"location":"mobile-computing-unit%202/#disadvantages-of-tdma-fdma","title":"Disadvantages of TDMA + FDMA","text":"<ul> <li>Coordination: Coordination between senders is required for frequency and time management.</li> <li>Interference: If two senders use the same frequency at the same time, interference occurs. Frequency hopping can minimize this, reducing interference time.</li> </ul>"},{"location":"mobile-computing-unit%202/#key-takeaways_1","title":"Key Takeaways","text":"<ul> <li>TDM: Simple but requires precise synchronization, making it suitable for scenarios where each sender needs to transmit in defined time slots.</li> <li>TDMA + FDMA: Offers better robustness and protection, but requires complex coordination and management of both time and frequency.</li> </ul>"},{"location":"mobile-computing-unit%202/#code-division-multiplexing-cdm","title":"Code Division Multiplexing (CDM)","text":"<p>Code Division Multiplexing (CDM) is a relatively new scheme used in commercial communication systems, having been initially used in military applications due to its built-in security features.</p> <ul> <li>Working Principle: All channels \\(k_i\\) use the same frequency at the same time. Separation is achieved by assigning each channel its own unique code.</li> <li>Guard Space: This is ensured by using codes with a sufficient distance in the code space, such as orthogonal codes.</li> </ul>"},{"location":"mobile-computing-unit%202/#example-party-with-global-participants","title":"Example: Party with Global Participants","text":"<p>Imagine a party with many participants from different countries who communicate using the same frequency range (approx. 300\u20136000 Hz): - Same Language (SDM): If everyone speaks the same language, space division multiplexing (SDM) is required to separate groups. - Different Languages (CDM): As soon as another language is used, a new code (language) can be tuned into, clearly separating communication in different languages. Other languages appear as background noise.</p>"},{"location":"mobile-computing-unit%202/#cdm-security","title":"CDM Security","text":"<ul> <li>Built-in Security: If the receiver doesn\u2019t know the code (or language), the signals are received but are essentially useless. This creates a secure channel in a potentially hostile environment, much like using a secret language at the party.</li> <li>Guard Space: Codes must be sufficiently distinct (e.g., Swedish and Finnish are orthogonal enough, but Swedish and Norwegian are too similar for separation).</li> </ul>"},{"location":"mobile-computing-unit%202/#advantages-of-cdm","title":"Advantages of CDM","text":"<ul> <li>Interference Protection: CDM provides strong protection against interference and tapping. The huge code space allows for easy assignment of unique codes to different senders without significant issues.</li> <li>Security: A secret code can create a secure channel, as only those with the correct code can decode the message.</li> </ul>"},{"location":"mobile-computing-unit%202/#disadvantages-of-cdm","title":"Disadvantages of CDM","text":"<ul> <li>Complex Receiver: The receiver must know the code and be able to decode the signal amidst background noise. This increases the complexity of the receiver.</li> <li>Synchronization Requirement: The receiver must be precisely synchronized with the transmitter for accurate decoding.</li> <li>Power Control: Signals must reach the receiver with equal strength. If signals are uneven, such as someone speaking too loudly near the receiver, the loud signal could drain the others, making it difficult for the receiver to decode other channels.</li> </ul>"},{"location":"mobile-computing-unit%202/#key-takeaways_2","title":"Key Takeaways","text":"<ul> <li>CDM: Provides secure and interference-resistant communication but requires precise synchronization and power control.</li> <li>Security: Built-in security by using unique codes (or languages) for each communication channel.</li> <li>Complexity: High complexity due to the need for the receiver to decode signals accurately and maintain synchronization.</li> </ul>"},{"location":"mobile-computing-unit%202/#tdma-overview","title":"TDMA Overview","text":"<p>Time Division Multiple Access (TDMA) divides a channel into time slots, allowing multiple users to share the same frequency by transmitting in allocated slots.</p>"},{"location":"mobile-computing-unit%202/#dynamic-allocation","title":"Dynamic Allocation","text":""},{"location":"mobile-computing-unit%202/#characteristics","title":"Characteristics","text":"<ul> <li>Sender may transmit in any slot.</li> <li>Good for dynamic loads.</li> </ul>"},{"location":"mobile-computing-unit%202/#potential-problems","title":"Potential Problems","text":"<ul> <li>Collisions if multiple senders choose the same slot.</li> <li>Receiver must identify the sender to confirm it is the intended recipient.</li> </ul>"},{"location":"mobile-computing-unit%202/#sender-requirements","title":"Sender Requirements","text":"<ul> <li>Include sender identification in transmissions for receiver response.</li> <li>Optionally, periodically announce the allocation scheme to inform receivers.</li> </ul>"},{"location":"mobile-computing-unit%202/#receiver-requirements","title":"Receiver Requirements","text":"<ul> <li>Monitor all slots to detect transmissions.</li> <li>Verify sender identification to ensure it is the intended recipient.</li> </ul>"},{"location":"mobile-computing-unit%202/#fixed-allocation","title":"Fixed Allocation","text":""},{"location":"mobile-computing-unit%202/#characteristics_1","title":"Characteristics","text":"<ul> <li>Sender transmits in fixed, pre-assigned slots.</li> <li>Good for static loads.</li> </ul>"},{"location":"mobile-computing-unit%202/#potential-problems_1","title":"Potential Problems","text":"<ul> <li>Inefficient for bursty or dynamic traffic, as slots may go unused.</li> <li>Synchronization issues if timing is not maintained.</li> </ul>"},{"location":"mobile-computing-unit%202/#sender-requirements_1","title":"Sender Requirements","text":"<ul> <li>Transmit only in assigned slots.</li> <li>Maintain synchronization with the base station.</li> </ul>"},{"location":"mobile-computing-unit%202/#receiver-requirements_1","title":"Receiver Requirements","text":"<ul> <li>Tune to specific slots to receive transmissions.</li> <li>Synchronization with the sender\u2019s slot timing is required; sender identification is not necessary.</li> </ul>"},{"location":"mobile-computing-unit%202/#fixed-tdm","title":"Fixed TDM","text":""},{"location":"mobile-computing-unit%202/#characteristics_2","title":"Characteristics","text":"<ul> <li>Allocates time slots for channels in a fixed pattern.</li> <li>Provides fixed bandwidth.</li> <li>Suitable for connections with a constant data rate.</li> <li>Guarantees fixed delay (e.g., transmit every 10 ms).</li> <li>Used in digital mobile phone systems like IS-54, IS-136, GSM, DECT.</li> </ul>"},{"location":"mobile-computing-unit%202/#assignment","title":"Assignment","text":"<ul> <li>Fixed pattern assigned by the base station, resolving competition between mobile stations.</li> <li>Ensures each mobile station knows its turn, preventing interference if synchronization is maintained.</li> </ul>"},{"location":"mobile-computing-unit%202/#limitations","title":"Limitations","text":"<ul> <li>Inefficient for bursty, asymmetric, or dynamic traffic (e.g., web browsing, where data transfer is sporadic).</li> <li>Too static and inflexible for data communication.</li> <li>Requires connectionless, demand-oriented TDMA schemes for dynamic traffic.</li> </ul>"},{"location":"mobile-computing-unit%202/#time-division-duplex-tdd","title":"Time Division Duplex (TDD)","text":""},{"location":"mobile-computing-unit%202/#characteristics_3","title":"Characteristics","text":"<ul> <li>Assigns different uplink and downlink slots between base station and mobile station.</li> <li>Perfect for connections with constant data rates.</li> </ul>"},{"location":"mobile-computing-unit%202/#limitations_1","title":"Limitations","text":"<ul> <li>Inefficient for bursty or asymmetric traffic patterns (e.g., web browsing, where data transfer varies between uplink and downlink).</li> <li>Needs dynamic TDMA schemes to handle demand-oriented communication.</li> </ul>"},{"location":"mobile-computing-unit%202/#dynamic-tdm","title":"Dynamic TDM","text":""},{"location":"mobile-computing-unit%202/#demand-oriented-tdma-simple-aloha","title":"Demand-Oriented TDMA - Simple Aloha","text":""},{"location":"mobile-computing-unit%202/#simple-mac","title":"Simple MAC","text":"<ul> <li>Operation: Node sends data whenever it wants to.</li> <li>Collision Handling: If a collision occurs, the node resends the data, leaving problem resolution to higher layers.</li> <li>Pros: Simple MAC implementation.</li> <li>Cons: High risk of collisions.</li> <li>Aloha Scheme: Not strictly a MAC protocol but effective for light loads.</li> <li>Throughput: Achieves maximum throughput of approximately 18%.</li> <li>Hidden/Exposed Terminal Problem: Simple Aloha cannot handle hidden or exposed terminal problems, as it lacks mechanisms to coordinate access or detect collisions caused by hidden nodes.</li> </ul>"},{"location":"mobile-computing-unit%202/#slotted-aloha","title":"Slotted Aloha","text":""},{"location":"mobile-computing-unit%202/#simple-mac_1","title":"Simple MAC","text":"<ul> <li>Operation: Node sends data whenever it wants, but transmission starts at a slot boundary.</li> <li>Collision Handling: Slots reduce the probability of collisions compared to Simple Aloha. If a collision occurs, the node resends.</li> <li>Pros: Reduced collision probability due to slot boundaries.</li> <li>Cons: Collisions still occur, and resending is required.</li> <li>Throughput: Achieves maximum throughput of approximately 36%.</li> <li>Hidden/Exposed Terminal Problem: Slotted Aloha cannot effectively handle hidden or exposed terminal problems, as it does not include mechanisms like RTS/CTS to coordinate access or mitigate interference from hidden nodes.</li> </ul>"},{"location":"mobile-computing-unit%202/#mac-design-principles","title":"MAC Design Principles","text":""},{"location":"mobile-computing-unit%202/#resource-allocation","title":"Resource Allocation","text":"<ul> <li>Limited Resources: Resources must be allocated to a set of users.</li> <li>Dimensions: Choose suitable dimension(s) to partition the resource (e.g., space, time, frequency, code).</li> <li>Technique: Decide technique for optimal allocation of resources to users in the selected dimension (e.g., time \u2192 TDMA).</li> </ul>"},{"location":"mobile-computing-unit%202/#centralized-scheme","title":"Centralized Scheme","text":"<ul> <li>Structure: Single base station or master controls access to the medium; all other nodes are slaves.</li> <li>Examples: Wireless LAN, cellular network with base station.</li> <li>Pros: Simple implementation.</li> <li>Cons: </li> <li>Master is a bottleneck.</li> <li>Single point of failure.</li> <li>Master needs to be re-elected on failure.</li> <li>Example Mechanism: Polling/Probing.</li> </ul>"},{"location":"mobile-computing-unit%202/#distributed-scheme","title":"Distributed Scheme","text":"<ul> <li>Structure: All nodes contend for the medium without a central controlling station.</li> <li>Pros: Lower delays due to lack of centralized coordination.</li> <li>Cons: Complex implementation.</li> </ul>"},{"location":"mobile-computing-unit%202/#performance-metrics","title":"Performance Metrics","text":"<ul> <li>Normalized Throughput: Fraction of link capacity used to carry non-retransmitted packets.</li> <li>Example: With no collisions, 1000 packets/sec; with a particular scheme and workload, 250 packets/sec \u2192 Throughput = 0.25.</li> <li>Mean Delay: Amount of time a station waits before successfully transmitting a packet; depends on load and medium characteristics.</li> <li>Stability: </li> <li>Unstable if heavy load leads to time spent resolving contentions.</li> <li>Stable algorithms maintain throughput as load increases.</li> <li>Infinite uncontrolled stations guarantee instability, but load reduction during overload can achieve stability.</li> <li>Fairness: </li> <li>No single definition.</li> <li>\u2018No-starvation\u2019: Source eventually gets a chance to send.</li> <li>Max-min fair share.</li> </ul>"},{"location":"mobile-computing-unit%202/#medium-access-control-review","title":"Medium Access Control Review","text":"<ul> <li>Purpose: Control user access to the medium.</li> <li>Traffic Signal Analogy: One vehicle passes at a time at a crossing; if a collision occurs, wait until the road is cleared and start again.</li> <li>Types: Can be centralized or decentralized.</li> <li>Wireless Consideration: Improvised MAC required for wireless networks (discussed later).</li> </ul>"},{"location":"mobile-computing-unit%202/#medium-access-in-wireless-review","title":"Medium Access in Wireless Review","text":"<ul> <li>Wireline Assumptions Failure:</li> <li>Signal strength is not constant throughout the medium.</li> <li>Signal attenuates with distance; conditions detected at one end differ from the other.</li> <li>Collisions at the receiver cannot be detected by listening to the medium.</li> <li>CSMA/CD in Wireless:</li> <li>Fails due to hidden/exposed terminal problems and near/far terminal problems.</li> <li>TDMA:</li> <li>Supports dynamic or fixed slot allocation.</li> <li>Aloha used as a simple MAC.</li> </ul>"},{"location":"mobile-computing-unit%202/#improving-aloha","title":"Improving ALOHA","text":"<ul> <li>Aloha Limitations: Low throughput due to lack of coordination.</li> <li>What is Missing in Aloha?: Carrier sensing is not performed; nodes transmit whenever they want.</li> <li>How to Improve?: Implement carrier sensing before transmission to check if the medium is free.</li> <li>Impact of Improvement: Carrier sensing can reduce collisions, improving throughput compared to Simple Aloha or Slotted Aloha, though it may not fully address hidden/exposed terminal problems without additional mechanisms like RTS/CTS.</li> </ul>"},{"location":"mobile-computing-unit%202/#1-persistent-csma","title":"1-Persistent CSMA","text":"<p>1-Persistent CSMA is a method where a device constantly checks the network channel to send data when free.</p> <ul> <li>How It Works: Listens to the channel. If busy, waits. If free, sends data instantly (100% chance, hence \u201c1-persistent\u201d).</li> <li>Example: Waiting at a phone booth, jumping in to call as soon as it\u2019s free.</li> <li>Pros: Fast sending when channel is free.</li> <li>Cons: High collision risk if multiple devices send at once, causing delays.</li> </ul> <p>Easy Idea</p> <p>1-Persistent CSMA is like grabbing the mic the moment the stage clears, risking others talking over you.</p> <p>Issue</p> <p>Collisions from multiple senders slow things down.</p>"},{"location":"mobile-computing-unit%202/#non-persistent-csma","title":"Non-Persistent CSMA","text":"<p>Non-Persistent CSMA checks the channel only when ready to send, waiting randomly if busy.</p> <ul> <li>How It Works: Checks channel. If free, sends. If busy, waits a random time, then checks again.</li> <li>Example: Checking a phone booth. If busy, you leave, wait a bit, then check again.</li> <li>Pros: Fewer collisions due to random waits.</li> <li>Cons: Slower as random waiting reduces efficiency.</li> </ul> <p>Easy Idea</p> <p>Non-Persistent CSMA is like stepping back if the stage is busy, checking later.</p> <p>Issue</p> <p>Random waits can delay sending too much.</p>"},{"location":"mobile-computing-unit%202/#p-persistent-csma","title":"P-Persistent CSMA","text":"<p>P-Persistent CSMA uses time slots, sending with a chance when the channel is free.</p> <ul> <li>How It Works: In slotted channels, checks if slot is free. Sends with probability P (e.g., 50%) or waits for next slot. Repeats until sending or another device sends.</li> <li>Example: At a slotted karaoke, flip a coin to sing if the mic\u2019s free, else wait for the next slot.</li> <li>Pros: Balances speed and collision risk.</li> <li>Cons: Some collisions if multiple devices send; delays if waiting too often.</li> </ul> <p>Easy Idea</p> <p>P-Persistent CSMA is like coin-flipping to grab a free slot, avoiding chaos.</p> <p>Issue</p> <p>Wrong probability can cause collisions or delays.</p> <p></p>"},{"location":"mobile-computing-unit%202/#improving-aloha-csma-basics","title":"Improving Aloha: CSMA Basics","text":"<p>CSMA improves Aloha (where devices send anytime, causing collisions) by checking the channel first.</p> <ul> <li>How It Works: Checks if channel is free. If free, sends. If busy, waits (persistent or random). Non-Persistent waits randomly; P-Persistent uses probability.</li> <li>Example: Unlike Aloha\u2019s shouting into a radio, CSMA listens first, then talks if quiet.</li> <li>Pros: Fewer collisions than Aloha.</li> <li>Cons: Collisions still happen; waiting can slow things.</li> </ul> <p>Easy Idea</p> <p>CSMA is like listening before talking on a radio, unlike Aloha\u2019s free-for-all.</p> <p>Issue</p> <p>Timing of checks and sends needs tuning to avoid collisions.</p>"},{"location":"mobile-computing-unit%202/#demand-assigned-multiple-access-dama","title":"Demand Assigned Multiple Access (DAMA)","text":"<p>DAMA reserves specific time slots for data, avoiding collisions during sending.</p> <ul> <li>How It Works: Devices compete in a reservation phase (Aloha-style). Successful ones get a slot, managed by a central system (e.g., satellite). Devices send in their slots without collisions.</li> <li>Example: Booking a conference talk slot to speak without interruptions.</li> <li>Pros: No collisions during data sending; reliable.</li> <li>Cons: Reservation phase collisions; wastes time with few devices.</li> </ul> <p>Easy Idea</p> <p>DAMA is like reserving a meeting room to talk without overlaps.</p> <p>Issue</p> <p>Reservation competition can slow things if many devices try.</p>"},{"location":"mobile-computing-unit%202/#packet-reservation-multiple-access-prma","title":"Packet Reservation Multiple Access (PRMA)","text":"<p>PRMA lets devices reserve slots, keeping them for ongoing data needs.</p> <ul> <li>How It Works: Time splits into frames with slots. Devices compete for empty slots (Aloha-style). Winning a slot reserves it for future frames until no more data. Empty slots reopen for competition.</li> <li>Example: Booking a weekly gym slot, yours until you stop going.</li> <li>Pros: Great for steady data like voice calls; fewer collisions after reservation.</li> <li>Cons: Initial competition causes collisions; unused slots waste time.</li> </ul> <p>Easy Idea</p> <p>PRMA is like reserving a regular class spot, yours until you\u2019re done.</p> <p>Issue</p> <p>Initial slot fights can be messy.</p>"},{"location":"mobile-computing-unit%202/#distributed-packet-reservation-multiple-access-d-prma","title":"Distributed Packet Reservation Multiple Access (D-PRMA)","text":"<p>D-PRMA is PRMA without a central controller, using broadcasts to manage slots.</p> <ul> <li>How It Works: Like PRMA, devices compete for slots in frames. Winning slots are reserved until data ends. A base station broadcasts slot status (free or taken).</li> <li>Example: Signing up for a recurring event; everyone hears your spot is taken.</li> <li>Pros: Works for cellular voice/data; reduces collisions post-reservation.</li> <li>Cons: Initial competition is chaotic; needs broadcast system.</li> </ul> <p>Easy Idea</p> <p>D-PRMA is like claiming a community event slot, announced to all.</p> <p>Issue</p> <p>Early slot competition can delay things.</p>"},{"location":"mobile-computing-unit%202/#reservation-time-division-multiple-access-reservation-tdma","title":"Reservation Time Division Multiple Access (Reservation-TDMA)","text":"<p>Reservation-TDMA uses mini-slots for reservations and data slots for sending.</p> <ul> <li>How It Works: Each frame has mini-slots (one per device) and data slots. Devices reserve data slots via their mini-slot. Unused slots are shared in a round-robin way.</li> <li>Example: Each person gets a small slot to book a bigger meeting room slot.</li> <li>Pros: Organized; no collisions in data slots.</li> <li>Cons: Mini-slots can limit flexibility; setup is complex.</li> </ul> <p>Easy Idea</p> <p>Reservation-TDMA is like everyone having a tiny slot to book a big one.</p> <p>Issue</p> <p>Complex setup can be overkill for simple networks.</p>"},{"location":"mobile-computing-unit%202/#multiple-access-with-collision-avoidance-maca","title":"Multiple Access with Collision Avoidance (MACA)","text":"<p>MACA uses a handshake to avoid collisions before sending data.</p> <ul> <li>How It Works: Device sends a Request to Send (RTS). Receiver replies with Clear to Send (CTS) if ready. Sender then sends data. If a packet fails, it waits a random time before retrying.</li> <li>Example: Asking \u201cCan I talk?\u201d and waiting for \u201cYes\u201d before speaking.</li> <li>Pros: Reduces collisions with RTS/CTS handshake.</li> <li>Cons: Extra steps slow things; retries needed for failures.</li> </ul> <p>Easy Idea</p> <p>MACA is like asking permission to talk, avoiding interruptions.</p> <p>Issue</p> <p>Handshake adds delay, especially if packets fail.</p> <p></p>"},{"location":"mobile-computing-unit%202/#polling","title":"Polling","text":"<p>Polling is a centralized method where a main station asks others to send data.</p> <ul> <li>How It Works: A master station (e.g., base station) polls slave stations one by one (round-robin or random) to send data.</li> <li>Example: A teacher calling on students one at a time to speak.</li> <li>Pros: No collisions; fully controlled.</li> <li>Cons: Slow if many stations; master is a single point of failure.</li> </ul> <p>Easy Idea</p> <p>Polling is like a boss calling each worker to report, one at a time.</p> <p>Issue</p> <p>Relies on the master; slow for big networks.</p>"},{"location":"mobile-computing-unit%202/#inhibit-sense-multiple-access","title":"Inhibit Sense Multiple Access","text":"<p>Inhibit Sense Multiple Access uses a busy signal to control sending.</p> <ul> <li>How It Works: Base station sends a busy tone when the channel is in use. When the tone stops, devices try to send without further coordination. Successful sends get a confirmation; collisions mean retrying.</li> <li>Example: A traffic light says \u201cstop\u201d when busy; when green, cars go without extra checks.</li> <li>Pros: Simple; base station controls busy state.</li> <li>Cons: Collisions likely after tone stops; no priority system.</li> </ul> <p>Easy Idea</p> <p>Inhibit Sense is like waiting for a \u201cgo\u201d signal, then rushing in.</p> <p>Issue</p> <p>Rushing after the tone can cause collisions.</p>"},{"location":"mobile-computing-unit%202/#comparison-table","title":"Comparison Table","text":"Method Key Feature Collision Risk Speed Complexity 1-Persistent CSMA Sends instantly if free High Fast Low Non-Persistent CSMA Waits randomly if busy Low Slower Low P-Persistent CSMA Sends with chance in slots Medium Medium Medium CSMA (Aloha Fix) Checks before sending Medium Medium Low DAMA Reserves slots None (data) Medium High PRMA Keeps slots for data Low (after) Fast Medium D-PRMA PRMA with broadcasts Low (after) Fast Medium Reservation-TDMA Mini-slots for booking None (data) Medium High MACA RTS/CTS handshake Low Slower Medium Polling Central polling None Slow High Inhibit Sense Busy tone control High Medium Low"},{"location":"mobile-computing-unit%202/#process-flow-dama-example","title":"Process Flow (DAMA Example)","text":"<pre><code>graph TD\n    A[Device] --&gt;|Request Slot| B[Central System]\n    B --&gt;|Assign Slot| A\n    A --&gt;|Send Data in Slot| C[Network]</code></pre>"},{"location":"mobile-computing-unit%202/#comparison-of-multiplexing-techniques","title":"Comparison of Multiplexing Techniques","text":"Approach SDMA (Space Division) TDMA (Time Division) FDMA (Frequency Division) CDMA (Code Division) Idea Segment space into cells/sectors Segment sending time into disjoint time-slots Divide the frequency band into sub-bands Spread the spectrum using orthogonal codes Terminals Only one terminal active per cell/sector All terminals share the same frequency but transmit in time slots Each terminal has its own dedicated frequency All terminals can be active simultaneously using unique codes Signal Separation Cell structure with directed antennas Synchronization in the time domain Filtering in the frequency domain Codes and special receivers Advantages Simple, increases capacity per km\u00b2 Fully digital, very flexible Simple, robust, and well-established Highly flexible, less planning needed, supports soft handover Disadvantages Inflexible, fixed antennas required Guard space needed, synchronization is complex Inflexible, limited by available frequencies Complex receivers, requires precise power control Comment Used in combination with TDMA, FDMA, or CDMA Standard in fixed networks, often combined with FDMA/SDMA in mobile networks Often combined with TDMA (frequency hopping patterns) and SDMA (frequency reuse) Used in 3G systems, requires integration with TDMA/FDMA"},{"location":"mobile-computing-unit%203/","title":"Mobile computing unit 3","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%203/#logical-mobility","title":"Logical Mobility","text":"<p>Logical Mobility refers to the ability to transfer software components, code, or computational elements between different systems or devices.</p>"},{"location":"mobile-computing-unit%203/#types-of-logical-mobility","title":"Types of Logical Mobility","text":"<ul> <li>Software Programs &amp; Applications: Moving entire applications between devices.</li> <li>Code Segments &amp; Modules: Transferring scripts or functions dynamically.</li> <li>Objects &amp; Data Structures: Migrating serialized objects or database entries.</li> <li>Computational Processes: Shifting active processing tasks to another system.</li> </ul>"},{"location":"mobile-computing-unit%203/#examples","title":"Examples","text":"<ul> <li>App Downloads: Installing an application from an app store.</li> <li>Web Execution: A browser fetching and executing JavaScript from a server.</li> </ul>"},{"location":"mobile-computing-unit%203/#process-migration","title":"Process Migration","text":"<p>Process Migration is the transfer of an executing process from one computing system to another while maintaining its state.</p>"},{"location":"mobile-computing-unit%203/#key-aspects-of-process-migration","title":"Key Aspects of Process Migration","text":"<ul> <li>Process = Program Under Execution</li> <li>State Transfer Includes:</li> <li>Address Space: Memory and allocated resources.</li> <li>Execution Point: CPU register contents.</li> <li>Communication State: Open files, message channels.</li> <li>OS-dependent States: Any system-specific data.</li> </ul>"},{"location":"mobile-computing-unit%203/#migration-process","title":"Migration Process","text":"<ol> <li>Two Instances Exist: A source and destination process.</li> <li>Final Handoff: The destination instance takes over as the migrated process.</li> <li>Remote Execution: A process running on another machine is called a remote process.</li> </ol>"},{"location":"mobile-computing-unit%203/#example","title":"Example","text":"<ul> <li>Watching a movie on a smart TV, then continuing playback on a tablet while traveling.</li> </ul>"},{"location":"mobile-computing-unit%203/#process-migration-steps","title":"Process Migration Steps","text":""},{"location":"mobile-computing-unit%203/#step-1-migration-request-issued","title":"Step 1: Migration Request Issued","text":"<ul> <li>A migration request is sent to a remote node.</li> <li>After negotiation, the migration is accepted.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-2-process-detachment","title":"Step 2: Process Detachment","text":"<ul> <li>The process is suspended on the source node.</li> <li>It is marked as \"migrating.\"</li> <li>Communication is temporarily redirected.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_1","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-3-temporary-communication-redirection","title":"Step 3: Temporary Communication Redirection","text":"<ul> <li>Incoming messages are queued.</li> <li>Messages are delivered after migration.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_2","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-4-process-state-extraction","title":"Step 4: Process State Extraction","text":"<ul> <li>The process's memory, registers, communication state, and kernel context are extracted.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_3","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-5-destination-process-instance-created","title":"Step 5: Destination Process Instance Created","text":"<ul> <li>A new process instance is initialized on the remote node.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_4","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-6-state-transfer","title":"Step 6: State Transfer","text":"<ul> <li>The extracted state is transferred to the destination node.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_5","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-7-forwarding-references","title":"Step 7: Forwarding References","text":"<ul> <li>References (e.g., file descriptors, network sockets) are updated to point to the new process instance.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_6","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#step-8-process-resumed","title":"Step 8: Process Resumed","text":"<ul> <li>The new process instance resumes execution on the remote node.</li> </ul>"},{"location":"mobile-computing-unit%203/#diagram_7","title":"Diagram","text":""},{"location":"mobile-computing-unit%203/#advantages-of-process-migration","title":"Advantages of Process Migration","text":"<ol> <li>Dynamic Load Distribution</li> <li>Balances the load by migrating processes from overloaded nodes to less loaded ones.</li> <li>Fault Resilience</li> <li>Ensures continuity by migrating processes from nodes that have partially failed or are at risk of failure.</li> <li>Improved System Administration</li> <li>Facilitates maintenance by moving processes from nodes that are about to be shut down or become unavailable.</li> <li>Data Access Locality</li> <li>Enhances efficiency by migrating processes closer to the data source, especially useful in mobile environments.</li> <li>Resource Sharing</li> <li>Allows access to specialized hardware by migrating a process to a node equipped with the required resources.</li> <li>Mobile Computing</li> <li>Enables users to continue running applications seamlessly as they move between networks or devices.</li> </ol>"},{"location":"mobile-computing-unit%203/#applications-of-process-migration","title":"Applications of Process Migration","text":"<ul> <li>Parallelizable Applications: Distributing computational tasks across multiple nodes.</li> <li>Long-running Applications: Allowing execution across different nodes without interruption.</li> <li>Generic Multiuser Workloads: Managing distributed workloads effectively.</li> <li>Pre-emptable Applications: Processes that can be temporarily suspended and resumed elsewhere.</li> <li>Migration-aware Applications: Applications designed to adapt to migration scenarios.</li> <li>Network &amp; Mobile Computing Applications: Ensuring service continuity as devices move across networks.</li> </ul>"},{"location":"mobile-computing-unit%203/#alternatives-to-process-migration","title":"Alternatives to Process Migration","text":"<ol> <li>Remote Execution</li> <li>Executes code on a remote node instead of migrating the entire process.</li> <li>Faster than migration due to lower data transfer costs.</li> <li>Cloning</li> <li>Creates a copy of the process on a different node using a remote fork mechanism.</li> <li>Unlike migration, both instances continue running using distributed shared state.</li> <li>Higher complexity but useful when state inheritance is required.</li> <li>Mobile Agents</li> <li>Uses Java, Tcl/Tk, or other technologies to move objects or scripts dynamically.</li> <li>Achieved at the middleware level using frameworks like:<ul> <li>Common Object Request Broker Architecture (CORBA)</li> <li>Distributed Objects</li> </ul> </li> </ol>"},{"location":"mobile-computing-unit%203/#mobile-agents","title":"Mobile Agents","text":"<p>Mobile Agents are software entities that autonomously move between computers and continue execution on the destination machine.</p> <ul> <li>Self-driven: Can function independently, even if the user disconnects from the network.</li> <li>Transportable: They move dynamically across systems.</li> <li>Data-Carriers: Store information and operate without requiring continuous communication.</li> </ul>"},{"location":"mobile-computing-unit%203/#types-of-mobile-agents","title":"Types of Mobile Agents","text":"<ol> <li>Agents with Pre-defined Path</li> <li>Follow a specific, predetermined route across nodes.</li> <li>Agents with Undefined Path (Roamer)</li> <li>Wander freely across the network, dynamically choosing destinations.</li> </ol>"},{"location":"mobile-computing-unit%203/#properties-of-mobile-agents","title":"Properties of Mobile Agents","text":"<p>A Mobile Agent is a software object that exists within an execution environment and possesses these key traits:</p>"},{"location":"mobile-computing-unit%203/#mandatory-properties","title":"Mandatory Properties","text":"<ul> <li>Reactive: Responds to environmental changes.</li> <li>Autonomous: Controls its own actions.</li> <li>Goal-Driven: Works proactively towards objectives.</li> <li>Temporally Continuous: Runs indefinitely.</li> </ul>"},{"location":"mobile-computing-unit%203/#optional-properties","title":"Optional Properties","text":"<ul> <li>Communicative: Can interact with other agents.</li> <li>Mobile: Can migrate between hosts.</li> <li>Learning: Adapts based on past experiences.</li> </ul>"},{"location":"mobile-computing-unit%203/#life-cycle-of-mobile-agents","title":"Life Cycle of Mobile Agents","text":"<ul> <li>Adapts to both home and foreign environments.</li> <li>Switches between nodes as needed.</li> <li>Focuses on achieving the final objective.</li> <li>Operates autonomously without external intervention.</li> </ul>"},{"location":"mobile-computing-unit%203/#mobile-agent-platforms","title":"Mobile Agent Platforms","text":"<ul> <li>Specialized Servers: Interpret agent behavior and handle communication.</li> <li>Autonomous Navigation: Agents can choose and request migration.</li> <li>Platform-Independent Execution: Can run on any machine without pre-installation.</li> <li>Java-Based Execution: Uses Java Virtual Machine (JVM) to dynamically load code.</li> </ul>"},{"location":"mobile-computing-unit%203/#types-of-mobile-agents_1","title":"Types of Mobile Agents","text":"<ul> <li>One-hop Agents: Migrate to a single destination.</li> <li>Multi-hop Agents: Roam across multiple locations dynamically.</li> </ul>"},{"location":"mobile-computing-unit%203/#components-of-a-mobile-agent","title":"Components of a Mobile Agent","text":"<p>A Mobile Agent consists of two key components:</p> <ol> <li>Code: Instructions defining the agent\u2019s behavior.</li> <li>Execution State: The agent\u2019s progress and memory.</li> </ol> <p>Unlike regular programs where code is stored on disk and execution state is in RAM, mobile agents carry both together when migrating.</p>"},{"location":"mobile-computing-unit%203/#migration-process_1","title":"Migration Process","text":"<ul> <li>Agent moves: Carries both its code &amp; execution state.</li> <li>Resumes seamlessly at the new host.</li> </ul>"},{"location":"mobile-computing-unit%203/#characteristics-of-mobile-agents","title":"Characteristics of Mobile Agents","text":"<ul> <li>Unique Identity: Each agent has a distinct presence.</li> <li>Aware of Other Agents: Can detect and interact with other agents.</li> <li>Message Handling: Sends &amp; receives structured messages.</li> <li>Host Communication: Can communicate with its hosting environment.</li> <li>Concurrent Execution: Supports multiple agents running simultaneously.</li> </ul>"},{"location":"mobile-computing-unit%203/#agent-architecture","title":"Agent Architecture","text":""},{"location":"mobile-computing-unit%203/#mobile-agents-vs-process-migration","title":"Mobile Agents vs. Process Migration","text":"Aspect Mobile Agents Process Migration Control Autonomous decision-making; agents decide when and where to move. System-controlled; OS or network manager decides movement. Intelligence Built-in intelligence to adapt behavior. No built-in intelligence; follows system instructions. Decision Basis Moves based on programmed objectives and current needs. Moves based on system load and resource availability. Flexibility Can change destinations dynamically; supports multi-hop movement. Fixed source-to-destination migration; single-hop only. State Management Carries both code &amp; state together as a package. State must be captured, transferred, and reconstructed. Interaction Can communicate with other agents and systems. No inter-process communication during migration."},{"location":"mobile-computing-unit%203/#clientserver-vs-mobile-agent-architectures","title":"Client/Server vs. Mobile Agent Architectures","text":""},{"location":"mobile-computing-unit%203/#traditional-clientserver-model","title":"Traditional Client/Server Model","text":"<ul> <li>Requires continuous communication between client and server.</li> <li>Frequent request/response cycles increase network bandwidth usage.</li> </ul>"},{"location":"mobile-computing-unit%203/#mobile-agent-architecture","title":"Mobile Agent Architecture","text":"<ul> <li>Moves queries/transactions from client to server, reducing repetitive requests.</li> <li>Works offline and syncs results when the system is back online.</li> <li>Handles intermittent &amp; unreliable networks effectively.</li> </ul>"},{"location":"mobile-computing-unit%203/#requirements-for-mobile-agent-systems","title":"Requirements for Mobile Agent Systems","text":"<ol> <li>Portability: Must run on different platforms without modifications.</li> <li>Ubiquity: Should be available across multiple network environments.</li> <li>Network Communication: Needs efficient mechanisms for sending/receiving data.</li> <li>Server Security: Must prevent unauthorized agent execution on a host.</li> <li>Agent Security: Protects agents from external threats or modifications.</li> <li>Resource Accounting: Tracks resource consumption for optimization.</li> </ol>"},{"location":"mobile-computing-unit%203/#diagram-mobile-agent-vs-client-server-communication","title":"Diagram: Mobile Agent vs. Client-Server Communication","text":"<pre><code>sequenceDiagram\n    participant Client\n    participant Server\n    Client-&gt;&gt;Server: Request Data\n    Server--&gt;&gt;Client: Response\n    Client-&gt;&gt;Server: Another Request\n    Server--&gt;&gt;Client: Another Response</code></pre>"},{"location":"mobile-computing-unit%203/#aglets-java-based-mobile-agent-platform","title":"Aglets: Java-Based Mobile Agent Platform","text":"<p>Aglets are a Java-based framework for mobile agents, designed by IBM. They allow objects to move between hosts on a network while maintaining their execution state.</p>"},{"location":"mobile-computing-unit%203/#how-aglets-work","title":"How Aglets Work","text":"<ul> <li>An Aglet can pause execution, move to a remote host, and resume execution.</li> <li>When an Aglet moves, it carries its code and object states to the new host.</li> <li>Multiple Aglets can run on a single node within different contexts.</li> </ul>"},{"location":"mobile-computing-unit%203/#aglet-context","title":"Aglet Context","text":"<p>An Aglet Context is the workspace where Aglets operate.</p> <ul> <li>Stationary Object: Provides a uniform execution environment.</li> <li>Hosts Multiple Contexts: A single network node can run multiple contexts.</li> </ul>"},{"location":"mobile-computing-unit%203/#aglet-proxy","title":"Aglet Proxy","text":"<p>A proxy is a representative of an Aglet that: - Shields the Aglet from direct access to its public methods. - Hides its real location, ensuring location transparency.</p>"},{"location":"mobile-computing-unit%203/#aglet-life-cycle","title":"Aglet Life Cycle","text":"Stage Description Creation Aglet is created within a context, assigned an identifier, and initialized. Execution starts immediately. Cloning Produces an identical copy of the Aglet in the same context, with a new identifier. Dispatching Moves the Aglet to another context, removing it from the current one. Execution restarts at the destination. Retraction Pulls the Aglet back to its original context after being dispatched. Deactivation Temporarily removes an Aglet from execution and stores it in secondary storage. Activation Restores a deactivated Aglet back into a context. Disposal Stops execution and removes the Aglet from the context permanently."},{"location":"mobile-computing-unit%203/#aglet-communication","title":"Aglet Communication","text":"<p>Aglets use messages and events to communicate and interact within their environment.</p>"},{"location":"mobile-computing-unit%203/#message-communication","title":"Message Communication","text":"<ul> <li>Synchronous: Requires an immediate response.</li> <li>Asynchronous: Messages are sent without waiting for an immediate reply.</li> </ul>"},{"location":"mobile-computing-unit%203/#event-driven-communication","title":"Event-Driven Communication","text":"<ul> <li>Used for reactive or proactive agents.</li> <li>Example: An Aglet can listen for a stock price change event and act accordingly.</li> </ul>"},{"location":"mobile-computing-unit%203/#aglet-api-java-based","title":"Aglet API (Java-based)","text":"<ul> <li><code>Aglet</code>: Core agent class.</li> <li><code>Aglet Proxy</code>: Ensures security and location transparency.</li> <li><code>Aglet Context</code>: Execution environment for Aglets.</li> <li><code>Message</code>: Communication mechanism.</li> </ul>"},{"location":"mobile-computing-unit%203/#applications-of-aglets","title":"Applications of Aglets","text":"<ul> <li>E-commerce: Mobile shopping assistants.</li> <li>E-marketplaces: Automated price comparison &amp; negotiation.</li> <li>Travel &amp; Tourism: Dynamic air-ticket booking &amp; package tour planning.</li> </ul>"},{"location":"mobile-computing-unit%203/#aglet-event-model","title":"Aglet Event Model","text":"<p>Aglets operate in an event-driven programming model. There are three types of listeners that handle different events:</p> Listener Type Function Clone Listener Handles events before, during, and after an Aglet is cloned. Mobility Listener Triggers actions before dispatching, during movement, and upon arrival at a new context. Persistence Listener Manages events before deactivation and after activation of an Aglet."},{"location":"mobile-computing-unit%203/#diagram-aglet-event-flow","title":"Diagram: Aglet Event Flow","text":"<pre><code>graph TD\n    A[Aglet Running] --&gt;|Clone Event| B[Clone Listener]\n    A --&gt;|Migration Event| C[Mobility Listener]\n    A --&gt;|Deactivation Event| D[Persistence Listener]</code></pre>"},{"location":"mobile-computing-unit%204/","title":"Mobile computing unit 4","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%204/#understanding-ipv4","title":"Understanding IPv4","text":"<p>An IP address (Internet Protocol address) is a unique identifier assigned to each device connected to a network using the Internet Protocol. It serves two main purposes:</p> <ul> <li>Identification: Uniquely identifies a device on a network.</li> <li>Location Addressing: Indicates where a device is located within a network, enabling data routing.</li> </ul> <p>Note</p> <p>IP addresses are essential for devices to communicate over the internet, ensuring proper identification and data transmission.</p>"},{"location":"mobile-computing-unit%204/#ipv4-format","title":"IPv4 Format","text":"<p>IPv4 (Internet Protocol Version 4) is the most widely used system for identifying devices on a network. It uses a 32-bit addressing scheme, represented as four numbers separated by periods.</p>"},{"location":"mobile-computing-unit%204/#example","title":"Example","text":"<pre><code>192.168.0.1\n</code></pre> <p>Each number (octet) can range from 0 to 255.</p> <p>Tip</p> <p>IPv4 supports approximately 4.3 billion unique addresses, which is why IPv6 was introduced to handle the growing number of devices.</p>"},{"location":"mobile-computing-unit%204/#mobile-ipv4","title":"Mobile IPv4","text":"<p>Mobile IPv4 is a protocol that enables devices to maintain their IP address and network connectivity while moving between different networks.</p>"},{"location":"mobile-computing-unit%204/#key-benefits","title":"Key Benefits","text":"<ul> <li>Ensures continuous network connections when a device changes its network (e.g., switching from Wi-Fi to cellular data).</li> <li>Maintains seamless communication for mobile users.</li> </ul> <p>Warning</p> <p>Without Mobile IPv4, devices would lose their network sessions when changing networks, leading to dropped connections and data loss.</p>"},{"location":"mobile-computing-unit%204/#agent-advertisement","title":"Agent Advertisement","text":"<p>Agent Advertisement is a process where Home Agents (HA) and Foreign Agents (FA) periodically send advertisement messages into their physical subnets.</p>"},{"location":"mobile-computing-unit%204/#how-it-works","title":"How It Works","text":"<ul> <li>HA/FA broadcast advertisement messages (ICMP messages) into the subnet.</li> <li>These messages act as beacons to notify Mobile Nodes (MN) of available networks.</li> <li>Packet Details:</li> <li>TTL (Time To Live): Set to 1 to prevent forwarding.</li> <li>Destination Address:<ul> <li>224.0.0.1 (Multicast Address) or</li> <li>255.255.255.255 (Broadcast Address)</li> </ul> </li> <li>Mobile Node (MN) Actions:</li> <li>Listens for advertisement messages.</li> <li>Detects if it's in a home or foreign network.</li> <li>Reads a Care-of Address (COA) from FA advertisement messages.</li> </ul> Field Value TTL 1 (Prevents forwarding) Destination Address 224.0.0.1 (Multicast) Destination Address 255.255.255.255 (Broadcast) <p>Note</p> <p>The Care-of Address (COA) allows the mobile device to register its new location while roaming, ensuring uninterrupted communication.</p> <p></p>"},{"location":"mobile-computing-unit%204/#mobile-ip-basic-operation","title":"Mobile IP: Basic Operation","text":""},{"location":"mobile-computing-unit%204/#agent-solicitation","title":"Agent Solicitation","text":"<p>If no agent advertisements are present, or if the time between two advertisements is too high, the mobile node must send an Agent Solicitation message.</p> <ul> <li>The solicitation message should not flood the network.</li> <li>A mobile node can send up to three solicitations per second upon entering a foreign network.</li> <li>If no response is received, the solicitation rate decreases exponentially to avoid network congestion.</li> <li>Agent discovery allows the mobile node to establish a better connection.</li> <li>Once an agent is discovered, the mobile node obtains a Care-of Address (COA).</li> </ul>"},{"location":"mobile-computing-unit%204/#registration-request","title":"Registration Request","text":"<p>Registration requests use UDP packets with the following structure:</p> <ul> <li>Source Address: Mobile Node (MN) IP address.</li> <li>Destination Address: Home Agent (HA) or Foreign Agent (FA) IP address (depending on COA location).</li> <li>Type Field: Set to 1 to indicate a registration request.</li> <li>Flags:</li> <li>S \u2013 Request Home Agent to retain previous mobility binding.</li> <li>B \u2013 Request to receive broadcast packets from the home network.</li> <li>D \u2013 Mobile Node will handle decapsulation at the tunnel (if COA is located at MN).</li> <li>M/G \u2013 Defines encapsulation type.</li> <li>T \u2013 Enables reverse tunneling.</li> <li>Lifetime: Defines the validity of the registration (in seconds).</li> <li>Home Address: Fixed IP address of the Mobile Node.</li> <li>Home Agent: IP address of the Home Agent.</li> <li>COA (Care-of Address): Represents the tunnel endpoint.</li> <li>Identification: 64-bit identifier generated by MN to match registration requests and replies, preventing replay attacks.</li> </ul> <p></p>"},{"location":"mobile-computing-unit%204/#registration-reply","title":"Registration Reply","text":"<p>Once a registration request is processed, a registration reply is sent back using UDP packets:</p> <ul> <li>Type Field: Set to 3 to indicate a registration reply.</li> <li>Code Field: Specifies the result of the registration request.</li> </ul> <p>Tip</p> <p>Registration replies confirm whether a Mobile Node's registration was successful and provide status codes for troubleshooting.</p>"},{"location":"mobile-computing-unit%204/#types-of-encapsulation","title":"Types of Encapsulation","text":"<p>Encapsulation is essential in Mobile IP to ensure packets reach the Care-of Address (COA). The Home Agent (HA) takes the original packet (with the Mobile Node (MN) as the destination), places it inside the data portion of a new packet, and sets a new IP header so that it is correctly routed to the COA.</p> <p>The newly added IP header is called the outer header.</p>"},{"location":"mobile-computing-unit%204/#encapsulation-methods","title":"Encapsulation Methods","text":"<p>There are three primary types of encapsulation:</p> <ol> <li>IP-in-IP Encapsulation</li> <li>Minimal Encapsulation</li> <li>Generic Routing Encapsulation (GRE)</li> </ol>"},{"location":"mobile-computing-unit%204/#ip-in-ip-encapsulation","title":"IP-in-IP Encapsulation","text":"<ul> <li>Defined in RFC 2003 (Mandatory)</li> <li>Creates a tunnel between the Home Agent (HA) and the COA.</li> <li>The entire original IP packet is encapsulated within a new IP header.</li> <li>Used when the MN is using a foreign agent COA.</li> </ul>"},{"location":"mobile-computing-unit%204/#minimal-encapsulation","title":"Minimal Encapsulation","text":"<ul> <li>Reduces redundancy present in IP-in-IP encapsulation.</li> <li>Only essential fields from the original header are included.</li> <li>Helps in reducing overhead, improving efficiency.</li> </ul>"},{"location":"mobile-computing-unit%204/#generic-routing-encapsulation-gre","title":"Generic Routing Encapsulation (GRE)","text":"<ul> <li>Unlike IP-in-IP and Minimal Encapsulation, which work only for IP packets, GRE supports other network layer protocols.</li> <li>Allows encapsulation of different protocol suites into the payload portion of a packet.</li> <li>Uses an outer IP header, with TTL and TOS values copied from the original header.</li> <li>Provides flexibility for non-IP protocols to be transported over an IP network.</li> </ul> <p>Note</p> <p>GRE is widely used in VPNs and multicast routing to carry non-IP traffic efficiently over an IP-based network.</p> <p></p> <p></p>"},{"location":"mobile-computing-unit%204/#mobile-ip-and-ipv6","title":"Mobile IP and IPv6","text":""},{"location":"mobile-computing-unit%204/#key-features-of-mobile-ip-in-ipv6","title":"Key Features of Mobile IP in IPv6","text":"<ul> <li>Integrated Security: Unlike IPv4, security is built into IPv6 rather than being an add-on. Authentication for registration is included.</li> <li>Auto-Configuration of COA:</li> <li>IPv6 supports automatic configuration of the Care-of Address (COA).</li> <li>DHCPv6 can be used for dynamic COA assignment.</li> <li>Every IPv6 node has built-in address auto-configuration.</li> <li>No Need for a Foreign Agent (FA):</li> <li>In IPv6, all routers perform router advertisements, eliminating the need for a dedicated Foreign Agent.</li> <li>Direct COA Signaling (Route Optimization):</li> <li>The Mobile Node (MN) can directly inform a sender of its COA, bypassing the Home Agent (HA).</li> <li>This enables automatic path optimization, reducing latency.</li> <li>Soft Handovers (Seamless Mobility):</li> <li>IPv6 supports smooth handovers without packet loss between subnets.</li> <li>The MN sends its new COA to the old router.</li> <li>The old router encapsulates and forwards packets to the new COA.</li> <li>Authentication remains intact throughout the process.</li> </ul>"},{"location":"mobile-computing-unit%204/#dynamic-host-configuration-protocol-dhcp","title":"Dynamic Host Configuration Protocol (DHCP)","text":""},{"location":"mobile-computing-unit%204/#overview-of-dhcp","title":"Overview of DHCP","text":"<ul> <li>DHCP is a standardized networking protocol used by servers to dynamically allocate IP addresses to computers in a network.</li> <li>Primary Purpose: Automates IP configuration without requiring a network administrator.</li> </ul>"},{"location":"mobile-computing-unit%204/#how-dhcp-works","title":"How DHCP Works","text":"<ol> <li>IP Address Allocation</li> <li>DHCP assigns IP addresses from a predefined range stored in a server database.</li> <li>Each IP is assigned for a lease period, after which the device must renew or acquire a new address.</li> <li>Full Network Integration</li> <li>DHCP provides additional configuration details:<ul> <li>DNS Server Address</li> <li>Default Gateway (Router)</li> <li>Subnet Mask</li> <li>Domain Name</li> <li>IP Address</li> </ul> </li> </ol>"},{"location":"mobile-computing-unit%204/#dhcp-client-server-model","title":"DHCP Client-Server Model","text":"<ul> <li>DHCP follows a client/server model where clients request IP configurations from servers.</li> <li>Clients send broadcast requests using MAC addresses to find available DHCP servers.</li> <li>A DHCP relay agent forwards requests if servers are in a different network segment.</li> </ul>"},{"location":"mobile-computing-unit%204/#dhcp-process","title":"DHCP Process","text":"<ol> <li>Client broadcasts a DHCPDISCOVER to find available DHCP servers.</li> <li>DHCP servers respond with DHCPOFFER, listing available configurations.</li> <li>Client sends a DHCPREQUEST to accept one configuration and reject others.</li> <li>Selected server sends a DHCPACK, confirming the lease.</li> <li>If the client leaves the subnet, it sends a DHCPRELEASE to free the assigned IP.</li> </ol>"},{"location":"mobile-computing-unit%204/#dhcp-in-mobile-ip","title":"DHCP in Mobile IP","text":"<ul> <li>DHCP is a strong candidate for Care-of Address (COA) assignment in Mobile IP.</li> <li>Security Concern: Without authentication, neither the Mobile Node (MN) nor the DHCP server can trust each other.</li> </ul>"},{"location":"mobile-computing-unit%204/#mobile-transport-layer","title":"Mobile Transport Layer","text":""},{"location":"mobile-computing-unit%204/#why-transport-layer-support-is-needed-for-mobility","title":"Why Transport Layer Support is Needed for Mobility","text":"<ul> <li>Mobile networks introduce challenges beyond just network-layer mobility.</li> <li>The Transport Layer plays a critical role in:</li> <li>Checksumming over user data.</li> <li>Multiplexing/Demultiplexing data to and from applications.</li> </ul>"},{"location":"mobile-computing-unit%204/#udp-user-datagram-protocol","title":"UDP (User Datagram Protocol)","text":"<ul> <li>Simple addressing mechanism.</li> <li>Connectionless (No established connection).</li> <li>No reliability guarantees (No retransmission, no in-order delivery).</li> </ul>"},{"location":"mobile-computing-unit%204/#udp-vs-tcp-in-mobile-networks","title":"UDP vs. TCP in Mobile Networks","text":"Feature UDP TCP Connection Type Connectionless Connection-oriented Reliability No reliability Reliable (retransmissions, acknowledgments) Congestion Control None Reduces speed in case of network congestion Order of Delivery No guarantee Ensures in-order delivery Usage in Mobility Suitable for real-time applications Requires adaptation for mobile networks"},{"location":"mobile-computing-unit%204/#challenges-of-tcp-in-mobile-networks","title":"Challenges of TCP in Mobile Networks","text":"<ul> <li>TCP assumes packet loss is due to network congestion, reducing the transmission rate unnecessarily.</li> <li>Mobile networks require optimized TCP for 3G, 4G, and 5G environments.</li> </ul>"},{"location":"mobile-computing-unit%204/#traditional-tcp-and-congestion-control","title":"Traditional TCP and Congestion Control","text":"<p>TCP was originally designed for fixed networks with stable end-systems where:</p> <ul> <li>Hardware introduces minimal transmission errors.</li> <li>Packet loss typically occurs due to network congestion.</li> <li>Routers drop packets when overloaded.</li> </ul>"},{"location":"mobile-computing-unit%204/#how-does-the-sender-detect-packet-loss","title":"How Does the Sender Detect Packet Loss?","text":"<ul> <li>Missing Acknowledgements (ACKs).</li> </ul>"},{"location":"mobile-computing-unit%204/#incorrect-approach","title":"Incorrect Approach","text":"<p>Simply retransmitting the missing packet without adjusting the transmission rate.</p>"},{"location":"mobile-computing-unit%204/#correct-approach","title":"Correct Approach","text":"<p>TCP slows down dramatically using congestion control mechanisms.</p>"},{"location":"mobile-computing-unit%204/#tcp-slow-start","title":"TCP Slow Start","text":"<p>After detecting congestion, TCP enters Slow Start mode:</p> <ul> <li>The congestion window (cwnd) begins at 1 segment.</li> <li>For every successful ACK, cwnd doubles (exponential growth).</li> <li>Growth continues until reaching a threshold (ssthresh).</li> <li>After reaching ssthresh, TCP switches to linear increase.</li> </ul>"},{"location":"mobile-computing-unit%204/#conditions-for-stopping-growth","title":"Conditions for Stopping Growth","text":"<ol> <li>Time-out due to missing ACK.</li> <li>Multiple ACKs for the same packet (duplicate ACKs).</li> </ol>"},{"location":"mobile-computing-unit%204/#tcp-congestion-control-steps","title":"TCP Congestion Control Steps","text":"Condition Action Taken First packet drop detected Reduce ssthresh to half Restart slow start Reset cwnd to 1 segment Continue with linear increase Until new loss occurs"},{"location":"mobile-computing-unit%204/#fast-retransmit-and-fast-recovery","title":"Fast Retransmit and Fast Recovery","text":""},{"location":"mobile-computing-unit%204/#fast-retransmit","title":"Fast Retransmit","text":"<ul> <li>If multiple duplicate ACKs are received before a timeout, the sender immediately retransmits the lost packet.</li> <li>Avoids waiting for the retransmission timer.</li> </ul>"},{"location":"mobile-computing-unit%204/#fast-recovery","title":"Fast Recovery","text":"<ul> <li>Instead of resetting to slow start, TCP continues with the current congestion window.</li> <li>This prevents unnecessary performance degradation.</li> </ul> <p>Tip</p> <p>Fast retransmit helps avoid unnecessary delays and ensures smoother TCP performance.</p>"},{"location":"mobile-computing-unit%204/#implications-of-tcp-on-mobility","title":"Implications of TCP on Mobility","text":"<p>TCP performs poorly in mobile environments due to incorrect assumptions.</p>"},{"location":"mobile-computing-unit%204/#incorrect-assumptions","title":"Incorrect Assumptions","text":"<ul> <li>Packet loss = Network congestion (but mobile networks lose packets due to handovers).</li> <li>Wireless error rates = Wired error rates (wireless links are more error-prone).</li> </ul>"},{"location":"mobile-computing-unit%204/#mobile-ip-issue","title":"Mobile IP Issue","text":"<ul> <li>Packets in transit to the old Foreign Agent (FA) are lost when the Mobile Node (MN) moves.</li> <li>TCP cannot differentiate between congestion-based and mobility-based packet losses.</li> </ul> <p>Warning</p> <p>TCP uses error control mechanisms to handle network congestion, which is not ideal for mobile networks.</p>"},{"location":"mobile-computing-unit%204/#tcp-improvements-indirect-tcp-i-tcp","title":"TCP Improvements: Indirect TCP (I-TCP)","text":""},{"location":"mobile-computing-unit%204/#how-i-tcp-works","title":"How I-TCP Works","text":"<ul> <li>Keeps standard TCP for fixed networks.</li> <li>Uses an optimized TCP for mobile devices.</li> <li>Splits the TCP connection at the Foreign Agent (FA) into two separate connections.</li> </ul>"},{"location":"mobile-computing-unit%204/#process","title":"Process","text":"<ol> <li>Correspondent host sends a packet.</li> <li>Foreign Agent acknowledges and forwards it to the Mobile Node.</li> <li>Any packet loss in the wireless network is handled by the Foreign Agent.</li> <li>If handover occurs, socket state (sequence numbers, ports, etc.) is migrated.</li> </ol>"},{"location":"mobile-computing-unit%204/#advantages-of-i-tcp","title":"Advantages of I-TCP","text":"<ul> <li>No changes needed in existing TCP implementations.</li> <li>Wireless errors don\u2019t affect fixed networks.</li> <li>Faster packet loss recovery (shorter wireless delays).</li> <li>Allows different transport protocols between FA and MN.</li> </ul> <p>Note</p> <p>I-TCP enhances TCP performance in wireless environments without altering fixed-network implementations.</p>"},{"location":"mobile-computing-unit%204/#disadvantages-of-i-tcp","title":"Disadvantages of I-TCP","text":"<ul> <li>Loses TCP\u2019s end-to-end reliability if FA crashes.</li> <li>Increased handover latency due to buffering at FA.</li> <li>Security risks: FA must be trusted, especially for encrypted data.</li> </ul> <p>Warning</p> <p>If the Foreign Agent crashes, the entire session might fail, causing disruptions.</p>"},{"location":"mobile-computing-unit%204/#summary-of-tcp-enhancements","title":"Summary of TCP Enhancements","text":"Feature Standard= Standard TCP Fast Retransmit I-TCP Handles congestion Yes Yes Yes Works in mobile networks No No Yes Requires protocol changes No No Yes Improves packet loss recovery No Yes Yes Preserves end-to-end connection Yes Yes No <p>Tip</p> <p>I-TCP is a powerful improvement for mobile networks, but it compromises end-to-end reliability.</p>"},{"location":"mobile-computing-unit%204/#snooping-tcp","title":"Snooping TCP","text":"<p>One of the drawbacks of I-TCP is the segmentation of the TCP connection, which violates end-to-end TCP semantics. Snooping TCP offers a transparent extension of TCP at the Foreign Agent (FA) to mitigate this issue.</p>"},{"location":"mobile-computing-unit%204/#how-snooping-tcp-works","title":"How Snooping TCP Works","text":"<ul> <li>The Foreign Agent (FA) buffers packets sent to the mobile host (MH) until an ACK is received.</li> <li>FA monitors (snoops) the packet flow in both directions.</li> <li>If a packet is lost on the wireless link, FA immediately retransmits it (local retransmission).</li> <li>The FA filters duplicate ACKs and prevents unnecessary congestion control actions in the fixed network.</li> </ul>"},{"location":"mobile-computing-unit%204/#data-transfer-mechanism","title":"Data Transfer Mechanism","text":"<ul> <li>To the Mobile Host:</li> <li>FA buffers data until it receives an ACK from MH.</li> <li>If a duplicate ACK or timeout occurs, FA quickly retransmits the packet.</li> <li>From the Mobile Host:</li> <li>FA detects lost packets via sequence numbers.</li> <li>FA sends a Negative Acknowledgment (NACK) to MH for quick retransmission.</li> </ul>"},{"location":"mobile-computing-unit%204/#integration-with-mac-layer","title":"Integration with MAC Layer","text":"<ul> <li>The MAC layer already detects duplicate packets due to retransmissions.</li> <li>This prevents redundant retransmissions by TCP.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages-of-snooping-tcp","title":"Advantages of Snooping TCP","text":"<ul> <li>Preserves end-to-end semantics (FA does not acknowledge data on behalf of MH).</li> <li>Reduces packet loss impact on wireless links.</li> <li>No changes required in the fixed network.</li> </ul>"},{"location":"mobile-computing-unit%204/#mobile-tcp-m-tcp","title":"Mobile TCP (M-TCP)","text":""},{"location":"mobile-computing-unit%204/#why-m-tcp","title":"Why M-TCP?","text":"<p>M-TCP improves overall TCP performance in mobile environments by: - Maintaining end-to-end TCP semantics. - Reducing delay in case of handovers. - Enhancing throughput and handling frequent disconnections.</p>"},{"location":"mobile-computing-unit%204/#how-m-tcp-works","title":"How M-TCP Works","text":"<p>Like I-TCP, M-TCP splits the TCP connection, but with key differences: - Uses a Supervisory Host (SH) instead of a Foreign Agent. - SH does not cache or retransmit packets. - If disconnection is detected, SH sets sender window size to 0. - The sender goes into persistent mode, preventing unnecessary retransmissions. - When connectivity is restored, SH restores the sender window to its original value.</p>"},{"location":"mobile-computing-unit%204/#advantages-of-m-tcp","title":"Advantages of M-TCP","text":"<ul> <li>Preserves end-to-end TCP semantics (SH does not modify ACKs).</li> <li>Handles disconnections efficiently without slow starts.</li> <li>No buffering at SH, reducing memory usage.</li> </ul>"},{"location":"mobile-computing-unit%204/#disadvantages-of-m-tcp","title":"Disadvantages of M-TCP","text":"<ul> <li>Packet loss on wireless links affects the fixed network.</li> <li>Requires modifications to both MH protocol stack and network infrastructure.</li> </ul>"},{"location":"mobile-computing-unit%204/#fast-retransmit-fast-recovery","title":"Fast Retransmit / Fast Recovery","text":"<p>This approach forces TCP\u2019s Fast Retransmit mechanism to handle handovers efficiently.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_1","title":"How It Works","text":"<ul> <li>When the mobile host (MH) moves to a new Foreign Agent (FA), it immediately sends duplicate ACKs to the Correspondent Host (CH).</li> <li>Sending three duplicate ACKs triggers Fast Retransmit at CH.</li> <li>This prevents Slow Start, improving handover performance.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages","title":"Advantages","text":"<ul> <li>Simple to implement.</li> <li>Faster recovery from handover-related losses.</li> </ul>"},{"location":"mobile-computing-unit%204/#disadvantages","title":"Disadvantages","text":"<ul> <li>Retransmitted packets still travel through the entire network.</li> <li>If handover takes too long, CH may initiate retransmissions prematurely.</li> <li>This approach does not address wireless link issues.</li> </ul>"},{"location":"mobile-computing-unit%204/#transmission-timeout-freezing","title":"Transmission / Timeout Freezing","text":"<p>TCP performance degrades in long interruptions (e.g., tunnels, no coverage areas). Timeout Freezing prevents unnecessary retransmissions.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_2","title":"How It Works","text":"<ul> <li>The MAC layer detects connection loss early.</li> <li>TCP pauses timers and freezes the congestion window.</li> <li>Once connectivity is restored, TCP resumes from the exact point it was stopped.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_1","title":"Advantages","text":"<ul> <li>Prevents unnecessary retransmissions during long disconnections.</li> <li>Maintains TCP state without requiring modifications in the fixed network.</li> <li>Works independently of acknowledgments or sequence numbers.</li> </ul>"},{"location":"mobile-computing-unit%204/#disadvantages_1","title":"Disadvantages","text":"<ul> <li>Relies on MAC layer to detect interruptions accurately.</li> <li>Encryption mechanisms with time-dependent keys may cause issues.</li> </ul>"},{"location":"mobile-computing-unit%204/#selective-retransmission","title":"Selective Retransmission","text":""},{"location":"mobile-computing-unit%204/#why-its-needed","title":"Why It\u2019s Needed","text":"<p>Standard TCP cumulatively acknowledges packets. If a single packet is lost, TCP retransmits all subsequent packets, wasting bandwidth.</p>"},{"location":"mobile-computing-unit%204/#how-selective-retransmission-works","title":"How Selective Retransmission Works","text":"<ul> <li>The receiver requests only the lost packets.</li> <li>The sender sends the missing packets instead of retransmitting everything.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_2","title":"Advantages","text":"<ul> <li>Minimizes retransmission overhead, especially in wireless networks.</li> <li>Improves efficiency on low-bandwidth connections.</li> </ul>"},{"location":"mobile-computing-unit%204/#disadvantages_2","title":"Disadvantages","text":"<ul> <li>Requires additional buffer space at the receiver.</li> <li>More complex implementation compared to standard TCP.</li> </ul>"},{"location":"mobile-computing-unit%204/#transaction-oriented-tcp","title":"Transaction-Oriented TCP","text":""},{"location":"mobile-computing-unit%204/#problem-with-traditional-tcp","title":"Problem with Traditional TCP","text":"<p>For short-lived requests, such as a mobile host sending a single request to a server, TCP\u2019s connection setup overhead is too high.</p>"},{"location":"mobile-computing-unit%204/#issues-with-standard-tcp-for-transactions","title":"Issues with Standard TCP for Transactions","text":"<ul> <li>Three-way handshake for connection setup.</li> <li>Multiple packets needed for transmission.</li> <li>Three more packets for connection teardown.</li> <li>If the data fits in one packet, TCP still requires seven packets.</li> </ul>"},{"location":"mobile-computing-unit%204/#solution-transaction-oriented-tcp","title":"Solution: Transaction-Oriented TCP","text":"<ul> <li>Reduces TCP overhead for short transactions.</li> <li>Uses minimal packet exchanges.</li> <li>T/TCP can combine packets for connection establishment and connection release with user data packets.</li> <li>This can reduce the number of packets down to two instead of seven.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantage-for-certain-applications","title":"Advantage for Certain Applications","text":"<p>The reduction in the overhead which standard TCP has for connection setup and connection release.</p>"},{"location":"mobile-computing-unit%204/#disadvantage","title":"Disadvantage","text":"<p>T/TCP is not the original TCP anymore, so it requires changes in the mobile host and all correspondent hosts.</p>"},{"location":"mobile-computing-unit%204/#tcp-enhancements-for-wireless-and-mobile-networks","title":"TCP Enhancements for Wireless and Mobile Networks","text":""},{"location":"mobile-computing-unit%204/#introduction","title":"Introduction","text":"<p>Transmission Control Protocol (TCP) was originally designed for wired networks, where packet loss is primarily due to congestion. However, in wireless and mobile networks, factors such as high latency, jitter, and packet loss due to handovers or signal interference significantly degrade TCP performance. This document explores various TCP improvements tailored for wireless environments.</p>"},{"location":"mobile-computing-unit%204/#snooping-tcp_1","title":"Snooping TCP","text":"<p>Note</p> <p>Snooping TCP is a transparent extension of TCP within the foreign agent (FA) to optimize performance in mobile networks.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_3","title":"How It Works","text":"<ul> <li>The foreign agent (FA) buffers packets destined for the mobile host (MH) until an acknowledgment (ACK) is received.</li> <li>If a packet is lost on the wireless link, the FA retransmits it locally instead of relying on the original sender.</li> <li>The FA snoops acknowledgments and filters duplicate ACKs, reducing unnecessary retransmissions.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_3","title":"Advantages","text":"<ul> <li>Preserves end-to-end TCP semantics by acknowledging only when the MH responds.</li> <li>Faster retransmissions as lost packets are handled locally.</li> <li>Works transparently without modifications to the TCP sender.</li> </ul>"},{"location":"mobile-computing-unit%204/#limitations","title":"Limitations","text":"<ul> <li>Requires modifications at the foreign agent.</li> <li>Does not work with encrypted TCP headers (e.g., IPsec).</li> </ul>"},{"location":"mobile-computing-unit%204/#mobile-tcp-m-tcp_1","title":"Mobile TCP (M-TCP)","text":"<p>Tip</p> <p>M-TCP improves throughput while maintaining end-to-end TCP semantics and ensuring efficient handovers.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_4","title":"How It Works","text":"<ul> <li>Supervisory Host (SH) monitors TCP traffic but does not cache or retransmit packets.</li> <li>If the mobile host disconnects, the SH sets the sender\u2019s TCP window size to zero, preventing unnecessary retransmissions.</li> <li>Once connectivity is restored, the window is reopened at the previous value, resuming normal data transfer.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_4","title":"Advantages","text":"<ul> <li>Supports long disconnections without breaking connections.</li> <li>Prevents slow start by maintaining the sender\u2019s state.</li> <li>No buffering at the supervisory host, reducing overhead.</li> </ul>"},{"location":"mobile-computing-unit%204/#limitations_1","title":"Limitations","text":"<ul> <li>Packet loss on the wireless link affects the fixed network.</li> <li>Requires modifications to the mobile host\u2019s TCP stack.</li> </ul>"},{"location":"mobile-computing-unit%204/#fast-retransmit-fast-recovery_1","title":"Fast Retransmit &amp; Fast Recovery","text":"<p>Warning</p> <p>This method artificially triggers fast retransmission to prevent slow start during handovers.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_5","title":"How It Works","text":"<ul> <li>When a mobile host moves to a new foreign agent, it sends three duplicate ACKs to the correspondent host.</li> <li>This forces the correspondent host into fast retransmit mode without triggering slow start.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_5","title":"Advantages","text":"<ul> <li>Reduces delay during handovers.</li> <li>Simple to implement with minor modifications.</li> </ul>"},{"location":"mobile-computing-unit%204/#limitations_2","title":"Limitations","text":"<ul> <li>Inefficient for networks with high latency.</li> <li>If the handover is slow, the retransmitted packets may arrive too late.</li> </ul> <pre><code>Example: Mobile host sends 3 duplicate ACKs -&gt; Fast retransmit triggered\n</code></pre>"},{"location":"mobile-computing-unit%204/#transmission-timeout-freezing_1","title":"Transmission Timeout Freezing","text":"<p>Note</p> <p>When a long disconnection (e.g., moving through a tunnel) is detected, TCP freezes its state to prevent timeouts.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_6","title":"How It Works","text":"<ul> <li>The MAC layer detects a connection issue before TCP is interrupted.</li> <li>TCP pauses timers and stops retransmissions, maintaining the congestion window state.</li> <li>Once connectivity is restored, TCP resumes without triggering slow start.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_6","title":"Advantages","text":"<ul> <li>Ideal for long interruptions (e.g., tunnels, network congestion).</li> <li>Independent of TCP mechanisms like sequence numbers and acknowledgments.</li> </ul>"},{"location":"mobile-computing-unit%204/#limitations_3","title":"Limitations","text":"<ul> <li>Requires MAC layer awareness of connection issues.</li> <li>Does not work with encryption methods that rely on timestamps.</li> </ul>"},{"location":"mobile-computing-unit%204/#selective-retransmission_1","title":"Selective Retransmission","text":"<p>Tip</p> <p>Instead of retransmitting all unacknowledged packets, TCP resends only the lost ones using Selective Acknowledgment (SACK).</p>"},{"location":"mobile-computing-unit%204/#how-it-works_7","title":"How It Works","text":"<ul> <li>The receiver informs the sender exactly which packets were lost.</li> <li>The sender only retransmits those specific packets.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_7","title":"Advantages","text":"<ul> <li>Reduces bandwidth consumption, especially on wireless links.</li> <li>Speeds up recovery from packet loss.</li> </ul>"},{"location":"mobile-computing-unit%204/#limitations_4","title":"Limitations","text":"<ul> <li>Requires more complex receiver logic.</li> <li>Buffering overhead for out-of-order packets.</li> </ul> <pre><code>Example: Lost packet #4 detected -&gt; Only #4 is retransmitted\n</code></pre>"},{"location":"mobile-computing-unit%204/#tcp-over-25g3g-networks","title":"TCP Over 2.5G/3G Networks","text":"<p>Warning</p> <p>TCP performance in 2.5G/3G networks is affected by high latency, jitter, and bandwidth fluctuations.</p>"},{"location":"mobile-computing-unit%204/#challenges-in-25g3g","title":"Challenges in 2.5G/3G","text":"Factor Impact on TCP Mitigation Latency Increases RTT due to error correction Use timestamp option for better RTT estimation Jitter Causes random delay spikes Enable Explicit Congestion Notification (ECN) Packet Loss Occurs during handovers Use Selective Acknowledgment (SACK) Bandwidth Oscillations Reduces throughput unpredictably Use large windows and limited transmit"},{"location":"mobile-computing-unit%204/#recommended-tcp-optimizations","title":"Recommended TCP Optimizations","text":"<ul> <li>Large TCP Window Size to adapt to higher latency.</li> <li>Limited Transmit (RFC 3042) to improve performance for small data transmissions.</li> <li>Explicit Congestion Notification (ECN) to signal congestion without dropping packets.</li> <li>Selective Acknowledgment (SACK) for efficient retransmission.</li> <li>Avoid TCP Header Compression (RFC 1144) as it performs poorly with packet loss.</li> </ul>"},{"location":"mobile-computing-unit%204/#performance-enhancing-proxies-pep","title":"Performance-Enhancing Proxies (PEP)","text":"<p>Note</p> <p>Proxies are used to improve TCP performance in wireless networks by handling retransmissions locally.</p>"},{"location":"mobile-computing-unit%204/#how-it-works_8","title":"How It Works","text":"<ul> <li>Splits the connection between sender and mobile host.</li> <li>Optimizes data flow by caching and retransmitting lost packets at the proxy level.</li> </ul>"},{"location":"mobile-computing-unit%204/#advantages_8","title":"Advantages","text":"<ul> <li>Reduces delay by handling retransmissions locally.</li> <li>Improves throughput in high-latency wireless networks.</li> </ul>"},{"location":"mobile-computing-unit%204/#limitations_5","title":"Limitations","text":"<ul> <li>Breaks end-to-end TCP semantics.</li> <li>Not compatible with IPsec encryption.</li> </ul>"},{"location":"mobile-computing-unit%205/","title":"Mobile computing unit 5","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%205/#mobile-databases","title":"Mobile Databases","text":""},{"location":"mobile-computing-unit%205/#introduction-to-mobile-databases","title":"Introduction to Mobile Databases","text":"<p>Mobile databases are specialized data management systems designed for mobile devices. They address unique challenges such as:</p> <ul> <li>Limited device resources: Optimizing power and storage usage.</li> <li>Intermittent network connectivity: Ensuring seamless synchronization.</li> <li>Data distribution: Managing access across multiple locations.</li> </ul> <p>These databases enable:</p> <ul> <li>Efficient data querying.</li> <li>Offline operations.</li> <li>Secure data handling.</li> <li>Synchronization between mobile devices and central servers.</li> </ul> <p>Note</p> <p>Mobile databases allow devices to function independently while staying connected to a broader data ecosystem.</p>"},{"location":"mobile-computing-unit%205/#need-for-mobile-databases","title":"Need for Mobile Databases","text":"<p>Users require seamless access to their data and the ability to perform transactions securely on mobile devices.</p>"},{"location":"mobile-computing-unit%205/#key-requirements","title":"Key Requirements","text":"<ul> <li>Transaction handling: Making secure payments, updating records.</li> <li>Everyday convenience: Sending money, booking seats, trading stocks.</li> <li>Continuous access: Uninterrupted availability of information.</li> </ul> <p>Tip</p> <p>The demand for \"anytime, anywhere\" access makes mobile databases essential in modern applications.</p>"},{"location":"mobile-computing-unit%205/#uses-of-mobile-databases","title":"Uses of Mobile Databases","text":"<p>Mobile databases empower developers to build and deploy applications for handheld devices.</p>"},{"location":"mobile-computing-unit%205/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Corporate Access:</li> <li>Employees connect to their company's network.</li> <li>Data is downloaded for offline work.</li> <li>Updates sync back when connected.</li> <li>Real-world Example:   A food delivery app rider using mobile databases can:</li> <li>Accept new orders while on the move.</li> <li>Track delivery locations and customer details offline.</li> <li>Update delivery status in real-time.</li> <li>Sync all completed deliveries to the restaurant\u2019s system.</li> </ul> <p>Note</p> <p>Mobile databases ensure real-time tracking and offline functionality for critical applications.</p>"},{"location":"mobile-computing-unit%205/#mobile-databases-design-issues","title":"Mobile Databases: Design Issues","text":"<p>Mobile databases must be built for mobility rather than adapted from traditional database systems.</p>"},{"location":"mobile-computing-unit%205/#key-challenges","title":"Key Challenges","text":"Challenge Description Query Optimization Users move constantly, making it hard to determine the best way to process data requests. Time Management Mobile networks often charge based on connection time and data usage, requiring efficient retrieval. Power Efficiency Limited battery life demands minimal energy consumption for database operations. <p>Warning</p> <p>Poor optimization can lead to high costs, battery drain, and slow performance.</p>"},{"location":"mobile-computing-unit%205/#problems-in-mobile-databases","title":"Problems in Mobile Databases","text":""},{"location":"mobile-computing-unit%205/#routing","title":"Routing","text":"<p>One of the biggest costs in wireless communication is connection time. Efficient routing reduces this expense.</p>"},{"location":"mobile-computing-unit%205/#query-processing","title":"Query Processing","text":"<ul> <li>Mobile devices often disconnect for extended periods.</li> <li>Users may issue queries or updates on cached data while offline.</li> </ul>"},{"location":"mobile-computing-unit%205/#recoverability","title":"Recoverability","text":"<ul> <li>If a disconnected device fails, all locally stored updates may be lost permanently.</li> </ul>"},{"location":"mobile-computing-unit%205/#consistency","title":"Consistency","text":"<ul> <li>Cached data can become outdated, and devices won\u2019t detect inconsistencies until they reconnect.</li> <li>No updates can sync until the device is back online.</li> </ul> <p>Tip</p> <p>Using synchronization mechanisms and conflict resolution strategies can mitigate these issues.</p>"},{"location":"mobile-computing-unit%205/#introduction-to-coda","title":"Introduction to CODA","text":"<p>CODA is a distributed file system designed for high availability, scalability, and fault tolerance. It was developed as an extension of the Andrew File System (AFS) at Carnegie Mellon University. CODA ensures continuous data access even in the presence of network failures or server disconnections by using client-side caching, replication, and disconnected operation.</p>"},{"location":"mobile-computing-unit%205/#mechanisms-of-the-coda-file-system","title":"Mechanisms of the CODA File System","text":""},{"location":"mobile-computing-unit%205/#server-replication","title":"Server Replication","text":"<p>Server replication ensures that data remains accessible by storing multiple read-write replicas across different servers.</p> <ul> <li>Volumes have read-write replicas stored on multiple servers, forming a Volume Storage Group (VSG).</li> <li>Clients track available servers through an Accessible Volume Storage Group (AVSG).</li> <li>Venus (cache manager) ensures consistency by implementing a coherence protocol.</li> <li>Servers notify clients whenever cached copies become stale or invalid.</li> <li>Modifications are propagated simultaneously across all AVSG sites and later synced to missing VSG sites.</li> </ul>"},{"location":"mobile-computing-unit%205/#disconnected-operation","title":"Disconnected Operation","text":"<p>CODA supports offline access by allowing clients to function independently when the network is unavailable.</p> <ul> <li>Venus handles all file system requests using local cache data.</li> <li>When the client reconnects, Venus syncs modifications to the server and returns to replication mode.</li> <li>Ensures uninterrupted access for mobile users.</li> </ul>"},{"location":"mobile-computing-unit%205/#client-side-caching","title":"Client-Side Caching","text":"<ul> <li>Uses Venus, the CODA client module, to cache frequently accessed files locally.</li> <li>Improves performance by reducing the need for frequent server requests.</li> <li>Cached files allow users to work offline and sync changes later.</li> </ul>"},{"location":"mobile-computing-unit%205/#conflict-resolution","title":"Conflict Resolution","text":"<ul> <li>Automatic resolution for simple conflicts (e.g., appending to logs).</li> <li>Manual intervention required for complex conflicts where two users modify the same file.</li> <li>Uses resolution tools to merge conflicting versions.</li> </ul>"},{"location":"mobile-computing-unit%205/#scalability-and-performance","title":"Scalability and Performance","text":"<ul> <li>Efficient handling of large-scale distributed systems.</li> <li>Supports large numbers of clients with minimal performance degradation.</li> <li>Balances workload using adaptive caching and replication strategies.</li> </ul>"},{"location":"mobile-computing-unit%205/#security","title":"Security","text":"<ul> <li>Uses Kerberos authentication for secure access control.</li> <li>Encrypts data transmissions to protect sensitive information.</li> <li>Access control lists (ACLs) manage user permissions.</li> </ul>"},{"location":"mobile-computing-unit%205/#venus-states-in-coda","title":"Venus States in CODA","text":"<p>Venus operates in three distinct states, depending on the network connection status.</p>"},{"location":"mobile-computing-unit%205/#hoarding-preparation-phase","title":"Hoarding (Preparation Phase)","text":"<ul> <li>Venus proactively caches essential data before disconnection.</li> <li>Frequently accessed files are prefetched while online.</li> <li>Uses Least Recently Used (LRU) strategy to manage cache content efficiently.</li> </ul>"},{"location":"mobile-computing-unit%205/#emulation-disconnected-operation","title":"Emulation (Disconnected Operation)","text":"<ul> <li>When disconnected, Venus operates as a pseudo-server, providing local file access.</li> <li>Applications access cached files without needing server connectivity.</li> <li>Venus tracks all changes and assigns temporary file IDs for new objects.</li> <li>Conflict detection: After reconnection, file versions are compared, and conflicts are flagged for manual resolution.</li> </ul>"},{"location":"mobile-computing-unit%205/#reintegration-reconnection-syncing","title":"Reintegration (Reconnection &amp; Syncing)","text":"<ul> <li>Venus propagates all changes made during disconnection back to the server.</li> <li>The system updates cached files to reflect server changes.</li> <li>Reintegration occurs automatically upon network reconnection.</li> <li>If conflicting updates exist, files are stored as separate copies for manual integration.</li> </ul>"},{"location":"mobile-computing-unit%205/#client-structure-in-coda","title":"Client Structure in CODA","text":"<p>CODA's client-side architecture is designed for flexibility and efficiency.</p> <ul> <li>Venus runs at the user level, not the kernel level, allowing easier updates and flexibility.</li> <li>A mini-cache inside the kernel filters frequent Venus-kernel interactions, improving performance.</li> <li>File access process:</li> <li>Applications request files via the Vnode interface.</li> <li>If the mini-cache contains the file, the request is processed instantly.</li> <li>If not, Venus fetches the file from the server and updates the cache.</li> <li>After processing, control returns to the application.</li> <li>Venus periodically updates the mini-cache to maintain consistency.</li> </ul>"},{"location":"mobile-computing-unit%205/#design-rationale-of-coda-file-system","title":"Design Rationale of CODA File System","text":"<p>CODA was designed with specific goals in mind to support mobile and distributed computing.</p> <ul> <li>Standard Hardware Compatibility: Works on commercial systems without requiring special equipment.</li> <li>Transparency: Users do not need to know where files are stored.</li> <li>Scalability: Handles growing networks and large data volumes efficiently.</li> <li>Mobile Computing Support: Built for portable workstations and remote access.</li> <li>High Availability: Ensures continuous access even during network failures.</li> <li>Strong Consistency: Synchronizes data accurately across all replicas.</li> </ul>"},{"location":"mobile-computing-unit%206/","title":"Mobile computing unit 6","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%206/#wireless-communication","title":"Wireless Communication","text":""},{"location":"mobile-computing-unit%206/#introduction","title":"Introduction","text":"<p>Wireless communication refers to the transfer of information between two or more devices without physical cables or wires. It uses electromagnetic waves to transmit data over the airwaves.</p> <p>Some common wireless communication technologies include:</p> <ul> <li>Wi-Fi: Uses radio waves to provide high-speed internet and network connections.</li> <li>Bluetooth: Short-range wireless technology for connecting devices like smartphones, laptops, and headphones.</li> <li>Cellular Networks: Enables voice and data communication using mobile devices.</li> <li>Satellite Communication: Uses satellites to transmit data over long distances.</li> <li>RFID (Radio Frequency Identification): Employs radio waves to identify and track objects.</li> </ul> <p>Wireless communication has revolutionized connectivity and has enabled technologies like the Internet of Things (IoT), which relies on wireless networks to link devices and sensors.</p>"},{"location":"mobile-computing-unit%206/#components-of-wireless-communication-systems","title":"Components of Wireless Communication Systems","text":""},{"location":"mobile-computing-unit%206/#transmitters","title":"Transmitters","text":"<p>A transmitter encodes information into a modulated radio frequency signal and transmits it via an antenna. It generates an alternating current that is applied to the antenna, which then radiates radio waves.</p>"},{"location":"mobile-computing-unit%206/#receivers","title":"Receivers","text":"<p>A receiver detects transmitted signals using an antenna and demodulates them to extract the original information.</p>"},{"location":"mobile-computing-unit%206/#antennas","title":"Antennas","text":"<p>An antenna is responsible for transmitting and receiving radio frequency signals.</p> <ul> <li>Converts electrical energy into electromagnetic waves (and vice versa).</li> <li>Enhances signal quality and reduces interference.</li> <li>High-gain antennas extend the range of communication.</li> </ul>"},{"location":"mobile-computing-unit%206/#filters","title":"Filters","text":"<p>Filters eliminate unwanted signals, reducing noise and interference to ensure that the transmitted or received signal is within the desired frequency range.</p>"},{"location":"mobile-computing-unit%206/#amplifiers","title":"Amplifiers","text":"<p>Amplifiers increase signal strength, allowing transmission over longer distances while maintaining quality. They also enhance receiver sensitivity.</p>"},{"location":"mobile-computing-unit%206/#mixers","title":"Mixers","text":"<p>Mixers convert signal frequency by combining two signals to produce a new signal with a frequency that is the sum or difference of the two input frequencies. This is essential in radio communication.</p> <p>Tip</p> <p>High-gain antennas and amplifiers can significantly extend the communication range in wireless systems.</p>"},{"location":"mobile-computing-unit%206/#bluetooth-technology","title":"Bluetooth Technology","text":"<p>Bluetooth is a short-range wireless technology that connects devices to form a Personal Area Network (PAN). It operates in the 2.4 GHz to 2.485 GHz range using ultra-high frequency (UHF) radio waves.</p>"},{"location":"mobile-computing-unit%206/#bluetooth-applications","title":"Bluetooth Applications","text":"<ul> <li>Wireless laptops and PCs</li> <li>Mobile phones and PDAs</li> <li>Printers</li> <li>Wireless headsets</li> <li>Personal and Local Area Networks (PANs &amp; LANs)</li> <li>Data transfer (files, videos, images, music)</li> <li>Wireless peripheral devices (mouse, keyboards)</li> </ul>"},{"location":"mobile-computing-unit%206/#bluetooth-protocol-stack","title":"Bluetooth Protocol Stack","text":"Protocol Layer Description Radio Defines air interface, frequency bands, and modulation techniques. Baseband Defines addressing, packet format, and power control algorithms. LMP (Link Manager Protocol) Establishes and maintains logical links, handles authentication and encryption. L2CAP (Logical Link Control and Adaptation Protocol) Provides adaptation between upper-layer frames and baseband format. SDP (Service Discovery Protocol) Handles service-related queries for device connections. <p>Warning</p> <p>Bluetooth operates on shared frequency bands, making it susceptible to interference from other wireless devices.</p>"},{"location":"mobile-computing-unit%206/#protocols-in-the-bluetooth-protocol-stack","title":"Protocols in the Bluetooth Protocol Stack","text":""},{"location":"mobile-computing-unit%206/#core-protocols","title":"Core Protocols","text":"<p>Includes essential Bluetooth layers: - Bluetooth Radio - Baseband - Link Manager Protocol (LMP) - Logical Link Control and Adaptation Protocol (L2CAP) - Service Discovery Protocol (SDP)</p>"},{"location":"mobile-computing-unit%206/#cable-replacement-protocol","title":"Cable Replacement Protocol","text":"<ul> <li>RFComm (Radio Frequency Communications Protocol): Provides a serial interface for replacing wired connections.</li> </ul>"},{"location":"mobile-computing-unit%206/#adopted-protocols","title":"Adopted Protocols","text":"<p>Bluetooth integrates several standard networking protocols: - Point-to-Point Protocol (PPP) - Internet Protocol (IP) - User Datagram Protocol (UDP) - Transmission Control Protocol (TCP) - Wireless Application Protocol (WAP)</p>"},{"location":"mobile-computing-unit%206/#additional-protocols","title":"Additional Protocols","text":"<ul> <li>AT Commands: Command set for controlling Bluetooth devices.</li> <li>Audio Protocol: Handles voice and sound transmission over Bluetooth.</li> </ul>"},{"location":"mobile-computing-unit%206/#bluetooth-frame-structure","title":"Bluetooth Frame Structure","text":"<p>Bluetooth packets consist of three main components: Access Code, Packet Header, and Payload. Each field plays a crucial role in ensuring reliable communication within a Bluetooth network.</p> Field Size (bits) Description Access Code 72 Used for timing synchronization, piconet identification, and error detection. Packet Header 54 Contains essential control information such as device address, type of packet, flow control, acknowledgment, sequence numbers, and error detection. Payload 0-2744 Carries actual data or voice, depending on the type of communication."},{"location":"mobile-computing-unit%206/#access-code-72-bits","title":"Access Code (72 bits)","text":"<p>The Access Code field is the first part of a Bluetooth packet and is primarily used for device identification and synchronization.</p> Subfield Size (bits) Description Preamble 4 Helps receivers synchronize with the incoming packet. It consists of alternating bits (1010 or 0101). Synchronization 64 Uniquely identifies the piconet and is derived from the master's Bluetooth address. It allows a slave to recognize packets from its master. Trailer 4 Ensures correct signal detection and packet alignment. <p>Note</p> <ul> <li>The Synchronization field is crucial for filtering out unwanted Bluetooth signals from other nearby piconets.</li> <li>The Access Code helps maintain collision avoidance and packet integrity.</li> </ul>"},{"location":"mobile-computing-unit%206/#packet-header-54-bits","title":"Packet Header (54 bits)","text":"<p>The Packet Header carries control and management information necessary for maintaining Bluetooth connections. It contains six subfields:</p> Subfield Size (bits) Description AM_ADDR (Active Member Address) 3 Identifies one of the seven active slaves in a piconet (0 is reserved for broadcast). Type 4 Specifies the type of Bluetooth packet (e.g., data, control, or voice packet). Flow 1 Flow control bit used for managing buffer overflow conditions. ARQN (Acknowledgment Number) 1 Acknowledges successful receipt of the last packet (1 = ACK, 0 = NACK). SEQN (Sequence Number) 1 Ensures correct packet order and detects duplicates in retransmission. HEC (Header Error Check) 8 Provides error detection for the header. It helps in identifying corrupt headers. <p>Tip</p> <ul> <li>The SEQN and ARQN fields work together to enable Bluetooth\u2019s Automatic Repeat reQuest (ARQ) mechanism for reliable transmission.</li> <li>The HEC ensures that header corruption is detected before processing further.</li> </ul>"},{"location":"mobile-computing-unit%206/#payload-0-2744-bits","title":"Payload (0-2744 bits)","text":"<p>The Payload is the data-carrying part of the packet. Its size varies based on the type of packet:</p> Payload Type Size (bits) Purpose Voice Data Fixed 240 Used for real-time audio communication. No retransmission occurs. Asynchronous Data (ACL) 0-2744 Used for file transfer and general data communication. Supports error correction and retransmission. Synchronous Data (SCO/eSCO) 0-240 Used for streaming applications like audio calls, with limited retransmission. <p>Warning</p> <ul> <li>Voice packets (SCO) have no retransmission due to real-time constraints.</li> <li>Data packets (ACL) support error correction and retransmission for reliability.</li> </ul>"},{"location":"mobile-computing-unit%206/#error-handling-in-bluetooth-packets","title":"Error Handling in Bluetooth Packets","text":"<p>Bluetooth implements several error detection and correction mechanisms:</p> <ol> <li>Header Error Check (HEC): Detects corruption in the packet header.</li> <li>Cyclic Redundancy Check (CRC): Applied to payload data for error detection.</li> <li>Forward Error Correction (FEC): Helps correct errors in weak signals (1/3 and 2/3 FEC schemes).</li> <li>Automatic Repeat reQuest (ARQ): Retransmits packets when errors are detected.</li> </ol> <p>Tip</p> <p>Bluetooth\u2019s robust error correction techniques ensure a balance between reliability and efficiency, making it suitable for both voice and data applications.</p>"},{"location":"mobile-computing-unit%206/#wi-fi-standards-ieee-80211-family","title":"Wi-Fi Standards (IEEE 802.11 Family)","text":""},{"location":"mobile-computing-unit%206/#introduction_1","title":"Introduction","text":"<p>Wi-Fi standards (IEEE 802.11) define wireless communication protocols, improving speed, frequency bands, and features over time.</p>"},{"location":"mobile-computing-unit%206/#major-wi-fi-standards-and-their-features","title":"Major Wi-Fi Standards and Their Features","text":"Standard Year Frequency Band Max Speed Key Features Also Known As 802.11 (Original) 1997 2.4 GHz 1-2 Mbps First wireless LAN standard using FHSS or DSSS - 802.11a 1999 5 GHz 54 Mbps Uses OFDM encoding scheme - 802.11b 1999 2.4 GHz 11 Mbps Uses DSSS, widely adopted first-gen Wi-Fi Wi-Fi (Original) 802.11g 2003 2.4 GHz 54 Mbps Combines features of 802.11a/b, backward compatible - 802.11e 2005 2.4 GHz &amp; 5 GHz Up to 54 Mbps Quality of Service (QoS) for better multimedia &amp; VoIP support WMM (Wi-Fi Multimedia) 802.11n 2009 2.4 GHz &amp; 5 GHz 600 Mbps Introduced MIMO for better speed &amp; range - 802.11ac 2013 5 GHz only 3.5 Gbps Improved 802.11n with wider channels &amp; better performance Wi-Fi 5 802.11ac Wave 2 ~2016 5 GHz only 6.93 Gbps Added MU-MIMO technology &amp; enhancements - 802.11ad 2012 60 GHz 7 Gbps High-speed, short-range (WiGig) WiGig 802.11ah 2017 Below 900 MHz Lower Extended range, better wall penetration Wi-Fi HaLow 802.11r - - - Fast BSS transition for VoIP handoff between access points Fast Roaming 802.1X - - - Security standard for network access control -"},{"location":"mobile-computing-unit%206/#key-takeaways","title":"Key Takeaways","text":"<ul> <li>Higher Frequencies (5 GHz, 60 GHz): Higher speeds but shorter range.</li> <li>Lower Frequencies (2.4 GHz, Below 900 MHz): Better range and penetration but lower speed.</li> <li>Newer Standards (802.11ac, 802.11ax, etc.): Improved speed, efficiency, and multi-device support.</li> <li>Wi-Fi 5 (802.11ac): Popular high-speed standard used today.</li> <li>Wi-Fi 6 (802.11ax - Not in table): Next-gen standard improving speed, efficiency, and congestion handling.</li> </ul>"},{"location":"mobile-computing-unit%206/#wireless-lan-wlan","title":"Wireless LAN (WLAN)","text":""},{"location":"mobile-computing-unit%206/#what-is-wlan","title":"What is WLAN?","text":"<ul> <li>WLAN (Wireless Local Area Network) allows mobile users to connect to a Local Area Network (LAN) wirelessly.</li> <li>Also known as LAWN (Local Area Wireless Network).</li> <li>Defined by IEEE 802.11 standards.</li> <li>Uses Ethernet protocol and CSMA/CA (Carrier Sense Multiple Access with Collision Avoidance) for communication.</li> <li>Implements WEP (Wired Equivalent Privacy) encryption for security.</li> <li>Provides high-speed data communication in small areas (offices, buildings, etc.).</li> <li>Used to reduce costs and avoid cable installation, especially in public areas.</li> </ul>"},{"location":"mobile-computing-unit%206/#advantages-of-wlans","title":"Advantages of WLANs","text":"<ol> <li>Flexibility</li> <li>Devices can communicate without physical connections.</li> <li>Radio waves penetrate walls, allowing hidden placements.</li> <li>Easy Planning</li> <li>Wireless ad-hoc networks do not require pre-planning like wired networks.</li> <li>Compact Design</li> <li>Allows development of small, portable devices (laptops, tablets, PDAs).</li> <li>Disaster Resilience</li> <li>Works even in natural disasters where wired infrastructure might fail.</li> <li>Cost Efficiency</li> <li>Cheaper installation and maintenance than traditional wired LANs.</li> <li>No extra cost for adding users after initial setup.</li> <li>Ease of Use</li> <li>Simple setup for users, requiring minimal technical knowledge.</li> </ol>"},{"location":"mobile-computing-unit%206/#disadvantages-of-wlans","title":"Disadvantages of WLANs","text":"<ol> <li>Quality of Service (QoS) Issues</li> <li>Lower bandwidth due to radio transmission limitations.</li> <li>Higher error rates from interference.</li> <li>Increased latency due to error correction.</li> <li>Proprietary Solutions</li> <li>Slow standardization leads to different vendor-specific solutions.</li> <li>Most systems adhere to IEEE 802.11a/b.</li> <li>Regulatory Restrictions</li> <li>Governments impose frequency restrictions to avoid interference.</li> <li>Global Operation Issues</li> <li>Frequency regulations differ across countries.</li> <li>Devices must comply with international standards.</li> <li>High Power Consumption</li> <li>Wireless devices consume more power than wired ones.</li> <li>Requires power-saving modes for efficiency.</li> <li>Licensing Requirements</li> <li>Operators prefer license-free bands like 2.4 GHz ISM band for easier deployment.</li> </ol>"},{"location":"mobile-computing-unit%206/#conclusion","title":"Conclusion","text":"<ul> <li>WLANs provide mobility, flexibility, and cost-effectiveness.</li> <li>They suffer from QoS issues, power constraints, and regulatory challenges.</li> <li>IEEE 802.11 continues to evolve, improving performance and security.</li> </ul>"},{"location":"mobile-computing-unit%207/","title":"Mobile computing unit 7","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%207/#evolution-of-internet-access-and-display-technology","title":"Evolution of Internet Access and Display Technology","text":""},{"location":"mobile-computing-unit%207/#early-internet-era","title":"Early Internet Era","text":"<ul> <li>Connectivity via 2 Mbps cable modems </li> <li>Remote access from workplace or residence </li> <li>Content delivered to high-resolution displays through HTTP/HTML protocols </li> </ul>"},{"location":"mobile-computing-unit%207/#early-2000s-transition","title":"Early 2000s Transition","text":"<ul> <li>Significant emergence of compact mobile and handheld technologies </li> <li>Web accessibility through wireless technologies including GPRS (2.5G at 38.4kbps) and GSM (2G/3G reaching 6kbps) </li> <li>Industry focus shifted toward miniature 96\u00d764 pixel displays, delivering content in 24\u00d77\u00d7365 availability </li> </ul>"},{"location":"mobile-computing-unit%207/#current-technology-landscape","title":"Current Technology Landscape","text":"<ul> <li>Evolution from HD (1280\u00d7720 pixels) to Full HD (1920\u00d71080 pixels) and beyond </li> <li>Premium smartphones featuring Quad HD (2560\u00d71440 pixels) or 4K Ultra HD (3840\u00d72160 pixels) resolution </li> <li>These advanced display technologies deliver exceptionally crisp and detailed visual reproduction</li> </ul>"},{"location":"mobile-computing-unit%207/#wireless-application-protocol-wap","title":"Wireless Application Protocol (WAP)","text":"<ul> <li>Open Global Standard: The Wireless Application Protocol is an open global specification that enables mobile users with wireless devices to access information and services instantly.</li> <li>Industry-Wide Adoption: By 2002, over 500 companies across the technology sector had joined the WAP Forum, including network operators, device manufacturers, service providers, and software vendors.</li> <li>Rapid Evolution: WAP technology progressed quickly, launching with version 1.0 in 1999 and advancing to WAP 2.0 by 2002.</li> </ul>"},{"location":"mobile-computing-unit%207/#the-web-programming-model","title":"The Web Programming Model","text":"<p>The Internet World-Wide-Web (WWW) architecture provides a very flexible and powerful programming model</p>"},{"location":"mobile-computing-unit%207/#abstract-data-exchange-model","title":"Abstract Data Exchange Model:","text":"<pre><code>flowchart LR\n    A[\"Web browsers (Networked application)\"] -- \"Request (for named objects)\" --&gt; B[\"Server\"]\n    B -- \"Data encoded using the standard formats\" --&gt; A\n    B1[\"Applications in standard data formats\"] \n    B2[\"Data in standard data format\"]\n    B --&gt; B1\n    B --&gt; B2</code></pre> <p>The WWW standards specify many of the mechanisms necessary to build a general-purpose application environment, including the following:</p> <ul> <li>Standard naming model: All servers and content on the WWW are named with an Internet standard Uniform Resource Locator (URL) .</li> <li>Content type: All content on the WWW is given a specific type, thereby allowing web browsers to correctly process the content, based on its type.</li> <li>Standard content formats: All web browsers support a set of standard content formats.  These include the HyperText Markup Language (HTML) , scripting languages like Javascript and a large number of other formats.</li> <li>Standard protocols: Standard networking protocols allow any web browser to communicate with any web server.  The most commonly used protocol on the WWW is the HyperText Transport Protocol (HTTP), operating on top of the TCP/IP protocol suite.</li> </ul>"},{"location":"mobile-computing-unit%207/#the-wap-programming-model","title":"The WAP Programming Model","text":"<p>The WAP programming Model, shown in Figure , is similar to the Web programming Model, with certain enhancements and extensions to match the characteristics and constraints of the wireless environment.  Characteristics like \u2013 slow CPU, low-bandwidth, small memory, small screens</p> <p></p> <p>The most significant enhancements that WAP has added to the programming model are - Push   - With Push Telephony Support, service providers can deliver various types of information to users' phones, such as call alerts, voicemail notifications, and updates on service subscriptions - Telephony support (WTA)   - WTA services, which include features like call forwarding, call waiting, and call holding, rely on Push Telephony Support to provide users with a more seamless and integrated telephony experience</p> <p>Request-response mechanism \u2794 referred to as pull, in contrast with the push mechanism.  </p> <p>Client pulls data from the server, where the server pushes data to the client.</p> <p>WAP content and applications are specified in a set of well-known content formats, based on the familiar WWW content formats.  </p> <p>Content is transported using a set of standard communication protocols based on the WWW communication protocols.</p> <p>The WAP microbrowser in the wireless terminal, coordinates the user-interface and is analogous to a standard web browser.  </p> <p>WAP defines a set of standard components that enable communication between mobile terminals and network servers, including the following:</p> <ul> <li>Standard naming model: WWW standard URLs are used to identify WAP content on origin servers.  </li> <li>Content typing: All WAP content is given a specific type consistent with WWW typing, thereby allowing WAP user agents to correctly process the content, based on its type.</li> <li>Standard content formats: All WAP content formats are based on WWW technology and include display markup, calendar information, electronic business card objects, images and scripting languages like and a large number of formats.</li> <li>Standard protocols: WAP communication protocols enable the communication of browser requests from the mobile terminal to the web server.  The WAP content types and protocols have been optimized for mass market, handheld wireless devices.</li> </ul>"},{"location":"mobile-computing-unit%207/#accessing-a-web-site-using-a-wap-enabled-device","title":"Accessing a Web Site Using a WAP-Enabled Device","text":"<p>Here's what happens when you access a Web site using a WAP-enabled device: - You turn on the device and open the minibrowser. - The device sends out a radio signal, searching for service. - A connection is made with your service provider. - You select a Web site that you wish to view. - A request is sent to a gateway server using WAP. - The gateway server retrieves the information via HTTP from the Web site. - The gateway server encodes the HTTP data as WML. - The WML-encoded data is sent to your device. - You see the wireless Internet version of the Web page you selected.</p>"},{"location":"mobile-computing-unit%207/#wap-protocol-stack","title":"WAP Protocol Stack","text":"<p>The WAP 1.1 protocol stack is shown in Figure.  It is derived and inherits most of its characteristics from the ISO OSI Reference Model and has 5 different layers</p> <p></p> <ul> <li>WAE : Wireless Application Environment</li> <li>holds the tools that wireless Internet content developers use. </li> <li>These include WML and WMLScript.</li> <li>WSP: Wireless Session protocol:</li> <li>determines whether a session between the device and the network will be connection-oriented or connectionless.</li> <li>In a connection-oriented session, data is passed both ways between the device and the network; WSP then sends the packet to the Wireless Transaction Protocol layer.</li> <li>If the session is connectionless, then WSP redirects the packet to the Wireless Datagram Protocol layer </li> <li>WTP - The Wireless Transaction Protocol</li> <li>It also determines how to classify each transaction request: Reliable two-way Reliable one-way Unreliable one-way </li> <li>The WSP and WTP layers correspond to Hypertext Transfer Protocol (HTTP) in the TCP/IP protocol suite.</li> <li>Wireless Transport Layer Security (WTLS): This component provides robust security features similar to Transport Layer Security (TLS) in TCP/IP protocols, ensuring data integrity through encryption while managing client and server authentication processes.</li> <li>Wireless Datagram Protocol (WDP): Operating in conjunction with the network carrier layer, WDP functions similarly to UDP and maintains a consistent interface for upper protocol layers despite communication occurring via bearer services.</li> <li>Bearer Services: These network carriers support various mobile phone systems including GSM and CDMA technologies, serving as the fundamental transport mechanism for WAP communications.</li> </ul>"},{"location":"mobile-computing-unit%207/#i-mode","title":"I-Mode","text":"<p>In 1999, the Japanese NTT DoCoMo company launched the Information-mode or I-Mode for wireless access to the web, using special handsets.  In fact the I-Mode system has a new transmission system, a new handset and a new language.  The i-mode handsets are basically wireless terminals are not user programmable.  The language used in the I-Mode is a compact version or subset of HTML, called cHTML.  cHTML browser does not support Javascript, frames, style sheets, JPEG images, etc.  the i-mode server is a full-blown system supporting CGI, Perl, PHP, JSP, ASP etc and everything else that web servers normally support.</p>"},{"location":"mobile-computing-unit%207/#wap-20","title":"WAP 2.0","text":"<p>The second generation wireless web, symbolized by WAP 2.0, uses packet switching, for example, GPRS.  It has some new features, the most significant of which are: - Push as well as pull model - Support for integrating telephony into applications. - Multimedia messaging - Inclusion of 264 pictograms - Interface to a storage device : FLASH ROM is supported as a storage device. A WAP enabled wireless camera could use it for temporary image storage, before sending it to the internet. - Support for plug-ins in the browser : support for scripting languages</p> <p>Various technical differences are also present between WAP 1.1 and 2.0.  </p> <p>Firstly, WAP 2.0 continues to support the WAP1.1 stack, but also supports the standard Internet stack with TCP and HTTP/1.1.  However, four minor but compatible changes to TCP were made to simplify the code: - use of a fixed 64-KB window - no slow start - maximum MTU of 1500bytes, (payload of Wi-fi) and - a slightly different retransmission algorithm</p> <p>Secondly, WAP2.0 supports XHTML Basic, a markup language intended for small wireless devices, like mobile phones, televisions, PDAs, vending machines, pagers, cars, game machines, watches, etc.  It therefore does not support style sheets, scripts or frames but most of the standard tags are there, which are defined in XML.</p> <p>WAP 2.0 runs at 384 Kbps, which is still very slow, as compared to the 11Mbps or 54Mbps data rates offered by IEEE Standard 802.11, which is giving it huge competition.</p>"},{"location":"mobile-computing-unit%207/#wap-gateway","title":"WAP Gateway","text":"<p>A gateway is an intermediary element, usually used to connect two different types of networks. Gateway receives requests from clients as if it were an origin server.  Clients are usually not aware that they are speaking to the Gateway.</p> <p></p> <p>WAP uses coded binary data to improve transmission efficiency. The header and content are compactly compiled. Traditional HTTP network \u2013 header is in string format. To adapt to WAP network \u2013encoding and decoding is required. Gateway provides coder\\decoder functionality.</p> <p>The key benefits: - Uses less data by compressing information - Makes websites accessible on limited mobile devices - Handles all the complex translation automatically</p> <p></p> <p>In general, a WAP gateway is expected to complete three tasks:  - Header translation  - Push operation: Which allows server to send right information to the client. - Content compilation : compaction of data for low bandwidth networks.</p>"},{"location":"mobile-computing-unit%207/#push-operation","title":"Push Operation","text":"<p>A push operation in WAP is accomplished by allowing a Push Initiator (PI) to transmit push content and delivery instructions to a Push Proxy Gateway (PPG), which then delivers the push content to the WAP client according to the delivery instructions. The PI is typically an application that runs on an ordinary web server. It communicates with the PPG using the Push Access Protocol (PAP). The PPG uses the Push Over-The-Air (OTA) Protocol to deliver the push content to the client.</p> <p></p>"},{"location":"mobile-computing-unit%207/#push-message-type","title":"Push Message Type","text":"<p>a) Service Indication : - SI sends notification to end users in asynchronous manner.  - SI messages are used to indicate new WAP content is available. - For example: new emails, changes in stock price, news headlines, advertising, reminders, low prepaid balance etc.</p> <pre><code>flowchart LR\n    A[Push Initiator] -- SI(textual) --&gt; B[Initiator Proxy/gateway]\n    B -- SI(binary) --&gt; C[Mobile client]\n    C --&gt; D[\"You have 4 new emails\"]</code></pre> <p>b) Service Loading : ask user agent on a mobile client to load and execute a service that can be in form of a WML deck. SL messages forces the phone to go directly to the content without user intervention.</p> <p>Examples of SL - Automatic updates - When a critical software update needs to be installed on your mobile device immediately  - Emergency alerts - During emergencies like natural disasters, the system could automatically load evacuation maps or safety instructions  - Time-sensitive content - Financial applications might automatically load trading screens when market conditions meet certain thresholds  - Subscription services - A news service you subscribed to might automatically load the full article when breaking news occurs  - Mobile banking - Your bank might automatically load a security verification page when suspicious activity is detected on your account </p>"},{"location":"mobile-computing-unit%207/#basic-steps-involved-in-push-operation","title":"Basic Steps Involved in Push Operation","text":"<ul> <li>The Push Initiator (Web server or Email provider) instructs the WAP (Push Proxy) Gateway to push an SI to the mobile client using the Push Access Protocol (PAP). The Push Initiator sends the SI message with an appropriate header and a URL to the e-mail service.</li> <li>The Push Proxy/Gateway sends the SI to the mobile client using the Push OTA Protocol. </li> <li>The mobile client receives the push containing the SI, and the message is presented to the end-user.</li> </ul>"},{"location":"mobile-computing-unit%207/#push-message-format-pap","title":"Push Message Format (PAP)","text":"<p>The Push message contains three entities:  - a control entity: XML document, contains delivery instructions for the PPG. - a content entity: contains content to be delivered - capability entity. (optional)</p> <p>These are bundled together in a multipart/related message, which is sent from the PI to the PPG.</p>"},{"location":"mobile-computing-unit%207/#pull-operation","title":"Pull Operation","text":"<ul> <li>User agent (Mobile) sends a uniform resource locator (URL) request to a WAP gateway following the WSP protocol. </li> <li>The WAP gateway decodes the request massage and translates the request line and request header (in binary format) to HTTP format by a mapping table. </li> <li>The WAP gateway creates a connection to the web server and sends an HTTP request to it. </li> <li>The HTTP request is processed by the web server. </li> <li>The Web server returns an HTTP reply message, which contains data.</li> <li>The WAP gateway encodes the reply and translates the well-known HTTP formatted reply line and reply header into WSP binary format using the mapping table. </li> <li>The WAP gateway creates WSP response containing the wireless markup language (WML) and returns it to the client system.</li> </ul>"},{"location":"mobile-computing-unit%207/#xhtml-m","title":"XHTML-M","text":"<p>XHTML-MP (XHTML Mobile Profile) is an XML-based markup language designed specifically for mobile devices with limited capabilities. It represents a key adaptation of standard web technologies for the mobile environment. XHTML-MP emerged as a successor to WML (Wireless Markup Language) and serves as a bridge between full HTML/XHTML and the constrained resources of mobile devices. It includes a subset of XHTML features optimized for small screens, limited processing power, and bandwidth constraints typical of mobile phones in the early 2000s. The \"Mobile Profile\" designation indicates its specialized focus on mobile applications, providing essential formatting capabilities while eliminating resource-intensive elements that would be impractical on mobile devices of that era. This standard was particularly important during the transition from basic WAP services to more sophisticated mobile web browsing experiences.</p>"},{"location":"mobile-computing-unit%208/","title":"Mobile computing unit 8","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%208/#mobile-ad-hoc-networks","title":"Mobile Ad-hoc Networks","text":""},{"location":"mobile-computing-unit%208/#wireless-networks-mobile-connectivity-challenges","title":"Wireless Networks - Mobile Connectivity Challenges","text":"<p>Wireless networks connect mobile users to services, but face challenges when infrastructure is limited.</p> <ul> <li>Infrastructure-Based Issues:</li> <li>Mobile IP: Needs home agents, tunnels, and default routers to work.</li> <li>DHCP: Requires dedicated servers and broadcast-capable networks.</li> <li>Cellular Networks: Depend on costly base stations.</li> <li>Challenges: High costs or lack of infrastructure in some areas make deployment tough.</li> <li>Example: Setting up a cellular tower in a remote village is too expensive.</li> </ul> <p>Simple Idea</p> <p>Wireless networks struggle without infrastructure, like trying to call without a phone tower.</p>"},{"location":"mobile-computing-unit%208/#mobile-ad-hoc-networks-manets","title":"Mobile Ad-Hoc Networks (MANETs)","text":"<p>MANETs are self-configuring wireless networks that work without fixed infrastructure.</p> <ul> <li>Key Features:</li> <li>Provide connectivity where traditional networks are unavailable or impractical.</li> <li>Excel in scenarios like military communications, disaster relief, temporary events, or home networks.</li> <li>Operate without centralized control, making them resilient.</li> <li>Example: Rescue teams using MANETs to communicate after an earthquake destroys cell towers.</li> </ul> <p>Simple Idea</p> <p>MANETs are like a group of radios linking up without a central station.</p>"},{"location":"mobile-computing-unit%208/#ad-hoc-network-applications","title":"Ad-Hoc Network Applications","text":"<p>MANETs support various scenarios where infrastructure is absent or slow to deploy.</p> <ul> <li>Instant Infrastructure:</li> <li>Used for unplanned meetings where infrastructure isn\u2019t ready.</li> <li>Faster than setting up fixed networks, which need planning.</li> <li>Example: A pop-up network for a spontaneous conference.</li> <li>Disaster Relief:</li> <li>Infrastructure fails in disasters (e.g., hurricanes cut power lines, floods ruin base stations).</li> <li>MANETs allow quick setup for emergency teams.</li> <li>Example: Firefighters coordinating via MANETs during a wildfire.</li> <li>Remote Areas:</li> <li>Too costly to build infrastructure in sparsely populated areas.</li> <li>MANETs or satellites are more practical based on usage.</li> <li>Example: Farmers in a remote valley sharing data via MANETs.</li> <li>Effectiveness:</li> <li>Cheaper than cellular for small, infrequent data (e.g., status updates every few minutes).</li> <li>Example: Sensors in a forest sending rare alerts via MANETs.</li> <li>Other Uses:</li> <li>Personal: Connecting phone, laptop, earphone, smartwatch.</li> <li>Military: Linking soldiers, tanks, planes.</li> <li>Civilian: Taxi networks, meeting rooms, stadiums, boats, small aircraft.</li> <li>Emergency: Search-and-rescue, policing, firefighting.</li> </ul> <p>Simple Idea</p> <p>MANETs are quick, cheap networks for emergencies, remote spots, or small data needs.</p>"},{"location":"mobile-computing-unit%208/#manet-characteristics-and-dynamics","title":"MANET Characteristics and Dynamics","text":"<p>MANETs have unique traits due to their mobile, infrastructure-free nature.</p> <ul> <li>Highly Mobile Nodes: Devices move, constantly changing network connections.</li> <li>Dynamic Connections: Links form and break as devices shift.</li> <li>No Infrastructure: No need for cellular towers or base stations.</li> <li>Multi-Hop: Data passes through multiple devices to reach its destination.</li> <li>Dual Role: Each device is both a user (sending/receiving) and a router (forwarding).</li> <li>Example: Drones relaying messages to each other as they fly, adjusting as they move.</li> </ul> <p>Simple Idea</p> <p>MANETs are like a chain of people passing notes, rearranging as they walk.</p>"},{"location":"mobile-computing-unit%208/#multi-hop-wireless","title":"Multi-Hop Wireless","text":"<p>MANETs rely on multi-hop communication due to limited device range.</p> <ul> <li>How It Works:</li> <li>Data travels through several devices to reach the destination.</li> <li>Each device has a short transmission range, so others relay the signal.</li> <li>Paths change as devices move in or out of range.</li> <li>Routing protocols adapt to these changes to find and maintain paths.</li> <li>Example: A message from one camper to another going through other campers\u2019 radios.</li> </ul> <p>Simple Idea</p> <p>Multi-hop is like passing a letter through friends to reach someone far away.</p>"},{"location":"mobile-computing-unit%208/#why-ad-hoc-networks","title":"Why Ad-Hoc Networks?","text":"<p>Ad-hoc networks are ideal when fixed infrastructure isn\u2019t feasible.</p> <ul> <li>Reasons:</li> <li>No infrastructure in disaster zones or war areas.</li> <li>Impractical for short-range devices like Bluetooth (10m range).</li> <li>Quick to deploy without backbone support.</li> <li>Example: Soldiers in a jungle setting up a MANET to communicate without towers.</li> </ul> <p>Simple Idea</p> <p>Ad-hoc networks are like setting up a temporary phone line when there\u2019s no service.</p>"},{"location":"mobile-computing-unit%208/#manet-and-mobile-ip","title":"MANET and Mobile IP","text":"<p>MANETs differ from Mobile IP, which relies on infrastructure.</p> <ul> <li>MANET Nodes: Combine routing and user functions, unlike Mobile IP\u2019s dependence on home agents.</li> <li>Example: In a MANET, a soldier\u2019s radio both sends messages and forwards others\u2019 messages.</li> </ul> <p>Simple Idea</p> <p>MANET devices are like team players handling both their tasks and passing messages.</p>"},{"location":"mobile-computing-unit%208/#routing-in-ad-hoc-networks","title":"Routing in Ad-Hoc Networks","text":"<p>Routing in MANETs is complex due to mobility and lack of infrastructure.</p> <ul> <li>Challenges:</li> <li>Unlike cellular networks where base stations reach all devices, MANETs need each device to forward data.</li> <li>Links vary (e.g., strong one way, weak the other) due to antenna or power differences.</li> <li>Topology changes fast as devices move.</li> <li>Example: A drone\u2019s signal to another might weaken as it flies, requiring a new path.</li> </ul> <p>Simple Idea</p> <p>Routing in MANETs is like finding a new path through a moving crowd.</p>"},{"location":"mobile-computing-unit%208/#differences-in-routing-wired-vs-ad-hoc-networks","title":"Differences in Routing: Wired vs. Ad-Hoc Networks","text":"<p>MANET routing differs from wired networks due to unique challenges.</p> <ul> <li>Asymmetric Links:</li> <li>A device may receive clearly but send weakly (or vice versa).</li> <li>Wired networks assume equal link quality both ways.</li> <li>Example: One radio hears another well, but its reply is faint.</li> <li>Redundant Links:</li> <li>MANETs have many possible paths, increasing routing complexity.</li> <li>Wired networks have fewer, planned redundant links.</li> <li>Example: Multiple drones can relay a message, complicating path choice.</li> <li>Interference:</li> <li>Wireless signals clash if devices are too close, unlike wired cables.</li> <li>Overhearing can help (learning topology) or hurt (interference).</li> <li>Example: Two nearby radios disrupt each other\u2019s signals.</li> <li>Dynamic Topology:</li> <li>MANETs change constantly as devices move or signals vary.</li> <li>Wired networks update slowly (e.g., every 30 seconds), unsuitable for MANETs.</li> <li>Example: A moving car network reshuffles connections every few seconds.</li> <li>Impact on Protocols:</li> <li>Traditional routing assumes stable links and global knowledge.</li> <li>MANETs need frequent updates, considering battery and bandwidth limits.</li> <li>Example: A wired network\u2019s routing table updates leisurely; a MANET\u2019s must be instant.</li> </ul> <p>Simple Idea</p> <p>MANET routing is like navigating a maze where walls move and paths vary.</p>"},{"location":"mobile-computing-unit%208/#problems-with-ad-hoc-networks","title":"Problems with Ad-Hoc Networks","text":"<p>MANETs face issues that make routing tricky.</p> <ul> <li>Dynamic Topology: Constant movement means paths change often.</li> <li>Incomplete Knowledge: Devices don\u2019t know the full network layout, traffic, link quality, or device power.</li> <li>Resource Constraints: Periodic updates waste battery and bandwidth, which are scarce.</li> <li>Traditional Protocol Failure:</li> <li>Wired protocols can\u2019t handle dynamic topology, asymmetric links, or interference.</li> <li>Centralized routing is too slow; topology changes before updates finish.</li> <li>Flooding (sending data everywhere) works but is inefficient, needing hop limits.</li> <li>Example: A robot swarm struggles to route data as robots move and signals fade.</li> </ul> <p>Simple Idea</p> <p>MANETs are hard to manage because everything keeps changing and resources are tight.</p>"},{"location":"mobile-computing-unit%208/#distance-vector-and-link-state-routing","title":"Distance-Vector and Link-State Routing","text":"<p>Traditional routing methods inform MANET protocols but need adaptation.</p> <ul> <li>Distance-Vector:</li> <li>Each device knows the cost (hops) to reach others.</li> <li>Shares distance lists with neighbors, updating paths if shorter ones are found.</li> <li>Tracks which neighbor offers the best path for forwarding.</li> <li>Example: A device says, \u201cI can reach X in 2 hops via Y,\u201d and neighbors update.</li> <li>Link-State:</li> <li>Devices know the entire network map and calculate shortest paths.</li> <li>Share link status with neighbors to build the map.</li> <li>Example: Devices share a full network diagram to plan routes.</li> <li>Assumptions: Both assume devices know neighbors\u2019 addresses and link costs (infinite if broken).</li> </ul> <p>Simple Idea</p> <p>Distance-vector is like sharing travel times; link-state is like sharing a full map.</p>"},{"location":"mobile-computing-unit%208/#routing-and-mobility","title":"Routing and Mobility","text":"<p>Mobility in MANETs complicates routing.</p> <ul> <li>Frequent Route Changes: Device movement creates unpredictable network layouts.</li> <li>Power Limits: Battery constraints affect routing choices.</li> <li>Goals:</li> <li>Reduce routing overhead.</li> <li>Find short, stable paths despite mobility.</li> <li>Example: A moving vehicle network must keep finding new paths as cars shift.</li> </ul> <p>Simple Idea</p> <p>Routing in MANETs is like planning a route in a city where roads keep changing.</p>"},{"location":"mobile-computing-unit%208/#routing-protocols-in-manets","title":"Routing Protocols in MANETs","text":"<p>MANET routing protocols are designed for dynamic, infrastructure-less networks.</p> <ul> <li>Proactive Protocols:</li> <li>Maintain routes to all devices at all times via periodic updates.</li> <li>Example: DSDV, GSR (Global State Routing).</li> <li>Reactive Protocols:</li> <li>Find routes only when needed, reducing overhead.</li> <li>Example: DSR, AODV.</li> <li>Hybrid Protocols:</li> <li>Combine proactive (local) and reactive (distant) routing.</li> <li>Example: ZRP.</li> </ul> <p>Simple Idea</p> <p>Proactive keeps all routes ready; reactive finds them as needed; hybrid mixes both.</p>"},{"location":"mobile-computing-unit%208/#proactive-routing-destination-sequenced-distance-vector-dsdv","title":"Proactive Routing: Destination Sequenced Distance Vector (DSDV)","text":"<p>DSDV is a proactive protocol enhancing distance-vector routing for MANETs.</p> <ul> <li>How It Works:</li> <li>Each device maintains a table with paths to all destinations, including:<ul> <li>Destination, next hop, hop count, sequence number, install time, stability data.</li> </ul> </li> <li>Shares tables with neighbors periodically.</li> <li>Sequence numbers (set by destination) ensure fresh routes and prevent loops.</li> <li>Immediate updates for new routes, broken links, or metric changes.</li> <li>Full updates send all table data; incremental updates send only changes.</li> <li>Count-to-Infinity Fix:</li> <li>In traditional distance-vector, a broken link causes endless updates (e.g., A thinks it can reach E via B, B via A).</li> <li>DSDV uses sequence numbers to mark newer routes, avoiding this.</li> <li>Example: Hikers share maps with version numbers; a higher number means a fresher path.</li> <li>Pros:</li> <li>Fast route access; loop-free with sequence numbers.</li> <li>Quick response to topology changes.</li> <li>Cons:</li> <li>High overhead from constant updates.</li> <li>Maintains unused routes, draining battery.</li> </ul> <p>Simple Idea</p> <p>DSDV is like always updating a group GPS with versioned paths, even for unused routes.</p>"},{"location":"mobile-computing-unit%208/#reactive-routing-dynamic-source-routing-dsr","title":"Reactive Routing: Dynamic Source Routing (DSR)","text":"<p>DSR is a reactive protocol finding routes only when needed.</p> <ul> <li>How It Works:</li> <li>Route Discovery:<ul> <li>Device broadcasts a Route Request (RREQ) with a unique ID and destination address.</li> <li>Nodes add their address and forward, dropping duplicates.</li> <li>Destination receives RREQ, picks the best path, and sends a Route Reply (RREP) back via the reverse path.</li> </ul> </li> <li>Route Maintenance:<ul> <li>Checks paths during use; finds new ones if broken.</li> </ul> </li> <li>Source Routing: Data packets carry the full path in the header.</li> <li>Caching: Nodes save learned paths to avoid rediscovery.</li> <li>Optimizations:<ul> <li>Limits broadcasts with a counter (drops after max hops).</li> <li>Nodes cache routes from RREQs, RREPs, or overheard data.</li> </ul> </li> <li>Example: Passing a note through friends to find a path, then using it to send messages.</li> <li>Pros:</li> <li>Low overhead; only active routes maintained.</li> <li>Caching reduces discovery needs.</li> <li>Single discovery yields multiple routes.</li> <li>Cons:</li> <li>Large packet headers for long paths.</li> <li>Flooding RREQs congests networks.</li> <li>Collisions from simultaneous broadcasts.</li> <li>Reply storms from cached replies.</li> <li>Stale caches cause route failures.</li> </ul> <p>Simple Idea</p> <p>DSR is like asking for a delivery route only when sending a package, saving the path for later.</p>"},{"location":"mobile-computing-unit%208/#reactive-routing-ad-hoc-on-demand-distance-vector-aodv","title":"Reactive Routing: Ad-Hoc On-Demand Distance Vector (AODV)","text":"<p>AODV is a reactive protocol using distance vectors on demand.</p> <ul> <li>How It Works:</li> <li>Route Discovery:<ul> <li>Source broadcasts RREQ with ID, source/destination addresses, sequence numbers, and Time-to-Live (TTL).</li> <li>Nodes set reverse route entries (source address, hop count, sequence number, lifetime).</li> <li>Destination or a node with a fresh route sends RREP via reverse path.</li> <li>TTL increases if no reply, expanding the search.</li> </ul> </li> <li>Route Maintenance:<ul> <li>\u201cHello\u201d messages check neighbor links.</li> <li>Route Error (RERR) packets notify broken links, propagated to affected nodes.</li> </ul> </li> <li>Tables: Store next-hop info, destination address, sequence number, lifetime; entries expire if unused.</li> <li>Sequence Numbers: Each node increases its number when topology changes, ensuring fresh routes.</li> <li>Example: Shouting for a path, setting breadcrumbs back, and checking if neighbors are reachable.</li> <li>Pros:</li> <li>Low overhead; only active routes kept.</li> <li>Smaller tables than DSR (next-hop only).</li> <li>Adapts to topology changes.</li> <li>Cons:</li> <li>Delay for route discovery.</li> <li>Flooding RREQs can clog networks.</li> <li>Hello messages add some overhead.</li> </ul> <p>Simple Idea</p> <p>AODV is like calling out for a route when needed, remembering just the next step.</p>"},{"location":"mobile-computing-unit%208/#hybrid-routing-zone-routing-protocol-zrp","title":"Hybrid Routing: Zone Routing Protocol (ZRP)","text":"<p>ZRP combines proactive and reactive routing for efficiency.</p> <ul> <li>How It Works:</li> <li>Each device has a zone (nodes within a set hop limit, e.g., 2 hops).</li> <li>Intra-Zone Routing (IARP): Proactive, maintains paths within the zone using link-state methods.</li> <li>Inter-Zone Routing (IERP): Reactive, finds paths outside the zone like DSR.</li> <li>Zones are hop-based, not physical distance.</li> <li>Example: Knowing all nearby streets proactively but asking for directions to a distant city reactively.</li> <li>Pros:</li> <li>Fast routing within zones; efficient for distant nodes.</li> <li>Scales well for large networks.</li> <li>Reduces overhead compared to fully proactive protocols.</li> <li>Cons:</li> <li>Complex to manage zone boundaries.</li> <li>Performance depends on zone size.</li> </ul> <p>Simple Idea</p> <p>ZRP is like keeping a local map updated but asking for help to reach far places.</p>"},{"location":"mobile-computing-unit%208/#hierarchical-state-routing-protocol-hsr","title":"Hierarchical State Routing Protocol (HSR)","text":"<p>HSR organizes MANETs into clusters for scalable routing.</p> <ul> <li>How It Works:</li> <li>Devices form clusters, each with a cluster head.</li> <li>Heads form higher-level clusters, creating a hierarchy.</li> <li>Proactive routing within clusters; reactive or hierarchical routing between clusters.</li> <li>Uses logical addresses (e.g., cluster IDs) to simplify routing.</li> <li>Example: Schools divided into classes (clusters), with teachers (heads) linking classes.</li> <li>Pros:</li> <li>Scales well for large networks.</li> <li>Reduces routing overhead with hierarchy.</li> <li>Efficient for structured networks.</li> <li>Cons:</li> <li>Complex to set up clusters.</li> <li>Cluster head failures disrupt routing.</li> </ul> <p>Simple Idea</p> <p>HSR is like organizing a big group into teams, with leaders coordinating between them.</p>"},{"location":"mobile-computing-unit%208/#power-aware-routing-metrics","title":"Power-Aware Routing Metrics","text":"<p>Power-aware routing optimizes paths to save energy in MANETs.</p> <ul> <li>Metrics:</li> <li>Energy Consumption: Chooses paths using less total energy.</li> <li>Link Quality: Picks strong links needing less power to transmit.</li> <li>Distance: Prefers shorter paths to reduce power needs.</li> <li>Traffic Load: Avoids busy devices that drain more power.</li> <li>Battery Life: Favors devices with more battery to extend network life.</li> <li>Uses: Common in ZigBee, Bluetooth Low Energy, and Wireless Sensor Networks.</li> <li>Example: Routing through a drone with a full battery over a short, clear path.</li> <li>Pros:</li> <li>Saves energy, prolongs device and network life.</li> <li>Adapts to battery and link conditions.</li> <li>Cons:</li> <li>May choose longer routes to save power, increasing delay.</li> <li>Adds complexity to routing decisions.</li> </ul> <p>Simple Idea</p> <p>Power-aware routing is like picking an easy bike path to save energy.</p>"},{"location":"mobile-computing-unit%208/#comparison-table","title":"Comparison Table","text":"Protocol Type Route Maintenance Speed Overhead Best For DSDV Proactive Always updated Fast High Small, stable networks DSR Reactive On-demand Slower Low Dynamic, sparse networks AODV Reactive On-demand Slower Low Dynamic, frequent routing ZRP Hybrid Local proactive, distant reactive Medium Medium Large networks HSR Hierarchical Cluster-based Medium Medium Large, scalable networks"},{"location":"mobile-computing-unit%208/#process-flow-aodv-route-discovery","title":"Process Flow (AODV Route Discovery)","text":"<pre><code>graph TD\n    A[Source] --&gt;|Broadcast RREQ| B[Node B]\n    B --&gt;|Set Reverse Route, Forward| C[Node C]\n    C --&gt;|Set Reverse Route, Forward| D[Destination]\n    D --&gt;|Send RREP| C\n    C --&gt;|Forward RREP| B\n    B --&gt;|Forward RREP| A</code></pre>"},{"location":"mobile-computing-unit%209/","title":"Mobile computing unit 9","text":"Unit 1 Unit 2 Unit 3 Unit 4 Unit 5 Unit 6 Unit 7 Unit 8 Unit 9"},{"location":"mobile-computing-unit%209/#embedded-operating-systems-android-and-symbian","title":"Embedded Operating Systems: Android and Symbian","text":""},{"location":"mobile-computing-unit%209/#1-introduction-to-embedded-operating-systems-e-os","title":"1. Introduction to Embedded Operating Systems (E-OS)","text":"<ul> <li>Definition: Software tailored for mobile devices, integrating OS, middleware, and applications to meet specific hardware constraints.</li> <li>Purpose: Addresses needs of mobile users, operators, developers, and manufacturers for customization, functionality, and stability.</li> </ul> <p>Examples:   - Android   - Symbian OS   - iOS   - Windows CE   - Palm OS   - Embedded Linux (e.g., Open Zaurus, Metano GNU/Linux)</p> <p>Key Characteristics:   - Compact to fit limited memory.   - Designed for standalone, portable devices.   - Supports intermittent connectivity.   - Open platform for third-party development.</p>"},{"location":"mobile-computing-unit%209/#2-android-operating-system","title":"2. Android Operating System","text":""},{"location":"mobile-computing-unit%209/#21-introduction","title":"2.1 Introduction","text":"<ul> <li>Overview: Software stack for mobile devices including OS, middleware, and key apps.</li> <li>Base: Linux OS, developed by Google and Open Handset Alliance (OHA).</li> <li>Development: Uses Java-like language with Google\u2019s Java libraries; no native code support.</li> <li>Launch: Announced November 5, 2007, with OHA; released 2008 under Apache license.</li> </ul>"},{"location":"mobile-computing-unit%209/#22-birth-of-android","title":"2.2 Birth of Android","text":"<ul> <li>Acquisition: Google acquired Android Inc. in July 2005 (key figures: Andy Rubin, Rich Miner, Nick Sears, Chris White).</li> <li> <p>OHA Formation: November 2007, consortium of Google, HTC, Intel, Motorola, Qualcomm, etc., to promote open mobile standards.</p> </li> <li> <p>Hardware Prototypes:</p> <ul> <li>Mobile World Congress (Feb 2008): Basic apps demoed.</li> <li>Google I/O (May 2008): 528 MHz Qualcomm processor, 128 MB RAM, 256 MB flash, UMTS, 3.6 Mbit/s HSDPA.</li> </ul> </li> </ul>"},{"location":"mobile-computing-unit%209/#23-android-architecture","title":"2.3 Android Architecture","text":"<ul> <li>Layers:</li> <li> <p>Kernel Layer: Linux 2.6 for memory, process, security, networking, and drivers; acts as Hardware Abstraction Layer (HAL).</p> </li> <li> <p>Native Libraries Layer:         - SGL (2D graphics), OpenGL ES (3D graphics).         - SQLite (data storage), WebKit (web rendering).         - Dalvik Virtual Machine: Optimized for mobile, converts Java bytecode to .dex for efficiency.         - Core libraries: Java-based, System C library, Media Libraries, Surface Manager, FreeType.</p> </li> <li> <p>Application Runtime: Dalvik VM runs apps in separate processes; handles security, threading, memory via Linux kernel.</p> </li> <li>Application Framework Layer: Java-based APIs for telephony, data sharing, notifications; uniform for all apps.</li> <li> <p>Applications Layer: Core (e.g., Phone, Contacts) and third-party apps in Java, run by Dalvik VM.</p> </li> <li> <p>Key Features:</p> <ul> <li>All apps equal (no distinction between core and third-party).</li> <li>Third-party apps can replace core functions (e.g., dialer).</li> </ul> </li> </ul>"},{"location":"mobile-computing-unit%209/#24-application-building-blocks","title":"2.4 Application Building Blocks","text":"<ul> <li>Activity: User interface screen; can be faceless, floating, or return values.</li> <li>Intent Receiver: Responds to broadcast intents (e.g., notifications, alarms); apps can define custom intents.</li> <li>Service: Background tasks (e.g., music playback, downloads).</li> <li>Content Provider: Enables data sharing across apps (e.g., contacts, gallery) via URI and MIME types.</li> </ul>"},{"location":"mobile-computing-unit%209/#25-application-lifecycle","title":"2.5 Application Lifecycle","text":"<ul> <li> <p>Process Management:</p> <ul> <li>Each app runs in its own process for security and performance.</li> <li>Importance hierarchy for memory management:<ol> <li>Visible Process: Activity visible but not foreground (e.g., dialog overlay).</li> <li>Service Process: Running background services (e.g., music, downloads).</li> <li>Background Process: Non-visible activities; killed based on LRU (Least Recently Used).</li> <li>Empty Process: No active components; cached for faster restarts.</li> </ol> </li> </ul> </li> <li> <p>Impact: Incorrect use of components (Activity, Service, Broadcast Receiver) can lead to process termination during critical tasks.</p> </li> </ul>"},{"location":"mobile-computing-unit%209/#26-development-tools","title":"2.6 Development Tools","text":"<ul> <li>Java, Eclipse IDE, ADT Plug-in, Android SDK, Android Emulator, command-line tools, documentation.</li> </ul>"},{"location":"mobile-computing-unit%209/#27-security-issues","title":"2.7 Security Issues","text":"<ul> <li>Strengths: Linux-based secure coding, solutions like McAfee and SMobile Systems (anti-virus, firewall).</li> <li>Weaknesses:</li> <li>Open-source code vulnerable to black-hat hackers.</li> <li>Risks: Trojans, viruses, unauthorized GPS tracking, malicious apps mimicking legitimate ones.</li> <li>Mitigation: SMobile Security Shield for alerts and blocking; no device is fully secure online.</li> </ul>"},{"location":"mobile-computing-unit%209/#28-advantages","title":"2.8 Advantages","text":"<ul> <li>Open API access to core functions.</li> <li>Equal treatment of all apps.</li> <li>Combines web and phone data for new experiences.</li> <li>Easy development with SDK and emulator.</li> </ul>"},{"location":"mobile-computing-unit%209/#29-disadvantages","title":"2.9 Disadvantages","text":"<ul> <li>Open-source invites hacker scrutiny.</li> <li>Unencrypted file system, vulnerable login.</li> <li>Dependence on hardware/carrier partners reduces Google\u2019s control.</li> </ul>"},{"location":"mobile-computing-unit%209/#210-why-android","title":"2.10 Why Android?","text":"<ul> <li>Open-source, Flash support, diverse models, reasonable prices, Google Apps, utility apps (e.g., Astro, Taskiller).</li> </ul>"},{"location":"mobile-computing-unit%209/#211-android-versions","title":"2.11 Android Versions","text":"<ul> <li>1.1, 1.5 (Cupcake), 1.6 (Donuts), 2.0 (\u00c9clair), 2.2 (Froyo), 2.3 (Gingerbread), 3.0 (Honeycomb).</li> <li>API levels ensure forward compatibility, not always backward.</li> </ul>"},{"location":"mobile-computing-unit%209/#3-symbian-operating-system","title":"3. Symbian Operating System","text":""},{"location":"mobile-computing-unit%209/#31-introduction","title":"3.1 Introduction","text":"<ul> <li>Overview: Designed for smartphones, supports multiple manufacturers, focuses on communication.</li> <li> <p>Market Needs:</p> <ul> <li>Small, mobile devices.</li> <li>Mass-market appeal.</li> <li>Intermittent connectivity.</li> <li>Product differentiation.</li> <li>Open platform for third-party apps.</li> </ul> </li> <li> <p>Goal: Compact yet feature-rich OS for 2.5G/3G networks, distinct from scaled-down PC OS.</p> </li> </ul>"},{"location":"mobile-computing-unit%209/#32-symbian-history","title":"3.2 Symbian History","text":"<ul> <li>Origin: Evolved from Psion\u2019s EPOC OS; renamed Symbian OS in 1998.</li> <li>Ownership: Ericsson, Nokia, Panasonic, Psion, Siemens, Sony-Ericsson; open licensing.</li> <li>Devices: Sony Ericsson P800, Nokia 9200 Communicator, NTT DoCoMo Fujitsu 2102V.</li> </ul>"},{"location":"mobile-computing-unit%209/#33-fundamental-requirements","title":"3.3 Fundamental Requirements","text":"<ul> <li>Standalone portable operation.</li> <li>Supports diverse devices.</li> <li>Future-proof, open licensing.</li> <li>Open for app development.</li> <li>Based on open standards (e.g., POSIX, J2ME, Bluetooth).</li> </ul>"},{"location":"mobile-computing-unit%209/#34-architecture","title":"3.4 Architecture","text":"<ul> <li> <p>Layers:</p> <ol> <li>Core: Kernel, file server, memory management, device drivers.</li> <li>System Layer: TCP/IP, IMAP4, SMS, database management.</li> <li>Application Engines: Interfaces for data access.</li> <li>User Interface Software: Customizable by manufacturers.</li> <li>Applications: Added above UI.</li> </ol> </li> <li> <p>Design: Hardware-independent, extendable, open for development.</p> </li> </ul>"},{"location":"mobile-computing-unit%209/#35-features","title":"3.5 Features","text":"<ul> <li>Client-Server Architecture: Programs (clients) access resources via servers for timely responses.</li> <li>Event Management: Event-based time sharing in a single thread; supports interactive designs.</li> <li>Object-Oriented Design: Configurable for hardware, component-based, flexible UI.</li> <li>Power Management: Kernel-level efficiency; disables unused peripherals.</li> <li>Robustness: Protected address spaces prevent data loss or crashes.</li> <li>Memory Management: Minimizes usage; supports RAM and flash memory.</li> <li>Full Multitasking: Runs multiple apps concurrently (e.g., calendar during a call).</li> </ul>"},{"location":"mobile-computing-unit%209/#36-platform-security","title":"3.6 Platform Security","text":"<ul> <li>Trust: Controls access to private data.</li> <li>Security: Manages costs, protects phone functions.</li> <li>Protection: Software ownership, DRM.</li> <li>Mechanisms: Trusted software installation, secure IPC, TCE (protects sensitive APIs).</li> </ul>"},{"location":"mobile-computing-unit%209/#37-strengths","title":"3.7 Strengths","text":"<ul> <li>Memory Management: Paging, address translation; no demand-paged virtual memory.</li> <li>Execution in-Place: Runs programs from flash memory, reducing RAM usage and load time.</li> </ul>"},{"location":"mobile-computing-unit%209/#38-weaknesses","title":"3.8 Weaknesses","text":"<ul> <li>No virtual memory; relies on RAM and flash.</li> <li>Limited memory impacts scalability.</li> </ul>"},{"location":"mobile-computing-unit%209/#39-advantages","title":"3.9 Advantages","text":"<ul> <li>Wide app range, high-quality games, better WAP browser, fast connectivity, media players.</li> <li>Supports software installation, large file downloads via 3G.</li> </ul>"},{"location":"mobile-computing-unit%209/#310-disadvantages","title":"3.10 Disadvantages","text":"<ul> <li>Not available for PCs.</li> <li>Susceptible to viruses.</li> </ul>"},{"location":"mobile-computing-unit%209/#4-android-vs-symbian","title":"4. Android vs. Symbian","text":"<ul> <li>Firmware Updates:<ul> <li>Symbian: Requires new phone for major updates (e.g., s60v3 to s60v5).</li> <li>Android: Software upgrades via phone/PC (e.g., 1.6 to 2.1).</li> </ul> </li> <li>Flashing:<ul> <li>Symbian: Risky; themes or new firmware via PC; failure can brick phone.</li> <li>Android: Safer; themes, launchers, or custom firmware via recovery menu; recoverable.</li> </ul> </li> <li>Feature Customization:<ul> <li>Symbian: Apps for UI changes consume memory, not default; custom firmware risky.</li> <li>Android: Replace default apps (e.g., file browser) without risks or extra memory.</li> </ul> </li> <li>Processor Control:<ul> <li>Symbian: No visibility/control over processor speed.</li> <li>Android: Apps monitor/control speed for battery or performance.</li> </ul> </li> <li>Modifications:<ul> <li>Symbian: Limited user modifications.</li> <li>Android: Encourages extensive customization.</li> </ul> </li> </ul>"},{"location":"mobile-computing-unit%209/#5-conclusion","title":"5. Conclusion","text":"<ul> <li>Android: Advanced, user-focused, supports extensive customization and updates.</li> <li>Symbian: Needs feature updates to compete; strong in traditional phone functions.</li> <li>Trend: Android\u2019s flexibility and open-source model give it an edge in modern mobile markets.</li> </ul>"},{"location":"reinforcement-learning-unit%201/","title":"Unit 1: Basics of Reinforcement Learning","text":"<p>Reinforcement Learning (RL) is a dynamic AI paradigm where an agent learns to make decisions by interacting with an environment to maximize cumulative rewards. This unit explores RL\u2019s applications, framework, comparison with other learning types, characteristics, problem elements, and immediate RL.</p>"},{"location":"reinforcement-learning-unit%201/#what-are-the-real-world-applications-of-reinforcement-learning","title":"What Are the Real-World Applications of Reinforcement Learning?","text":"<p>Reinforcement Learning powers systems that require adaptive decision-making in complex, dynamic environments. Its applications span multiple domains, leveraging trial-and-error learning to optimize outcomes. Key examples include:</p> <ul> <li>Toddler Learning to Walk: A child experiments with steps, receiving feedback (stability or falling), and refines movements to walk steadily, mirroring RL\u2019s reward-driven learning.</li> <li>Game-Playing Agents: Systems like DeepMind\u2019s AlphaGo and OpenAI\u2019s Dota 2 bot learn optimal strategies by playing millions of games, maximizing scores or wins.</li> <li>Robotics: Robots use RL to master tasks like grasping objects or navigating spaces, optimizing actions based on sensor feedback (e.g., +10 for a successful grasp).</li> <li>Autonomous Vehicles: Self-driving cars adjust speed, steering, or lane changes to maximize safety and efficiency, using rewards tied to traffic rules and collision avoidance.</li> <li>Healthcare: RL optimizes treatment plans, such as adjusting drug dosages for chronic diseases, maximizing patient recovery metrics.</li> <li>Finance: Trading algorithms learn to buy or sell stocks to maximize profits, with rewards based on portfolio growth.</li> <li>Smart Grids: RL manages energy distribution in power systems, optimizing for cost, demand, and sustainability.</li> <li>Recommendation Systems: Platforms like Netflix use RL to suggest content, maximizing user engagement (e.g., time spent watching).</li> </ul> <p>Mnemonic: RL Applications</p> <p>\"GAMES\": Games, Autonomous systems, Medicine, Energy, Stock trading.</p> <p>Why RL Excels</p> <p>RL thrives in scenarios where explicit instructions are impractical, and learning from interaction is the only viable approach.</p>"},{"location":"reinforcement-learning-unit%201/#explain-the-rl-framework-what-are-its-core-components","title":"Explain the RL Framework. What Are Its Core Components?","text":"<p>The RL framework models an agent learning optimal behavior through interaction with an environment. The agent observes the environment\u2019s state, takes actions, receives rewards, and updates its strategy to maximize long-term rewards. This iterative process is formalized as a Markov Decision Process (MDP).</p>"},{"location":"reinforcement-learning-unit%201/#core-components","title":"Core Components","text":"<ol> <li>Agent: The learner or decision-maker (e.g., a robot, game AI).</li> <li>Environment: The external system the agent interacts with (e.g., a maze, stock market).</li> <li>State (S): A snapshot of the environment at a given time (e.g., the agent\u2019s position in a grid).</li> <li>Action (A): Choices the agent can make (e.g., move left, buy stock).</li> <li>Reward (R): A scalar feedback signal indicating the action\u2019s success (e.g., +100 for reaching a goal).</li> <li>Policy (\u03c0): The agent\u2019s strategy, mapping states to actions (deterministic: \u03c0(s) = a, or probabilistic: \u03c0(a|s)).</li> <li>Value Function (V or Q): Estimates the expected cumulative reward for a state (V(s)) or state-action pair (Q(s, a)).</li> <li>Transition Function (P): Defines the probability of moving to a new state given a state and action (P(s\u2019|s, a)).</li> <li>Discount Factor (\u03b3): Balances immediate vs. future rewards (0 \u2264 \u03b3 \u2264 1; e.g., \u03b3 = 0.9 prioritizes long-term gains).</li> </ol>"},{"location":"reinforcement-learning-unit%201/#rl-process-flow","title":"RL Process Flow","text":"<p>The agent-environment interaction forms a loop, as shown in this Mermaid diagram:</p> <p></p>"},{"location":"reinforcement-learning-unit%201/#how-it-works","title":"How It Works","text":"<ol> <li>The agent observes the current state \\( s_t \\).</li> <li>Based on its policy \\( \\pi \\), it selects an action \\( a_t \\).</li> <li>The environment responds with a reward \\( r_{t+1} \\) and a new state \\( s_{t+1} \\).</li> <li>The agent updates its policy or value function to improve future decisions.</li> <li>The cycle repeats, aiming to maximize the cumulative reward:</li> </ol> \\[G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots\\] <p>Definition: RL Framework</p> <p>RL is a sequential decision-making process where an agent learns an optimal policy by trial and error to maximize expected discounted rewards.</p>"},{"location":"reinforcement-learning-unit%201/#what-are-the-different-types-of-learning-in-ai","title":"What Are the Different Types of Learning in AI?","text":"<p>AI learning paradigms vary based on data and feedback mechanisms. The three primary types are:</p> <p>Supervised Learning:</p> <ul> <li>Uses labeled datasets (input-output pairs) to train models.</li> <li>Goal: Predict accurate outputs for new inputs.</li> <li>Example: Classifying images as \u201ccat\u201d or \u201cdog\u201d using labeled images.</li> <li>Applications: Spam detection, speech recognition, regression.</li> </ul> <p>Unsupervised Learning:</p> <ul> <li>Works with unlabeled data to find hidden patterns or structures.</li> <li>Goal: Group or organize data without predefined outputs.</li> <li>Example: Clustering customers based on purchasing behavior.</li> <li>Applications: Market segmentation, anomaly detection, data compression.</li> </ul> <p>Reinforcement Learning:</p> <ul> <li>Learns through interaction with an environment, guided by rewards.</li> <li>Goal: Maximize cumulative rewards through trial and error.</li> <li>Example: A robot learning to navigate a maze by earning rewards for reaching the exit.</li> <li>Applications: Game AI, robotics, resource optimization.</li> </ul> <p>Mnemonic: AI Learning Types</p> <p>\"SUP\": Supervised (predict), Unsupervised (pattern), P for RL (policy/reward).</p>"},{"location":"reinforcement-learning-unit%201/#compare-and-contrast-supervised-unsupervised-and-reinforcement-learning","title":"Compare and Contrast Supervised, Unsupervised, and Reinforcement Learning","text":"<p>The table below provides a detailed comparison of the three learning paradigms:</p> Aspect Supervised Learning Unsupervised Learning Reinforcement Learning Data Labeled (input-output pairs, e.g., images with labels) Unlabeled (raw data, e.g., customer transactions) No predefined dataset; generated via environment interaction Goal Minimize prediction error to match labels Discover patterns, clusters, or representations Maximize cumulative reward over time Feedback Direct feedback (correct labels) No feedback; relies on data structure Sparse, delayed rewards from environment Learning Process Train on static dataset, optimize loss (e.g., MSE) Iterative pattern discovery (e.g., k-means) Trial-and-error, policy optimization Example Predicting house prices from features Grouping similar news articles Training a drone to avoid obstacles Challenges Requires large labeled datasets Hard to evaluate results without labels Balancing exploration vs. exploitation Applications Image recognition, natural language processing Dimensionality reduction, clustering Autonomous systems, game AI, optimization Environment Interaction None; data is static None; data is static Dynamic; actions affect future states Time Horizon One-shot predictions One-shot or iterative analysis             ** Sequential, long-term decision-making <p>Key Difference</p> <p>RL\u2019s dynamic interaction and delayed rewards distinguish it from supervised and unsupervised learning, which rely on static datasets and immediate feedback.</p> <p>Common Pitfall</p> <p>Misapplying supervised learning to sequential decision tasks (like robotics) can fail, as it doesn\u2019t account for action-state dependencies, unlike RL.</p>"},{"location":"reinforcement-learning-unit%201/#list-and-explain-characteristics-of-rl","title":"List and Explain Characteristics of RL","text":"<p>RL\u2019s unique characteristics define its approach to learning:</p> <p>Trial-and-Error Learning:</p> <ul> <li>Agents learn by experimenting with actions and observing outcomes.</li> <li>Example: A robot tries different arm movements to pick up an object, refining based on success or failure.</li> </ul> <p>Delayed Rewards:</p> <ul> <li>Rewards may come after a sequence of actions, requiring the agent to plan for long-term outcomes.</li> <li>Example: In chess, the reward (win/loss) is only received at the game\u2019s end.</li> </ul> <p>Dynamic Environment:</p> <ul> <li>The environment changes based on the agent\u2019s actions, creating a feedback loop.</li> <li>Example: A self-driving car\u2019s actions (e.g., braking) alter traffic conditions.</li> </ul> <p>No Supervisor:</p> <ul> <li>Unlike supervised learning, RL relies on reward signals, not explicit instructions.</li> <li>Example: A game AI learns strategies without being told the \u201ccorrect\u201d move.</li> </ul> <p>Exploration vs. Exploitation:</p> <ul> <li>Agents must balance exploring new actions (to discover better strategies) with exploiting known rewarding actions.</li> <li>Example: A trading bot tests new stocks (exploration) but focuses on profitable ones (exploitation).</li> </ul> <p>Sequential Decision-Making:</p> <ul> <li>Actions influence future states and rewards, requiring foresight.</li> <li>Example: In a maze, moving left now may block a future path.</li> </ul>"},{"location":"reinforcement-learning-unit%201/#what-are-the-key-elements-of-an-rl-problem","title":"What Are the Key Elements of an RL Problem?","text":"<p>An RL problem is formalized as a Markov Decision Process (MDP), which includes the following elements:</p> <p>Set of States (S):</p> <ul> <li>All possible configurations of the environment.</li> <li>Example: In a grid world, states are the agent\u2019s coordinates (x, y).</li> </ul> <p>Set of Actions (A):</p> <ul> <li>All possible decisions the agent can make.</li> <li>Example: Move {up, down, left, right} in a maze.</li> </ul> <p>Reward Function (R):</p> <ul> <li>Maps state-action pairs (or states) to a scalar reward.</li> <li>Example: R(s, a) = +100 for reaching the goal, -1 for hitting a wall.</li> </ul> <p>Transition Probability (P):</p> <ul> <li>Defines the likelihood of moving to a new state given a current state and action (P(s\u2019|s, a)).</li> <li>Example: Moving right in a deterministic grid moves to (x+1, y).</li> </ul> <p>Discount Factor (\u03b3):</p> <ul> <li>A value (0 \u2264 \u03b3 \u2264 1) that balances immediate vs. future rewards.</li> <li>Example: \u03b3 = 0.9 discounts future rewards, prioritizing near-term gains.</li> </ul> <p>Policy (\u03c0):</p> <ul> <li>The agent\u2019s strategy, mapping states to actions (\u03c0(s) = a or \u03c0(a|s) for probabilistic policies).</li> <li>Example: A policy might dictate \u201calways move toward the goal.\u201d</li> </ul>"},{"location":"reinforcement-learning-unit%201/#example-maze-navigation","title":"Example: Maze Navigation","text":"<ul> <li>States: Grid cells (e.g., (2, 3)).</li> <li>Actions: {up, down, left, right}.</li> <li>Rewards: +100 for reaching the exit, -1 for each step.</li> <li>Transitions: Deterministic (move right from (1, 1) goes to (2, 1)).</li> <li>Discount Factor: \u03b3 = 0.95.</li> <li>Policy: Move toward the exit while avoiding walls.</li> </ul> <p>Formula: Objective</p> <p>The agent seeks to maximize the expected cumulative reward: [ G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + \\dots ] where \\( G_t \\) is the discounted return at time \\( t \\).</p>"},{"location":"reinforcement-learning-unit%201/#what-is-immediate-reinforcement-learning","title":"What Is Immediate Reinforcement Learning?","text":"<p>Immediate Reinforcement Learning is a simplified RL setting where the agent receives rewards immediately after each action, eliminating the complexity of delayed rewards.</p> <ul> <li>Characteristics:</li> <li>Rewards are tied directly to the action just taken, providing instant feedback.</li> <li>Simplifies learning, as the agent doesn\u2019t need to account for future states or long-term consequences.</li> <li>Often used in controlled or educational environments to teach RL basics.</li> <li>Example:</li> <li>In a tic-tac-toe game, the agent gets +10 for placing a mark that wins the game immediately.</li> <li>In a slot machine simulation, each pull yields an instant reward (+5 or 0).</li> <li>Advantages:</li> <li>Faster learning due to clear action-reward associations.</li> <li>Easier to implement and debug in simple environments.</li> <li>Limitations:</li> <li>Rarely reflects real-world scenarios, where rewards are often delayed (e.g., winning a chess game requires many moves).</li> <li>Less applicable to complex tasks requiring strategic planning.</li> <li>Comparison to Standard RL:</li> <li>Standard RL handles delayed rewards, requiring algorithms like Q-learning or policy gradients to estimate future rewards.</li> <li>Immediate RL is a special case, often used in bandit problems (e.g., choosing the best slot machine).</li> </ul> <p>Mnemonic: Immediate RL</p> <p>\"AIR\": Action, Instant Reward.</p> <p>Practical Note</p> <p>Immediate RL is useful for prototyping or teaching but should transition to delayed reward models for real-world applications.</p>"},{"location":"reinforcement-learning-unit%202/","title":"Unit 2: Multi-Arm Bandits","text":"<p>Multi-Arm Bandit (MAB) problems are a cornerstone of reinforcement learning (RL), modeling decision-making under uncertainty. They focus on the exploration vs. exploitation trade-off, where an agent must choose between trying new options (exploration) to learn their value or selecting known high-reward options (exploitation) to maximize cumulative rewards. This unit provides an in-depth exploration of the k-armed bandit problem, key algorithms (\u03b5-greedy, Upper Confidence Bound), action-value methods, non-stationary tracking, and comparative analyses, enriched with detailed examples and conceptual insights.</p>"},{"location":"reinforcement-learning-unit%202/#what-is-the-k-armed-bandit-problem","title":"What Is the K-Armed Bandit Problem?","text":"<p>The k-armed bandit problem is a fundamental RL problem inspired by a gambler facing \\( k \\) slot machines (\"bandits\"), each with an unknown reward probability distribution. The agent\u2019s goal is to maximize total rewards over a series of trials by strategically choosing which arm to pull, balancing the need to explore unknown arms and exploit known high-reward ones.</p>"},{"location":"reinforcement-learning-unit%202/#formal-definition","title":"Formal Definition","text":"<ul> <li>Setup:</li> <li>At each time step \\( t = 1, 2, \\dots, T \\), the agent selects one of \\( k \\) arms, denoted \\( A_t \\in \\{1, 2, \\dots, k\\} \\).</li> <li>The environment returns a reward \\( R_t \\), drawn from the arm\u2019s unknown probability distribution.</li> <li>Each arm \\( a \\) has a true expected reward (action value) \\( q_*(a) = E[R_t | A_t = a] \\), which is stationary (unchanging) in the classic setting.</li> <li>Objective: Maximize the cumulative reward:</li> </ul> \\[  \\sum_{t=1}^T R_t  \\] <ul> <li>Regret: The difference between the optimal reward (always choosing the best arm) and the actual reward:</li> </ul> \\[  \\text{Regret} = T \\cdot \\max_a q_*(a) - \\sum_{t=1}^T R_t\\] <ul> <li>Key Characteristics:</li> <li>Single-state problem: No state transitions, unlike general RL.</li> <li>Unknown distributions: The agent estimates \\( q_*(a) \\) via observed rewards.</li> <li>Exploration vs. Exploitation: Trying new arms risks low rewards but improves estimates; sticking to the best-known arm maximizes short-term gains but may miss better options.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#example-restaurant-choice","title":"Example: Restaurant Choice","text":"<ul> <li>Scenario: You\u2019re in a town with 4 restaurants (arms) for 1000 days. Each restaurant has an unknown probability of a \"happy\" meal: \\( P(M_1) = 0.6 \\), \\( P(M_2) = 0.4 \\), \\( P(M_3) = 0.7 \\), \\( P(M_4) = 0.9 \\). Reward = 1 for a happy meal, 0 otherwise.</li> <li>Strategies:</li> <li>Exploit Only: Always choose restaurant 1 (assuming it seems best initially). Expected reward: \\( 1000 \\times 0.6 = 600 \\). Regret: \\( 1000 \\times 0.9 - 600 = 300 \\).</li> <li>Explore Only: Choose each restaurant 250 times. Expected reward: \\( 250 \\times (0.6 + 0.4 + 0.7 + 0.9) = 650 \\). Regret: \\( 900 - 650 = 250 \\).</li> <li>Optimal: Always choose restaurant 4 (if probabilities were known). Expected reward: \\( 1000 \\times 0.9 = 900 \\).</li> <li>Challenge: Without knowing probabilities, the agent must balance trying all restaurants to find the best (exploration) with repeatedly visiting the best-known one (exploitation).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#real-world-analogies","title":"Real-World Analogies","text":"<ul> <li>Clinical Trials: Test different drugs (arms) to find the most effective, balancing patient outcomes (exploitation) with learning about new treatments (exploration).</li> <li>Online Advertising: Choose between ad campaigns to maximize clicks, testing new ads (exploration) vs. showing high-performing ads (exploitation).</li> <li>Game Playing: In chess, play known strong moves (exploitation) or experimental moves to learn their effectiveness (exploration).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#process-flow","title":"Process Flow","text":"<p>The k-armed bandit interaction is a simple feedback loop, as shown below:</p> <p></p> <p>Definition: K-Armed Bandit</p> <p>A k-armed bandit problem involves selecting one of \\( k \\) actions with unknown reward distributions to maximize cumulative rewards, formalized as a single-state Markov Decision Process (MDP).</p> <p>Key Challenge</p> <p>Over-exploration wastes trials on poor arms; over-exploitation risks missing the optimal arm, leading to high regret.</p>"},{"location":"reinforcement-learning-unit%202/#what-is-the-greedy-algorithm","title":"What Is the \u03b5-Greedy Algorithm?","text":"<p>The \u03b5-greedy algorithm is a widely used method to balance exploration and exploitation in k-armed bandit problems. It predominantly selects the arm with the highest estimated reward (greedy action) but occasionally chooses a random arm to explore, controlled by a parameter \\( \\epsilon \\).</p>"},{"location":"reinforcement-learning-unit%202/#detailed-algorithm","title":"Detailed Algorithm","text":"<ol> <li>Initialization:</li> <li>For each arm \\( a = 1, 2, \\dots, k \\):<ul> <li>Set initial action-value estimate \\( Q_1(a) = 0 \\) (or an optimistic value, e.g., 5).</li> <li>Set selection count \\( N_1(a) = 0 \\).</li> </ul> </li> <li>Choose exploration probability \\( \\epsilon \\in [0, 1] \\).</li> <li>For each time step \\( t = 1, 2, \\dots, T \\):</li> <li>Generate a random number \\( x \\sim \\text{Uniform}[0, 1] \\).</li> <li>Action Selection:<ul> <li>If \\( x &gt; \\epsilon \\) (probability \\( 1 - \\epsilon \\)):</li> <li>Exploit: Choose the greedy action \\( A_t = \\arg\\max_a Q_t(a) \\). Break ties randomly.</li> <li>Else (probability \\( \\epsilon \\)):</li> <li>Explore: Choose a random arm \\( A_t \\) with probability \\( 1/k \\).</li> </ul> </li> <li>Receive Reward: Pull arm \\( A_t \\), get reward \\( R_t \\).</li> <li>Update Counts: \\( N_{t+1}(A_t) = N_t(A_t) + 1 \\).</li> <li>Update Action-Value:</li> </ol> \\[      Q_{t+1}(A_t) = Q_t(A_t) + \\frac{1}{N_t(A_t)} [R_t - Q_t(A_t)]   \\] <p>For other arms \\( a \\neq A_t \\), \\( Q_{t+1}(a) = Q_t(a) \\), \\( N_{t+1}(a) = N_t(a) \\).</p>"},{"location":"reinforcement-learning-unit%202/#numerical-example","title":"Numerical Example","text":"<ul> <li>Setup: 4-arm bandit with true win probabilities \\( P(M_1) = 0.6 \\), \\( P(M_2) = 0.4 \\), \\( P(M_3) = 0.7 \\), \\( P(M_4) = 0.9 \\). Use \\( \\epsilon = 0.2 \\), run for 5 steps.</li> <li>Input:</li> <li>Random numbers for action selection: [0.68, 0.55, 0.23, 0.95, 0.8].</li> <li>Random numbers for rewards: [0.6, 0.2, 0.3, 0.4, 0.9].</li> <li>Reward rule: If random number \\( \\leq P(M_i) \\), \\( R_t = 1 \\); else \\( R_t = 0 \\).</li> <li>Initialization: \\( Q_1(a) = 0 \\), \\( N_1(a) = 0 \\) for all arms.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#step-by-step-execution","title":"Step-by-Step Execution","text":"<p>Step 1:</p> <ul> <li>\\( x = 0.68 &gt; 0.2 \\), greedy. All \\( Q_1(a) = 0 \\), pick \\( M_1 \\) (random tie-break).</li> <li>Reward: \\( 0.6 \\leq 0.6 \\), \\( R_1 = 1 \\).</li> <li>Update: \\( N_2(M_1) = 1 \\), \\( Q_2(M_1) = 0 + \\frac{1}{1} (1 - 0) = 1 \\).</li> </ul> <p>Step 2:</p> <ul> <li>\\( x = 0.55 &gt; 0.2 \\), greedy. \\( Q_2(M_1) = 1 \\), others 0, pick \\( M_1 \\).</li> <li>Reward: \\( 0.2 \\leq 0.6 \\), \\( R_2 = 1 \\).</li> <li>Update: \\( N_3(M_1) = 2 \\), \\( Q_3(M_1) = 1 + \\frac{1}{2} (1 - 1) = 1 \\).</li> </ul> <p>Step 3:</p> <ul> <li>\\( x = 0.23 &gt; 0.2 \\), greedy. Pick \\( M_1 \\).</li> <li>Reward: \\( 0.3 \\leq 0.6 \\), \\( R_3 = 1 \\).</li> <li>Update: \\( N_4(M_1) = 3 \\), \\( Q_4(M_1) = 1 + \\frac{1}{3} (1 - 1) = 1 \\).</li> </ul> <p>Step 4:</p> <ul> <li>\\( x = 0.95 &gt; 0.2 \\), greedy. Pick \\( M_1 \\).</li> <li>Reward: \\( 0.4 \\leq 0.6 \\), \\( R_4 = 1 \\).</li> <li>Update: \\( N_5(M_1) = 4 \\), \\( Q_5(M_1) = 1 + \\frac{1}{4} (1 - 1) = 1 \\).</li> </ul> <p>Step 5:</p> <ul> <li>\\( x = 0.8 &gt; 0.2 \\), greedy. Pick \\( M_1 \\).</li> <li>Reward: \\( 0.9 &gt; 0.6 \\), \\( R_5 = 0 \\).</li> <li>Update: \\( N_6(M_1) = 5 \\), \\( Q_6(M_1) = 1 + \\frac{1}{5} (0 - 1) = \\frac{4}{5} = 0.8 \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#results","title":"Results","text":"<ul> <li>Total Reward: \\( 1 + 1 + 1 + 1 + 0 = 4 \\).</li> <li>Optimal Reward: Always pick \\( M_4 \\): \\( 0.9 \\times 5 = 4.5 \\).</li> <li>Regret: \\( 4.5 - 4 = 0.5 \\).</li> <li>Analysis: The algorithm was unlucky, as no exploration (\\( x &lt; 0.2 \\)) occurred, missing \\( M_4 \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#advantages-and-limitations","title":"Advantages and Limitations","text":"<ul> <li>Advantages:</li> <li>Simple to implement and understand.</li> <li>Guarantees exploration of all arms with \\( \\epsilon &gt; 0 \\), ensuring \\( Q_t(a) \\to q_*(a) \\) as \\( t \\to \\infty \\).</li> <li>Effective in stationary environments with proper \\( \\epsilon \\).</li> <li>Limitations:</li> <li>Fixed \\( \\epsilon \\) leads to unnecessary exploration in later steps, increasing regret.</li> <li>Random exploration may repeatedly select poor arms.</li> <li>Requires tuning \\( \\epsilon \\), which is problem-dependent.</li> </ul> <p>Pitfall</p> <p>A high \\( \\epsilon \\) (e.g., 0.5) wastes trials on suboptimal arms, while \\( \\epsilon = 0 \\) (pure greedy) risks getting stuck on a suboptimal arm.</p>"},{"location":"reinforcement-learning-unit%202/#what-is-epsilon-decay-and-why-is-it-used","title":"What Is Epsilon Decay, and Why Is It Used?","text":"<p>Epsilon decay is an enhancement to the \u03b5-greedy algorithm where the exploration probability \\( \\epsilon \\) decreases over time, shifting focus from exploration to exploitation as the agent gains confidence in its action-value estimates.</p>"},{"location":"reinforcement-learning-unit%202/#detailed-mechanism","title":"Detailed Mechanism","text":"<ul> <li>Initial \\( \\epsilon \\): Start with a high \\( \\epsilon_0 \\) (e.g., 0.5) to encourage exploration.</li> <li>Decay Strategies:</li> <li>Linear Decay: \\( \\epsilon_t = \\epsilon_0 - \\delta \\cdot t \\), where \\( \\delta \\) is a small constant (e.g., \\( \\delta = 0.0001 \\)).</li> <li>Exponential Decay: \\( \\epsilon_t = \\epsilon_0 \\cdot \\gamma^t \\), where \\( 0 &lt; \\gamma &lt; 1 \\) (e.g., \\( \\gamma = 0.999 \\)).</li> <li>Inverse Decay: \\( \\epsilon_t = \\frac{\\epsilon_0}{1 + \\kappa \\cdot t} \\), where \\( \\kappa \\) controls decay speed.</li> <li>Minimum \\( \\epsilon \\): Set a floor \\( \\epsilon_{\\text{min}} \\) (e.g., 0.01) to ensure some exploration persists.</li> <li>Implementation:</li> <li>Update \\( \\epsilon_t \\) after each step or episode.</li> <li>Example: \\( \\epsilon_t = \\max(0.01, 0.5 \\cdot 0.999^t) \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#why-its-used","title":"Why It\u2019s Used","text":"<ol> <li>Early Exploration: High initial \\( \\epsilon \\) ensures all arms are sampled, reducing the risk of missing the optimal arm.</li> <li>Late Exploitation: As \\( Q_t(a) \\) becomes reliable, lower \\( \\epsilon \\) focuses on the best arm, maximizing rewards.</li> <li>Reduced Regret: Decreasing exploration minimizes trials wasted on suboptimal arms.</li> <li>Adaptability: Matches the learning process, where uncertainty decreases over time.</li> <li>Practicality: Avoids manual tuning of a fixed \\( \\epsilon \\).</li> </ol>"},{"location":"reinforcement-learning-unit%202/#example-exponential-decay","title":"Example: Exponential Decay","text":"<ul> <li>Setup: \\( \\epsilon_0 = 0.5 \\), \\( \\gamma = 0.995 \\), \\( \\epsilon_{\\text{min}} = 0.01 \\), \\( T = 1000 \\).</li> <li>Calculation:</li> <li>Step 100: \\( \\epsilon_{100} = 0.5 \\cdot 0.995^{100} \\approx 0.303 \\).</li> <li>Step 500: \\( \\epsilon_{500} \\approx 0.036 \\).</li> <li>Step 1000: \\( \\epsilon_{1000} \\approx 0.01 \\) (hits minimum).</li> <li>Impact: Early steps explore ~50% of the time; by step 1000, exploration drops to ~1%, prioritizing the best arm.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#derivation-why-decay-works","title":"Derivation: Why Decay Works","text":"<ul> <li>Early Phase: High \\( \\epsilon \\) increases \\( N_t(a) \\) for all arms, improving \\( Q_t(a) \\) accuracy.</li> <li>Late Phase: As \\( Q_t(a) \\to q_*(a) \\), the optimal arm\u2019s \\( Q_t(a) \\) dominates, and exploration becomes less necessary.</li> <li>Regret Analysis:</li> <li>Fixed \\( \\epsilon \\): Linear regret (\\( O(T) \\)), as exploration continues indefinitely.</li> <li>Decaying \\( \\epsilon \\): Sublinear regret (e.g., \\( O(\\sqrt{T}) \\)) with proper decay (e.g., \\( \\epsilon_t \\propto 1/t \\)).</li> </ul> <p>Formula: Exponential Decay</p> \\[ \\epsilon_t = \\max(\\epsilon_{\\text{min}}, \\epsilon_0 \\cdot \\gamma^t) \\] <p>Tuning Challenge</p> <p>Too fast a decay (large \\( \\gamma \\)) may stop exploration prematurely; too slow a decay wastes trials. Tune \\( \\gamma \\) based on problem horizon \\( T \\).</p>"},{"location":"reinforcement-learning-unit%202/#what-are-action-value-methods","title":"What Are Action-Value Methods?","text":"<p>Action-value methods are techniques that estimate the expected reward (action value) of each arm based on observed rewards and use these estimates to guide action selection. They form the foundation of bandit algorithms like \u03b5-greedy, UCB, and optimistic initial values.</p>"},{"location":"reinforcement-learning-unit%202/#core-components","title":"Core Components","text":"<p>Expected Value \\( q_*(a) \\):</p> <ul> <li>The true mean reward for arm \\( a \\): \\( q_*(a) = E[R_t | A_t = a] \\).</li> <li>Example: For a Bernoulli bandit, \\( q_*(a) = P(\\text{win}) \\).</li> <li>Unknown to the agent, it\u2019s estimated empirically.</li> </ul> <p>Estimated Value \\( Q_t(a) \\):    - The agent\u2019s approximation of \\( q_*(a) \\) at time \\( t \\).    - Computed via sample-average method:</p> \\[      Q_t(a) = \\frac{\\sum_{i=1}^{t-1} R_i \\cdot \\mathbb{1}_{A_i=a}}{N_t(a)}    \\] <ul> <li>\\( N_t(a) \\): Number of times arm \\( a \\) was chosen.</li> <li>\\( \\mathbb{1}_{A_i=a} \\): Indicator (1 if \\( A_i = a \\), 0 otherwise).</li> <li>If \\( N_t(a) = 0 \\), set \\( Q_t(a) = 0 \\) or a default (e.g., optimistic value). Incremental Update:<ul> <li>To avoid storing all rewards, update \\( Q_t(a) \\) incrementally:</li> </ul> </li> </ul> \\[ Q_{t+1}(a) = Q_t(a) + \\frac{1}{N_t(a)} [R_t - Q_t(a)]  \\] <ul> <li>Derivation:</li> </ul> \\[  Q_{t+1}(a) = \\frac{\\sum_{i=1}^t R_i \\cdot \\mathbb{1}_{A_i=a}}{N_t(a)} = \\frac{(N_t(a) - 1) Q_t(a) + R_t}{N_t(a)}   \\] \\[  = Q_t(a) + \\frac{R_t - Q_t(a)}{N_t(a)}   \\] <ul> <li>Requires storing only \\( Q_t(a) \\) and \\( N_t(a) \\), making it memory-efficient.</li> </ul> <p>Action Selection:    - Use \\( Q_t(a) \\) to choose arms, e.g.:      - Greedy: \\( A_t = \\arg\\max_a Q_t(a) \\).      - \u03b5-Greedy: Mix greedy with random exploration.      - UCB: Incorporate uncertainty (see later).</p>"},{"location":"reinforcement-learning-unit%202/#example-incremental-update","title":"Example: Incremental Update","text":"<ul> <li>Setup: Arm \\( a \\) chosen 3 times, rewards: [1, 0, 1]. Initial \\( Q_1(a) = 0 \\), \\( N_1(a) = 0 \\).</li> <li>Updates:</li> <li>After \\( R_1 = 1 \\): \\( Q_2(a) = 0 + \\frac{1}{1} (1 - 0) = 1 \\), \\( N_2(a) = 1 \\).</li> <li>After \\( R_2 = 0 \\): \\( Q_3(a) = 1 + \\frac{1}{2} (0 - 1) = 0.5 \\), \\( N_3(a) = 2 \\).</li> <li>After \\( R_3 = 1 \\): \\( Q_4(a) = 0.5 + \\frac{1}{3} (1 - 0.5) \\approx 0.667 \\), \\( N_4(a) = 3 \\).</li> <li>Verification: Sample-average: \\( Q_4(a) = \\frac{1 + 0 + 1}{3} = \\frac{2}{3} \\approx 0.667 \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#general-form","title":"General Form","text":"<ul> <li>The incremental update follows:</li> </ul> \\[ \\text{NewEstimate} = \\text{OldEstimate} + \\text{StepSize} \\cdot [\\text{Target} - \\text{OldEstimate}]  \\] <ul> <li>Target: The new reward \\( R_t \\).</li> <li>StepSize: \\( \\frac{1}{N_t(a)} \\), which decreases as \\( N_t(a) \\) grows.</li> <li>Error: \\( R_t - Q_t(a) \\), reduced by moving toward the target.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#why-it-matters","title":"Why It Matters","text":"<ul> <li>Convergence: By the Law of Small Numbers, \\( Q_t(a) \\to q_*(a) \\) as \\( N_t(a) \\to \\infty \\).</li> <li>Efficiency: Incremental updates minimize computational and memory costs.</li> <li>Flexibility: Forms the basis for various algorithms (\u03b5-greedy, UCB, etc.).</li> </ul> <p>Law of Large Numbers</p> <p>As the number of samples \\( N_t(a) \\) increases, the sample average \\( Q_t(a) \\) converges to the true expected value \\( q_*(a) \\).</p> <p>Exploration Dependency</p> <p>Accurate \\( Q_t(a) \\) requires sufficient exploration; if \\( N_t(a) \\) is low, estimates are noisy, necessitating algorithms like \u03b5-greedy or UCB.</p>"},{"location":"reinforcement-learning-unit%202/#how-do-we-track-a-non-stationary-problem-in-bandit-settings","title":"How Do We Track a Non-Stationary Problem in Bandit Settings?","text":"<p>In non-stationary bandit problems, the reward distributions (\\( q_*(a) \\)) change over time, rendering traditional sample-average methods ineffective. Tracking these changes requires prioritizing recent rewards to adapt to evolving environments.</p>"},{"location":"reinforcement-learning-unit%202/#non-stationary-challenges","title":"Non-Stationary Challenges","text":"<ul> <li>Stationary Limitation: Sample-average methods assume \\( q_*(a) \\) is fixed, so \\( Q_t(a) \\) converges to a constant, ignoring shifts.</li> <li>Real-World Examples:</li> <li>A restaurant\u2019s quality changes due to a new chef.</li> <li>A slot machine\u2019s payout rate adjusts due to casino updates.</li> <li>Ad click-through rates shift with user trends.</li> <li>Need for Adaptability: Old rewards become irrelevant, and the agent must track the current \\( q_*(a) \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#solution-constant-step-size-update","title":"Solution: Constant Step-Size Update","text":"<ul> <li>Modification: Replace the decreasing step-size \\( \\frac{1}{N_t(a)} \\) with a constant step-size \\( \\alpha \\in (0, 1] \\):</li> </ul> \\[ Q_{t+1}(a) = Q_t(a) + \\alpha [R_t - Q_t(a)] \\] <ul> <li>Alternative Form:</li> </ul> \\[ Q_{t+1}(a) = (1 - \\alpha) Q_t(a) + \\alpha R_t \\] <ul> <li>Weighted Average:</li> <li>After \\( n \\) selections of arm \\( a \\), the estimate is:</li> </ul> \\[ Q_{n+1}(a) = \\alpha \\sum_{i=1}^n (1 - \\alpha)^{n-i} R_i + (1 - \\alpha)^n Q_1(a) \\] <ul> <li>Weights: \\( \\alpha (1 - \\alpha)^{n-i} \\) for reward \\( R_i \\), decaying exponentially with time since observation.</li> <li>Sum of Weights: \\( \\sum_{i=1}^n \\alpha (1 - \\alpha)^{n-i} + (1 - \\alpha)^n = 1 \\), forming a weighted average.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#example-tracking-changing-rewards","title":"Example: Tracking Changing Rewards","text":"<ul> <li>Setup: Arm \\( a \\), initial \\( Q_1(a) = 0 \\), \\( \\alpha = 0.1 \\). Rewards: [1, 1, 0, 2, 2] (assume \\( q_*(a) \\) shifts from 1 to 2 after step 3).</li> <li>Updates:</li> <li>Step 1: \\( R_1 = 1 \\), \\( Q_2(a) = 0 + 0.1 (1 - 0) = 0.1 \\).</li> <li>Step 2: \\( R_2 = 1 \\), \\( Q_3(a) = 0.1 + 0.1 (1 - 0.1) = 0.19 \\).</li> <li>Step 3: \\( R_3 = 0 \\), \\( Q_4(a) = 0.19 + 0.1 (0 - 0.19) = 0.171 \\).</li> <li>Step 4: \\( R_4 = 2 \\), \\( Q_5(a) = 0.171 + 0.1 (2 - 0.171) = 0.354 \\).</li> <li>Step 5: \\( R_5 = 2 \\), \\( Q_6(a) = 0.354 + 0.1 (2 - 0.354) = 0.499 \\).</li> <li>Analysis: \\( Q_t(a) \\) starts near 1, then gradually tracks toward 2, reflecting the shift in \\( q_*(a) \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#why-it-works","title":"Why It Works","text":"<ul> <li>Recency Bias: \\( \\alpha \\) emphasizes recent rewards, with \\( (1 - \\alpha)^{n-i} \\) reducing the influence of older rewards.</li> <li>Exponential Decay: The weight \\( \\alpha (1 - \\alpha)^{n-i} \\) decreases exponentially, ensuring adaptability.</li> <li>Tunable \\( \\alpha \\):</li> <li>High \\( \\alpha \\) (e.g., 0.5): Fast adaptation, but noisy estimates.</li> <li>Low \\( \\alpha \\) (e.g., 0.01): Smooth estimates, but slow to adapt.</li> <li>Applications: Non-stationary bandits are common in online advertising, recommendation systems, and dynamic pricing.</li> </ul> <p>Exponentially Weighted Average</p> <p>The constant \\( \\alpha \\) creates an exponentially recency-weighted average, ideal for tracking non-stationary reward distributions.</p> <p>Mnemonic: Non-Stationary</p> <p>\"ADAPT\": Always Discount Ancient rewards, Prioritize Today\u2019s.</p> <p>Balancing Act</p> <p>Choosing \\( \\alpha \\) is critical: too high causes instability; too low lags behind changes. Test multiple \\( \\alpha \\) values for optimal performance.</p>"},{"location":"reinforcement-learning-unit%202/#what-is-the-upper-confidence-bound-ucb-approach","title":"What Is the Upper Confidence Bound (UCB) Approach?","text":"<p>The Upper Confidence Bound (UCB) approach is a sophisticated method for action selection in bandit problems, selecting arms by combining their estimated rewards with an uncertainty term to prioritize those with high potential (either due to high estimates or insufficient exploration).</p>"},{"location":"reinforcement-learning-unit%202/#algorithm-details","title":"Algorithm Details","text":"<ul> <li>Action Selection:   [   A_t = \\arg\\max_a \\left[ Q_t(a) + c \\sqrt{\\frac{\\ln t}{N_t(a)}} \\right]   ]</li> <li>\\( Q_t(a) \\): Estimated action value.</li> <li>\\( c &gt; 0 \\): Exploration parameter (typically \\( c = 2 \\)) controls the trade-off between exploration and exploitation.</li> <li>\\( \\sqrt{\\frac{\\ln t}{N_t(a)}} \\): Uncertainty term, high when \\( N_t(a) \\) is small (few selections) or \\( t \\) is large (many steps).</li> <li>If \\( N_t(a) = 0 \\), assume infinite UCB (select the arm).</li> <li>Update:</li> <li>Pull arm \\( A_t \\), receive \\( R_t \\).</li> <li>Update: \\( N_{t+1}(A_t) = N_t(A_t) + 1 \\), \\( Q_{t+1}(A_t) = Q_t(A_t) + \\frac{1}{N_t(A_t)} [R_t - Q_t(A_t)] \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#intuition","title":"Intuition","text":"<ul> <li>The UCB value \\( Q_t(a) + c \\sqrt{\\frac{\\ln t}{N_t(a)}} \\) estimates an upper bound on the true \\( q_*(a) \\), assuming optimism in uncertainty.</li> <li>High \\( Q_t(a) \\): Indicates a promising arm (exploitation).</li> <li>High \\( \\sqrt{\\frac{\\ln t}{N_t(a)}} \\): Indicates an under-explored arm (exploration).</li> <li>Dynamic Balance:</li> <li>Choosing an arm increases \\( N_t(a) \\), reducing its uncertainty term.</li> <li>Not choosing an arm increases \\( t \\), raising its uncertainty term.</li> <li>Logarithmic Term: \\( \\ln t \\) ensures exploration diminishes over time but never stops.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#numerical-example_1","title":"Numerical Example","text":"<ul> <li>Setup: 3 machines at \\( t = 1000 \\), \\( c = 2 \\). Current estimates:</li> <li>\\( M_1 \\): \\( Q_t(M_1) = 0.8 \\), \\( N_t(M_1) = 250 \\).</li> <li>\\( M_2 \\): \\( Q_t(M_2) = 1.0 \\), \\( N_t(M_2) = 350 \\).</li> <li>\\( M_3 \\): \\( Q_t(M_3) = 1.2 \\), \\( N_t(M_3) = 400 \\).</li> <li>Calculate UCB:</li> <li>\\( \\ln 1000 \\approx 6.908 \\).</li> <li>\\( M_1 \\): \\( 0.8 + 2 \\sqrt{\\frac{6.908}{250}} = 0.8 + 2 \\sqrt{0.027632} \\approx 0.8 + 0.332 = 1.132 \\).</li> <li>\\( M_2 \\): \\( 1.0 + 2 \\sqrt{\\frac{6.908}{350}} \\approx 1.0 + 0.281 = 1.281 \\).</li> <li>\\( M_3 \\): \\( 1.2 + 2 \\sqrt{\\frac{6.908}{400}} \\approx 1.2 + 0.263 = 1.463 \\).</li> <li>Choice: Select \\( M_3 \\) (UCB = 1.463).</li> <li>Update: If \\( R_t = 1 \\):</li> <li>\\( N_{t+1}(M_3) = 401 \\).</li> <li>\\( Q_{t+1}(M_3) = 1.2 + \\frac{1}{401} (1 - 1.2) \\approx 1.2 - 0.0005 = 1.1995 \\).</li> </ul>"},{"location":"reinforcement-learning-unit%202/#additional-example-early-steps","title":"Additional Example: Early Steps","text":"<ul> <li>Setup: 2 arms, \\( t = 3 \\), \\( c = 2 \\), \\( Q_1(a) = 0 \\), \\( N_1(a) = 0 \\).</li> <li>Step 1: All \\( N_1(a) = 0 \\), pick \\( M_1 \\). Reward \\( R_1 = 1 \\). Update: \\( Q_2(M_1) = 1 \\), \\( N_2(M_1) = 1 \\).</li> <li>Step 2: \\( \\ln 2 \\approx 0.693 \\).</li> <li>\\( M_1 \\): \\( 1 + 2 \\sqrt{\\frac{0.693}{1}} \\approx 1 + 1.665 = 2.665 \\).</li> <li>\\( M_2 \\): \\( 0 + \\infty = \\infty \\).</li> <li>Pick \\( M_2 \\). Reward \\( R_2 = 0 \\). Update: \\( Q_3(M_2) = 0 \\), \\( N_3(M_2) = 1 \\).</li> <li>Step 3: \\( \\ln 3 \\approx 1.099 \\).</li> <li>\\( M_1 \\): \\( 1 + 2 \\sqrt{\\frac{1.099}{1}} \\approx 1 + 2.098 = 3.098 \\).</li> <li>\\( M_2 \\): \\( 0 + 2 \\sqrt{\\frac{1.099}{1}} \\approx 2.098 \\).</li> <li>Pick \\( M_1 \\).</li> </ul> <p>UCB Principle</p> <p>UCB follows optimism in the face of uncertainty, assuming untested arms could be optimal, thus encouraging targeted exploration.</p> <p>Mnemonic: UCB</p> <p>\"UNCAP\": Uncertainty Nudges Choice, Aiming for Potential.</p> <p>Stationarity Assumption</p> <p>UCB assumes stationary rewards; non-stationary settings require variants like discounted UCB or sliding-window UCB.</p>"},{"location":"reinforcement-learning-unit%202/#compare-ucb-with-greedy-which-balances-exploration-better","title":"Compare UCB with \u03b5-Greedy: Which Balances Exploration Better?","text":""},{"location":"reinforcement-learning-unit%202/#detailed-comparison","title":"Detailed Comparison","text":"Aspect \u03b5-Greedy UCB Action Selection Greedy (\\( \\arg\\max Q_t(a) \\)) with probability \\( 1 - \\epsilon \\); random with \\( \\epsilon \\) \\( \\arg\\max \\left[ Q_t(a) + c \\sqrt{\\frac{\\ln t}{N_t(a)}} \\right] \\) Exploration Mechanism Random exploration with fixed or decaying \\( \\epsilon \\) Uncertainty-driven; prioritizes arms with low \\( N_t(a) \\) or high potential Exploration Control \\( \\epsilon \\) (fixed or decaying) controls exploration frequency \\( c \\) scales uncertainty term, balancing exploration intensity Exploration Pattern Uniform random exploration, may oversample poor arms Targeted exploration, favors near-optimal or under-explored arms Convergence All arms sampled infinitely (\\( \\epsilon &gt; 0 \\)), \\( Q_t(a) \\to q_*(a) \\) All arms sampled, with suboptimal arms selected less over time Regret Linear regret (\\( O(T) \\)) with fixed \\( \\epsilon \\); sublinear with decay Logarithmic regret (\\( O(\\ln T) \\)), theoretically optimal Computational Cost Low; simple random choice and updates Moderate; requires computing \\( \\ln t \\) and \\( \\sqrt{\\frac{\\ln t}{N_t(a)}} \\) Implementation Ease Very simple, minimal tuning More complex, requires tuning \\( c \\) Suitability Stationary problems, quick prototypes Stationary problems, long-term optimization Non-Stationary Poor; needs decay or other adaptations Poor; needs variants like discounted UCB"},{"location":"reinforcement-learning-unit%202/#which-balances-exploration-better","title":"Which Balances Exploration Better?","text":"<ul> <li>UCB is superior for balancing exploration and exploitation in most stationary bandit problems because:</li> <li>Targeted Exploration: UCB selects arms based on their potential to be optimal, considering both \\( Q_t(a) \\) and uncertainty. This avoids wasting trials on clearly suboptimal arms, unlike \u03b5-greedy\u2019s random exploration.</li> <li>Theoretical Optimality: UCB achieves logarithmic regret (\\( O(\\ln T) \\)), meaning regret grows slowly, compared to \u03b5-greedy\u2019s linear regret (\\( O(T) \\)) with fixed \\( \\epsilon \\) or sublinear regret with decay.</li> <li>Dynamic Adjustment: The uncertainty term \\( \\sqrt{\\frac{\\ln t}{N_t(a)}} \\) naturally reduces exploration for well-tested arms and increases it for under-explored ones, without manual tuning.</li> <li>Empirical Evidence: On the 10-armed testbed (Sutton &amp; Barto, 2020), UCB outperformed \u03b5-greedy (\\( \\epsilon = 0.1, 0.01 \\)) in average reward (~1.4 vs. ~1.2) and optimal arm selection (~80% vs. ~60%) after 1000 steps.</li> <li>\u03b5-Greedy Strengths:</li> <li>Simplicity: Easier to implement and understand, ideal for quick prototypes or small-scale problems.</li> <li>Flexibility with Decay: Epsilon decay improves performance, though it requires careful tuning.</li> <li>Robustness: Performs adequately in noisy environments where UCB\u2019s uncertainty estimates may be less reliable.</li> <li>\u03b5-Greedy Weaknesses:</li> <li>Random exploration can repeatedly select poor arms, increasing regret.</li> <li>Fixed \\( \\epsilon \\) causes excessive exploration in later steps.</li> <li>Tuning \\( \\epsilon \\) or decay parameters is problem-specific and error-prone.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#10-armed-testbed-insights","title":"10-Armed Testbed Insights","text":"<ul> <li>Setup: 2000 random 10-armed bandit problems, \\( q_*(a) \\sim N(0, 1) \\), rewards \\( R_t \\sim N(q_*(a), 1) \\).</li> <li>Results (Sutton &amp; Barto, 2020):</li> <li>Greedy (\\( \\epsilon = 0 \\)): ~1.0 reward, ~33% optimal arm selection (gets stuck on suboptimal arms).</li> <li>\u03b5-Greedy (\\( \\epsilon = 0.1 \\)): ~1.2 reward, ~60% optimal arm selection.</li> <li>\u03b5-Greedy (\\( \\epsilon = 0.01 \\)): Slightly better early but plateaus lower than UCB.</li> <li>UCB (\\( c = 2 \\)): ~1.4 reward, ~80% optimal arm selection, excelling after initial exploration.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#when-to-choose-each","title":"When to Choose Each","text":"<ul> <li>UCB: Preferred for stationary problems with many trials, where low regret and targeted exploration are critical (e.g., ad optimization, clinical trials).</li> <li>\u03b5-Greedy: Suitable for quick implementations, noisy environments, or when computational simplicity is prioritized (e.g., educational settings, small-scale tests).</li> </ul> <p>Winner: UCB</p> <p>UCB\u2019s uncertainty-driven exploration provides better regret bounds and efficiency, making it the go-to for stationary bandit problems.</p> <p>Non-Stationary Limitation</p> <p>Both algorithms struggle with non-stationary rewards. UCB requires adaptations like discounted UCB; \u03b5-greedy needs decay or step-size adjustments.</p>"},{"location":"reinforcement-learning-unit%202/#conceptuallogical-questions","title":"Conceptual/Logical Questions","text":""},{"location":"reinforcement-learning-unit%202/#what-is-the-greedy-algorithm_1","title":"What Is the \u03b5-Greedy Algorithm?","text":"<ul> <li>Answer: The \u03b5-greedy algorithm is a bandit strategy that balances exploration and exploitation. It selects the arm with the highest estimated reward (\\( \\arg\\max Q_t(a) \\)) with probability \\( 1 - \\epsilon \\) (exploitation) and a random arm with probability \\( \\epsilon \\) (exploration). Action values are updated incrementally using sample averages. It\u2019s simple but may explore inefficiently with fixed \\( \\epsilon \\), often improved with epsilon decay.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#which-parameter-should-be-reduced-to-prevent-inefficient-exploration-why","title":"Which Parameter Should Be Reduced to Prevent Inefficient Exploration? Why?","text":"<ul> <li>Answer: The epsilon (\\( \\epsilon \\)) parameter should be reduced, typically via decay (e.g., \\( \\epsilon_t = \\epsilon_0 \\cdot \\gamma^t \\)). High \\( \\epsilon \\) causes excessive random exploration, selecting suboptimal arms even when \\( Q_t(a) \\) is reliable, increasing regret. Reducing \\( \\epsilon \\) over time shifts focus to exploitation, leveraging accurate estimates to maximize rewards.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#define-exploration-vs-exploitation","title":"Define Exploration vs. Exploitation","text":"<ul> <li>Answer:</li> <li>Exploration: Choosing arms to learn their reward distributions, improving \\( Q_t(a) \\) estimates. It risks short-term losses but enhances long-term performance by identifying the best arm. Example: Trying a new restaurant to assess its quality.</li> <li>Exploitation: Selecting the arm with the highest \\( Q_t(a) \\) to maximize immediate rewards based on current knowledge. It ensures short-term gains but may miss better arms. Example: Repeatedly visiting your favorite restaurant.</li> <li>Conflict: Exploration sacrifices immediate rewards for knowledge; exploitation prioritizes immediate rewards but risks suboptimal long-term choices.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#does-a-higher-ucb-value-indicate-exploration-or-exploitation","title":"Does a Higher UCB Value Indicate Exploration or Exploitation?","text":"<ul> <li>Answer: A higher UCB value (\\( Q_t(a) + c \\sqrt{\\frac{\\ln t}{N_t(a)}} \\)) can indicate exploration if driven by a large uncertainty term (high \\( \\frac{\\ln t}{N_t(a)} \\)) for under-explored arms, or exploitation if driven by a high \\( Q_t(a) \\) for well-tested arms. UCB dynamically balances both, favoring arms with high potential to be optimal.</li> </ul>"},{"location":"reinforcement-learning-unit%202/#revision-checklist","title":"Revision Checklist","text":"<ul> <li>[ ] Explain the k-armed bandit problem, including its definition, objective, regret, and a detailed restaurant example.</li> <li>[ ] Describe the \u03b5-greedy algorithm step-by-step and solve a 4-arm numerical example with random numbers.</li> <li>[ ] Define epsilon decay, explain its necessity, and provide a numerical example with exponential decay.</li> <li>[ ] Detail action-value methods, including expected vs. estimated values, incremental updates, and a sample calculation.</li> <li>[ ] Explain tracking non-stationary problems using constant step-size updates, with a numerical example and derivation.</li> <li>[ ] Describe the UCB approach, its formula, intuition, and solve a 3-arm numerical example at \\( t = 1000 \\).</li> <li>[ ] Compare UCB and \u03b5-greedy across action selection, regret, and exploration efficiency, citing testbed results.</li> <li>[ ] Answer conceptual questions on \u03b5-greedy, parameter tuning, exploration vs. exploitation, and UCB values.</li> <li>[ ] Understand the 10-armed testbed and its implications for algorithm performance.</li> </ul>"},{"location":"reinforcement-learning-unit%207/","title":"Policy Approximation in Reinforcement Learning","text":"<p>Policy approximation is a critical technique in reinforcement learning (RL) for handling large or continuous state and action spaces. It involves representing the policy function\u2014mapping states to actions\u2014using parameterized models like neural networks, rather than storing explicit policies for every state. This set of notes covers policy approximation, the Naive REINFORCE algorithm, REINFORCE with baselines, Actor-Critic methods, RL methods combining policy and value learning, and the essential elements of Naive RL, with detailed explanations, examples, and comparisons.</p>"},{"location":"reinforcement-learning-unit%207/#what-is-policy-approximation","title":"What Is Policy Approximation?","text":"<p>Policy approximation refers to representing an RL agent's policy using a parameterized function, such as a neural network or linear model, instead of explicitly defining actions for every possible state. This is essential for scalability and generalization in complex environments with large or continuous state spaces.</p>"},{"location":"reinforcement-learning-unit%207/#background-what-is-a-policy","title":"Background: What Is a Policy?","text":"<ul> <li>A policy \\( \\pi \\) defines the agent\u2019s behavior, mapping states to actions:</li> <li>Deterministic Policy: \\( \\pi(s) = a \\), where \\( a \\) is the action taken in state \\( s \\).</li> <li>Stochastic Policy: \\( \\pi(a|s) = P(a|s) \\), the probability of taking action \\( a \\) in state \\( s \\).</li> <li>Objective: Find a policy \\( \\pi \\) that maximizes the expected cumulative reward:</li> </ul> \\[ J(\\pi) = E_{\\pi} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right] \\] <p>where \\( \\gamma \\in [0, 1) \\) is the discount factor, and \\( r_t \\) is the reward at time \\( t \\).</p>"},{"location":"reinforcement-learning-unit%207/#why-approximate-a-policy","title":"Why Approximate a Policy?","text":"<p>Scalability:</p> <ul> <li>In real-world problems (e.g., robotics, games, autonomous driving), state spaces are vast or continuous (e.g., \\( 10^{10} \\) states or \\( \\mathbb{R}^n \\)).</li> <li>Storing a tabular policy (one entry per state) is infeasible due to memory and computation constraints.</li> </ul> <p>Generalization:</p> <ul> <li>A parameterized policy \\( \\pi_\\theta(s) \\) generalizes to unseen states by learning patterns in the state space.</li> <li>Example: In a driving simulator, a neural network policy can handle new road configurations based on learned features.</li> </ul> <p>Continuous Spaces:    - Approximation enables policies for continuous state or action spaces, where tabular methods fail.</p> <p>Efficiency:    - Parameterized models (e.g., neural networks with thousands of parameters) are compact compared to millions of state-action pairs.</p>"},{"location":"reinforcement-learning-unit%207/#types-of-policy-approximations","title":"Types of Policy Approximations","text":"<p>Parametric Approximation:    - Represent the policy as a function \\( \\pi_\\theta(s) \\) or \\( \\pi_\\theta(a|s) \\) with parameters \\( \\theta \\).    - Examples:      - Linear Model: \\( \\pi_\\theta(s) = \\theta^T \\phi(s) \\), where \\( \\phi(s) \\) is a feature vector (e.g., state coordinates).      - Neural Network (Deep RL): \\( \\pi_\\theta(s) = \\text{NN}_\\theta(s) \\), outputting actions or action probabilities.      - Radial Basis Functions (RBF): Use localized basis functions for smooth approximations.    - The policy is updated by optimizing \\( \\theta \\) to maximize expected rewards.</p> <p>Non-Parametric Approximation:    - Use methods like kernel-based models or decision trees, less common in deep RL.</p>"},{"location":"reinforcement-learning-unit%207/#approaches-to-rl-with-policy-approximation","title":"Approaches to RL with Policy Approximation","text":"Approach Learns Uses Approximation? Example Algorithms Value-Based Optimal value function \\( V^*(s) \\) or \\( Q^*(s,a) \\) Yes (for \\( V \\) or \\( Q \\)) Q-Learning, DQN Policy-Based Optimal policy Yes (for \\( \\pi \\)) REINFORCE, TRPO, PPO Actor-Critic Both policy and value function Yes (for both) A2C, A3C, DDPG, SAC"},{"location":"reinforcement-learning-unit%207/#how-policy-approximation-works","title":"How Policy Approximation Works","text":"<ul> <li>Goal: Optimize parameters \\( \\theta \\) to maximize the expected return:</li> </ul> \\[ J(\\theta) = E_{\\pi_\\theta} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right] \\] <ul> <li>Methods:</li> <li>Policy Gradient Methods:<ul> <li>Use gradient ascent to update \\( \\theta \\):</li> </ul> </li> </ul> \\[ \\theta \\leftarrow \\theta + \\alpha \\nabla_\\theta J(\\theta) \\] <pre><code> - Algorithms: REINFORCE, PPO, TRPO.\n</code></pre> <ol> <li>Imitation Learning/Behavior Cloning:<ul> <li>Train \\( \\pi_\\theta(a|s) \\) to mimic expert demonstrations using supervised learning.</li> <li>Example: Train a self-driving car policy using human driver data.</li> </ul> </li> <li>Value-Based Policy Derivation:<ul> <li>Approximate \\( Q_\\theta(s,a) \\), then derive \\( \\pi(s) = \\arg\\max_a Q_\\theta(s,a) \\).</li> <li>Example: DQN uses a neural network for \\( Q \\).</li> </ul> </li> </ol>"},{"location":"reinforcement-learning-unit%207/#policy-approximation-techniques","title":"Policy Approximation Techniques","text":"Technique Description Suitable For Linear Models Simple, low-capacity, \\( \\pi_\\theta = \\theta^T \\phi(s) \\) Simple problems, low-dimensional states Neural Networks High expressiveness, handles complex patterns High-dimensional, continuous spaces Radial Basis Functions Local generalization, smooth approximations Medium-complexity problems Decision Trees/Boosting Structured, interpretable approximations Discrete or structured actions"},{"location":"reinforcement-learning-unit%207/#trade-offs","title":"Trade-Offs","text":"<ul> <li>Advantages:</li> <li>Generalizes to unseen states, reducing memory needs.</li> <li>Handles continuous state/action spaces.</li> <li>Compact representation (e.g., \\( 10^5 \\) parameters vs. \\( 10^{10} \\) states).</li> <li>Challenges:</li> <li>Overfitting/Underfitting: Poor generalization if the model is too complex or simple.</li> <li>Training Stability: Gradient-based optimization can be unstable.</li> <li>Tuning: Requires careful selection of architecture, learning rates, and regularization.</li> </ul> <p>Key Idea</p> <p>Policy approximation replaces tabular policies with parameterized functions to scale RL to large, continuous, or complex environments.</p> <p>Mnemonic: Policy Approximation</p> <p>\"APPROX\": Adaptable, Parameterized Policy Representation Optimizes Xpected rewards.</p> <p>Challenge</p> <p>Poorly designed approximators (e.g., insufficient capacity or noisy gradients) can lead to suboptimal policies or instability.</p>"},{"location":"reinforcement-learning-unit%207/#naive-reinforce-algorithm","title":"Naive REINFORCE Algorithm","text":"<p>The Naive REINFORCE algorithm is a policy gradient method that directly optimizes a stochastic policy \\( \\pi_\\theta(a|s) \\) by maximizing the expected return using gradient ascent. It is a foundational algorithm in policy-based RL.</p>"},{"location":"reinforcement-learning-unit%207/#core-idea","title":"Core Idea","text":"<ul> <li>Objective: Maximize \\( J(\\theta) = E_{\\pi_\\theta} \\left[ \\sum_{t=0}^\\infty \\gamma^t r_t \\right] \\).</li> <li>Approach: Sample trajectories under \\( \\pi_\\theta \\), compute returns, and update \\( \\theta \\) to increase the likelihood of high-reward actions.</li> <li>Policy Gradient Theorem: The gradient of the objective is:</li> </ul> \\[ \\nabla_\\theta J(\\theta) = E_{\\pi_\\theta} \\left[ \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t \\right] \\] <p>where \\( G_t = \\sum_{k=t}^T \\gamma^{k-t} r_k \\) is the return from time \\( t \\).</p>"},{"location":"reinforcement-learning-unit%207/#algorithm","title":"Algorithm","text":"<p>Initialize: Policy parameters \\( \\theta \\), learning rate \\( \\alpha \\).</p> <p>For each episode:    - Generate a trajectory: \\( s_0, a_0, r_1, s_1, a_1, \\dots, s_T \\), sampling \\( a_t \\sim \\pi_\\theta(a_t|s_t) \\).    - Compute returns: \\( G_t = \\sum_{k=t}^T \\gamma^{k-t} r_k \\) for each \\( t \\).    - Compute gradient: \\( \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t \\).    - Update: \\( \\theta \\leftarrow \\theta + \\alpha \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t \\).</p>"},{"location":"reinforcement-learning-unit%207/#numerical-example","title":"Numerical Example","text":"<ul> <li>Setup: 2 states (\\( s_1, s_2 \\)), 2 actions (\\( a_1, a_2 \\)), policy \\( \\pi_\\theta(a|s) = \\text{softmax}(\\theta^T \\phi(s,a)) \\), \\( \\gamma = 0.9 \\), \\( \\alpha = 0.1 \\).</li> <li>Trajectory: \\( s_1, a_1, r_1=1, s_2, a_2, r_2=2, s_1 \\).</li> <li>Returns:</li> <li>\\( G_1 = r_1 + \\gamma r_2 = 1 + 0.9 \\cdot 2 = 2.8 \\).</li> <li>\\( G_2 = r_2 = 2 \\).</li> <li>Gradient: Assume \\( \\nabla_\\theta \\log \\pi_\\theta(a_1|s_1) = [1, 0] \\), \\( \\nabla_\\theta \\log \\pi_\\theta(a_2|s_2) = [0, 1] \\).</li> <li>Total gradient: \\( [1, 0] \\cdot 2.8 + [0, 1] \\cdot 2 = [2.8, 2] \\).</li> <li>Update: \\( \\theta = \\theta + 0.1 \\cdot [2.8, 2] = \\theta + [0.28, 0.2] \\).</li> </ul>"},{"location":"reinforcement-learning-unit%207/#characteristics","title":"Characteristics","text":"<ul> <li>Model-Free: No environment model needed.</li> <li>On-Policy: Learns from trajectories generated by \\( \\pi_\\theta \\).</li> <li>Monte Carlo: Uses full episode returns \\( G_t \\).</li> <li>High Variance: \\( G_t \\) varies across episodes, making updates noisy.</li> <li>No Bias: Gradient is unbiased but slow to converge.</li> </ul>"},{"location":"reinforcement-learning-unit%207/#process-flow","title":"Process Flow","text":"<pre><code>\ngraph TD\n    A[Agent] --&gt;|Sample action from policy| B[Environment]\n    B --&gt;|Return next state and reward| A\n    A --&gt;|Compute return Gt| C[Store Trajectory]\n    C --&gt;|End Episode| D[Compute Gradient]\n    D --&gt;|Update policy parameters| A\n</code></pre> <p>Policy Gradient Theorem</p> <p>The gradient \\( \\nabla_\\theta J(\\theta) \\propto E[\\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t] \\) weights actions by their returns, increasing the probability of high-reward actions.</p> <p>Mnemonic: Naive REINFORCE</p> <p>\"FORCE\": Follow Optimal Returns, Compute Expected gradients.</p> <p>High Variance</p> <p>The reliance on full returns \\( G_t \\) causes noisy gradients, slowing convergence, especially in long episodes.</p>"},{"location":"reinforcement-learning-unit%207/#reinforce-with-baselines","title":"REINFORCE with Baselines","text":"<p>REINFORCE with Baselines improves the Naive REINFORCE algorithm by subtracting a baseline from the return to reduce gradient variance, stabilizing learning without introducing bias.</p>"},{"location":"reinforcement-learning-unit%207/#core-idea_1","title":"Core Idea","text":"<ul> <li>Problem: In Naive REINFORCE, \\( G_t \\) varies widely, leading to high-variance gradients.</li> <li>Solution: Subtract a state-dependent baseline \\( b(s_t) \\) (e.g., the value function \\( V(s_t) \\)) from \\( G_t \\):</li> </ul> \\[ \\nabla_\\theta J(\\theta) = E_{\\pi_\\theta} \\left[ \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot (G_t - b(s_t)) \\right] \\] <ul> <li>Effect: Centers the advantage \\( G_t - b(s_t) \\), reducing variance while keeping the gradient unbiased.</li> </ul>"},{"location":"reinforcement-learning-unit%207/#update-rule","title":"Update Rule","text":"\\[ \\theta \\leftarrow \\theta + \\alpha \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot (G_t - b(s_t)) \\] <ul> <li>Common Baseline: \\( b(s_t) = V(s_t) \\), the expected return from state \\( s_t \\).</li> <li>Learning \\( V(s_t) \\): Use a separate parameterized model \\( V_w(s) \\), updated via regression:</li> </ul> \\[ w \\leftarrow w - \\beta \\cdot \\nabla_w (V_w(s_t) - G_t)^2 \\]"},{"location":"reinforcement-learning-unit%207/#numerical-example_1","title":"Numerical Example","text":"<ul> <li>Setup: Same as Naive REINFORCE example, with baseline \\( V_w(s_1) = 2 \\), \\( V_w(s_2) = 1 \\).</li> <li>Trajectory: \\( s_1, a_1, r_1=1, s_2, a_2, r_2=2 \\).</li> <li>Returns: \\( G_1 = 2.8 \\), \\( G_2 = 2 \\).</li> <li>Advantages:</li> <li>\\( t=1 \\): \\( G_1 - V_w(s_1) = 2.8 - 2 = 0.8 \\).</li> <li>\\( t=2 \\): \\( G_2 - V_w(s_2) = 2 - 1 = 1 \\).</li> <li>Gradient: \\( [1, 0] \\cdot 0.8 + [0, 1] \\cdot 1 = [0.8, 1] \\).</li> <li>Update: \\( \\theta = \\theta + 0.1 \\cdot [0.8, 1] = \\theta + [0.08, 0.1] \\).</li> <li>Critic Update: For \\( s_1 \\), minimize \\( (V_w(s_1) - 2.8)^2 \\), adjust \\( w \\).</li> </ul>"},{"location":"reinforcement-learning-unit%207/#benefits","title":"Benefits","text":"<ul> <li>Lower Variance: \\( G_t - b(s_t) \\) has smaller magnitude than \\( G_t \\), reducing gradient fluctuations.</li> <li>Unbiased: The baseline does not affect the expected gradient.</li> <li>Faster Convergence: Stabilizes learning, especially in noisy environments.</li> </ul> <p>Why Baseline Works</p> <p>The baseline \\( b(s_t) \\) centers the advantage, reducing the magnitude of gradient updates without altering their direction.</p> <p>Mnemonic: REINFORCE with Baseline</p> <p>\"BASE\": Balance Advantage, Stabilize Expectations.</p> <p>Baseline Choice</p> <p>An inaccurate baseline (e.g., poorly trained \\( V_w(s) \\)) can increase variance or slow learning.</p>"},{"location":"reinforcement-learning-unit%207/#reinforce-with-baselines-actor-critic-methods","title":"REINFORCE with Baselines + Actor-Critic Methods","text":"<p>Actor-Critic methods combine policy-based (actor) and value-based (critic) learning, using a learned value function as a baseline to reduce variance and enable online updates. They extend REINFORCE with baselines by integrating temporal-difference (TD) learning.</p>"},{"location":"reinforcement-learning-unit%207/#core-idea_2","title":"Core Idea","text":"<ul> <li>Actor: A policy \\( \\pi_\\theta(a|s) \\) that selects actions.</li> <li>Critic: A value function \\( V_w(s) \\) or \\( Q_w(s,a) \\) that estimates expected returns, serving as a baseline.</li> <li>Interaction: The critic evaluates the actor\u2019s actions, guiding policy updates with lower-variance advantages.</li> </ul>"},{"location":"reinforcement-learning-unit%207/#update-rules","title":"Update Rules","text":"<ol> <li> <p>Actor Update (Policy Optimization): [ \\theta \\leftarrow \\theta + \\alpha \\cdot \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot (G_t - V_w(s_t)) ]</p> </li> <li> <p>Or, using TD error for online updates:</p> </li> </ol> \\[ \\theta \\leftarrow \\theta + \\alpha \\cdot \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot \\delta_t \\] <p>where \\( \\delta_t = r_t + \\gamma V_w(s_{t+1}) - V_w(s_t) \\) is the TD error.</p> <ol> <li>Critic Update (Value Learning):</li> </ol> \\[ w \\leftarrow w - \\beta \\cdot \\nabla_w (V_w(s_t) - (r_t + \\gamma V_w(s_{t+1})))^2 \\] <ul> <li>Minimizes the TD error to improve \\( V_w(s) \\).</li> </ul>"},{"location":"reinforcement-learning-unit%207/#numerical-example_2","title":"Numerical Example","text":"<ul> <li>Setup: Same trajectory: \\( s_1, a_1, r_1=1, s_2, a_2, r_2=2 \\). \\( \\gamma = 0.9 \\), \\( \\alpha = 0.1 \\), \\( \\beta = 0.05 \\).</li> <li>Critic: \\( V_w(s_1) = 2 \\), \\( V_w(s_2) = 1 \\), \\( V_w(s_3) = 0 \\).</li> <li>Step 1:</li> <li>TD error: \\( \\delta_1 = r_1 + \\gamma V_w(s_2) - V_w(s_1) = 1 + 0.9 \\cdot 1 - 2 = 0.9 - 2 = -1.1 \\).</li> <li>Actor: \\( \\nabla_\\theta \\log \\pi_\\theta(a_1|s_1) = [1, 0] \\), update: \\( \\theta + 0.1 \\cdot [1, 0] \\cdot (-1.1) = \\theta + [-0.11, 0] \\).</li> <li>Critic: Update \\( V_w(s_1) \\) to minimize \\( (V_w(s_1) - (r_1 + \\gamma V_w(s_2)))^2 \\).</li> <li>Step 2:</li> <li>TD error: \\( \\delta_2 = r_2 + \\gamma V_w(s_3) - V_w(s_2) = 2 + 0.9 \\cdot 0 - 1 = 1 \\).</li> <li>Actor: \\( \\nabla_\\theta \\log \\pi_\\theta(a_2|s_2) = [0, 1] \\), update: \\( \\theta + 0.1 \\cdot [0, 1] \\cdot 1 = \\theta + [0, 0.1] \\).</li> </ul>"},{"location":"reinforcement-learning-unit%207/#benefits_1","title":"Benefits","text":"<ul> <li>Online Learning: TD-based updates allow learning within an episode, unlike Monte Carlo.</li> <li>Lower Variance: TD error or value-based baseline reduces noise compared to raw returns.</li> <li>Flexibility: Supports both discrete and continuous action spaces (e.g., DDPG for continuous control).</li> </ul>"},{"location":"reinforcement-learning-unit%207/#process-flow_1","title":"Process Flow","text":"<pre><code>graph TD\n    A[Actor] --&gt;|Select action a_t| B[Environment]\n    B --&gt;|Return s_t+1 and r_t+1| A\n    B --&gt;|Send s_t, r_t, s_t+1| C[Critic]\n    C --&gt;|Compute delta_t| A\n    A --&gt;|Update theta| A\n    C --&gt;|Update w| C</code></pre> <p>Actor-Critic Advantage</p> <p>The critic provides a dynamic baseline, enabling faster and more stable learning than REINFORCE.</p> <p>Mnemonic: Actor-Critic</p> <p>\"ACT\": Actor Chooses, Teacher (Critic) evaluates.</p> <p>Complexity</p> <p>Training two models (actor and critic) requires careful tuning of learning rates and network architectures.</p>"},{"location":"reinforcement-learning-unit%207/#which-rl-methods-combine-policy-and-value-learning","title":"Which RL Methods Combine Policy and Value Learning?","text":"<p>Actor-Critic methods are the primary RL approaches that combine policy optimization (learning \\( \\pi_\\theta(a|s) \\)) and value estimation (learning \\( V_w(s) \\) or \\( Q_w(s,a) \\)). Examples include:</p> <ul> <li>A2C (Advantage Actor-Critic): Uses advantage function \\( A(s,a) = Q(s,a) - V(s) \\).</li> <li>A3C (Asynchronous A2C): Parallelizes learning for efficiency.</li> <li>PPO (Proximal Policy Optimization): Stabilizes policy updates with clipped objectives.</li> <li>DDPG (Deep Deterministic Policy Gradient): Handles continuous actions.</li> <li>SAC (Soft Actor-Critic): Incorporates entropy for exploration.</li> </ul>"},{"location":"reinforcement-learning-unit%207/#why-combine-both","title":"Why Combine Both?","text":"<ul> <li>Policy Learning: Directly optimizes actions, suitable for continuous or complex spaces.</li> <li>Value Learning: Provides baselines or TD errors, reducing variance and enabling online updates.</li> <li>Synergy: The critic guides the actor, improving sample efficiency and stability.</li> </ul> <p>Key Feature</p> <p>Actor-Critic methods leverage the strengths of policy-based (direct optimization) and value-based (stable estimation) approaches.</p>"},{"location":"reinforcement-learning-unit%207/#essential-elements-of-naive-reinforcement-learning","title":"Essential Elements of Naive Reinforcement Learning","text":"<p>Naive RL, exemplified by the Naive REINFORCE algorithm, is characterized by the following elements:</p> <ol> <li>Stochastic Policy \\( \\pi_\\theta(a|s) \\):</li> <li>Outputs probabilities over actions, enabling exploration.</li> <li>Parameterized (e.g., neural network) for approximation.</li> <li>Episode-Based Learning (Monte Carlo):</li> <li>Collects full trajectories before updating.</li> <li>Uses complete returns \\( G_t \\), not TD estimates.</li> <li>Return Estimation:</li> <li>Computes \\( G_t = \\sum_{k=t}^T \\gamma^{k-t} r_k \\) for each timestep.</li> <li>Measures the quality of actions taken.</li> <li>Gradient Ascent:</li> <li>Updates \\( \\theta \\) to increase \\( J(\\theta) \\) using:</li> </ol> \\[ \\theta \\leftarrow \\theta + \\alpha \\sum_{t=0}^T \\nabla_\\theta \\log \\pi_\\theta(a_t|s_t) \\cdot G_t \\] <ol> <li>No Baselines or Critics:</li> <li>Relies on raw returns, leading to high variance.</li> <li>No separate value function to stabilize learning.</li> </ol>"},{"location":"reinforcement-learning-unit%207/#limitations","title":"Limitations","text":"<ul> <li>High Variance: \\( G_t \\) fluctuates, slowing convergence.</li> <li>Sample Inefficiency: Requires full episodes, unsuitable for online learning.</li> <li>Scalability Issues: Struggles with long horizons or complex environments.</li> </ul> <p>Naive RL Simplicity</p> <p>Naive RL is a pure policy-based approach, ideal for understanding policy gradients but impractical for large-scale problems.</p>"},{"location":"reinforcement-learning-unit%207/#comparison-table","title":"Comparison Table","text":"Method Learns Policy? Learns Value? Variance Bias Stability Online Learning? Naive REINFORCE \u2705 Yes \u274c No \ud83d\udd3a High \u274c No \u274c Low \u274c No REINFORCE + Baseline \u2705 Yes \u2705 Yes (Baseline) \ud83d\udd3b Medium \u274c No \u2705 Medium \u274c No Actor-Critic \u2705 Yes \u2705 Yes \ud83d\udd3b Low \ud83d\udd3a Some \u2705 High \u2705 Yes"},{"location":"reinforcement-learning-unit%207/#revision-checklist","title":"Revision Checklist","text":"<ul> <li>[ ] Explain policy approximation, its necessity, types (parametric, value-based, policy-based), and trade-offs.</li> <li>[ ] Describe the Naive REINFORCE algorithm, including the policy gradient theorem, update rule, and a numerical example.</li> <li>[ ] Detail REINFORCE with baselines, how it reduces variance, and provide a numerical example.</li> <li>[ ] Explain Actor-Critic methods, their actor and critic components, TD-based updates, and a numerical example.</li> <li>[ ] Identify RL methods combining policy and value learning (e.g., A2C, PPO, DDPG, SAC).</li> <li>[ ] List the essential elements of Naive RL and their limitations.</li> <li>[ ] Compare Naive REINFORCE, REINFORCE with baselines, and Actor-Critic in terms of variance, bias, and stability.</li> <li>[ ] Understand the process flows for REINFORCE and Actor-Critic using Mermaid diagrams.</li> <li>[ ] Memorize mnemonics: APPROX, FORCE, BASE, ACT.</li> </ul>"},{"location":"rpa-app/","title":"Rpa app","text":"Power automate desktop Power Apps"},{"location":"rpa-app/#power-apps","title":"Power Apps","text":""},{"location":"rpa-app/#login-functionality-with-validation","title":"Login Functionality with Validation","text":"<p>Create an app that demonstrates the Login Functionality with validation in the power app.</p> <p>Onselect-property</p> <pre><code>If(\n</code></pre> <p>pass.Text = \"122345\", Navigate( 'Welcome', ScreenTransition.None ), Notify( \"Invalid Password!!! Please Enter a Valid Password\", NotificationType.Error ) ); Reset(user); Reset(pass);</p>"},{"location":"rpa-app/#login-credentials-with-sharepoint-list","title":"Login Credentials with SharePoint List","text":"<p>Create a list with login credentials like username and password and connect to Canvas App.</p> <p>Login-validation-logic</p> <p>If( IsBlank(TextInput1.Text) || IsBlank(TextInput2.Text), Notify(\"Username and Password cannot be blank\", NotificationType.Warning),</p> <p>!IsBlank(LookUp(CreditList, UserName = TextInput1.Text &amp;&amp; Password = TextInput2.Text).Title),  Navigate(Screen2), </p> <p>Notify(\"Invalid Username or Password\", NotificationType.Error); UpdateContext({ShowForgetMessage: true}) )</p>"},{"location":"rpa-app/#cascading-list-with-sharepoint","title":"Cascading List with SharePoint","text":"<p>Create a list on SharePoint with fields Country, City and demonstrate cascading list using canvas app. Add personalization at the bottom of the left corner.</p> <p>Dropdown-list-1</p> <p>Distinct (C114_Country_City, Country)</p> <p>Dropdown-list-2</p> <p>Filter(C114_Country_City, Country = Dropdown1.SelectedText.Value)</p>"},{"location":"rpa-app/#search-and-filter-functionality-in-power-app","title":"Search and Filter Functionality in Power App","text":"<p>Create an app that demonstrates the Search functionality in a Power app and creates a list, as mentioned in Snap.</p> <p>Search-formula</p> <p>Search(Table1, SearchText.Text, 'Product','Country')</p> <p>Filter-formula-gallery</p> <p>Filter(Table1, If(Dropdown1.SelectedText.Value=\"All\", true, Product = Dropdown1.SelectedText.Value))</p> <p>Filter-formula-dropdown-items</p> <p>[\"All\", \"Pen\", \"Pencil\", \"Mouse\",\"Pad\"]</p>"},{"location":"rpa-app/#form-validation-and-save","title":"Form Validation and Save","text":"<p>Perform validation on the form. Employee ID and Age must be 5 and 3 digits respectively. Add a 'Save' button. Clicking on this button will save the list data.</p> <p>5-digit-logic</p> <p>If(IsMatch(DataCardValue1.Text,Match.Digit &amp; Match.Digit &amp; Match.Digit &amp; Match.Digit &amp; Match.Digit),Parent.BorderColor, Color.Red)</p> <p>Is-blank-logic</p> <p>If(IsBlank(DataCardValue1.Text), true, false)</p>"},{"location":"rpa-app/#global-variables-in-canvas-app","title":"Global Variables in Canvas App","text":"<p>Create a Canvas app that demonstrates how to use global variables.</p> <p>Global-variable</p> <p>Set(Fname, TextInput1_1.Text); Set(Lname, TextInput2_1.Text)</p> <p>Screen-2</p> <p>Concatenate(Fname,\" \",Lname)</p>"},{"location":"rpa-app/#collection-variables-in-canvas-app","title":"Collection Variables in Canvas App","text":"<p>Create a Canvas app that demonstrates how to use collection variables.</p> <p>Collection</p> <p>Collect(mycollection,{Product:TextInput1.Text,Price: TextInput2.Text})</p> <p>Reset</p> <p>Clear(mycollection)</p>"},{"location":"rpa-app/#screen-navigation-in-canvas-app","title":"Screen Navigation in Canvas App","text":"<p>Create a Canvas app that demonstrates how to navigate from one screen to another.</p> <p>Screen-1</p> <p>Navigate(DetailScreen,ScreenTransition.Cover)</p> <p>Screen-2</p> <p>Navigate(HomeScreen,ScreenTransition.Cover)</p>"},{"location":"rpa-app/#patch-function","title":"Patch Function","text":"<p>Patch Function</p> <p>Create-new-record</p> <p>Patch(EmployeeList, Defaults(EmployeeList), {Name: \"Rishikesh\", Age: 25})</p> <p>Patch-update</p> <p>Patch(EmployeeList, LookUp(EmployeeList, Name = \"Rishikesh\"), {Age: 26})</p>"},{"location":"rpa-m2-formula/","title":"RPA Formulae","text":""},{"location":"rpa-m2-formula/#1-cascading-dropdown","title":"1. Cascading Dropdown","text":"<p>Two Dropdown applications, set the Items field as follows:</p>"},{"location":"rpa-m2-formula/#dropdown-1-dd1","title":"Dropdown 1 (DD1)","text":"<pre><code>Distinct(Country_City, Country)\n</code></pre>"},{"location":"rpa-m2-formula/#dropdown-2-dd2","title":"Dropdown 2 (DD2)","text":"<pre><code>Filter(Country_City, Country = Dropdown1.SelectedText.Value)\n</code></pre>"},{"location":"rpa-m2-formula/#2-form-validation","title":"2. Form Validation","text":""},{"location":"rpa-m2-formula/#digit-validation-for-employee-id","title":"Digit Validation for Employee ID","text":"<ul> <li>Border turns red if there aren\u2019t 5 digits </li> <li>Set in the BorderColor field: <pre><code>If(\n    IsMatch(DataCardValue1.Text, Match.Digit &amp; Match.Digit &amp; Match.Digit &amp; Match.Digit &amp; Match.Digit),\n    Parent.BorderColor,\n    Color.Red\n)\n</code></pre></li> </ul>"},{"location":"rpa-m2-formula/#remove-required-field-if-textbox-is-filled","title":"Remove * (Required Field) if Textbox is Filled","text":"<ul> <li>Set in the Required Field: <pre><code>If(IsBlank(DataCardValue1.Text), true, false)\n</code></pre></li> </ul>"},{"location":"rpa-m2-formula/#3-crud-operations","title":"3. CRUD Operations","text":""},{"location":"rpa-m2-formula/#setup","title":"Setup","text":"<ol> <li>Add a Data Source</li> <li>Insert Form &amp; Gallery </li> <li>Connect to Data Source </li> <li>Set Form Mode to <code>New</code></li> </ol>"},{"location":"rpa-m2-formula/#view-data","title":"View Data","text":"<ul> <li>OnSelect (Gallery) <pre><code>ViewForm(Form1)\n</code></pre></li> <li>Items Property (Form) <pre><code>Gallery1.Selected\n</code></pre></li> </ul>"},{"location":"rpa-m2-formula/#add-new-entry","title":"Add New Entry","text":"<pre><code>NewForm(Form1)\n</code></pre>"},{"location":"rpa-m2-formula/#edit-existing-entry","title":"Edit Existing Entry","text":"<pre><code>EditForm(Form1)\n</code></pre>"},{"location":"rpa-m2-formula/#submit-form-with-notification","title":"Submit Form with Notification","text":"<pre><code>SubmitForm(Form1);\nNotify(\"Entry Added\", NotificationType.Information)\n</code></pre>"},{"location":"rpa-m2-formula/#delete-entry","title":"Delete Entry","text":"<ul> <li>OnSelect Property of Delete Button: <pre><code>Remove(CRUD_Table, ThisItem)\n</code></pre></li> </ul>"},{"location":"rpa-m2-formula/#4-personalization","title":"4. Personalization","text":"<ul> <li>User Profile Details: <pre><code>User().Image   // Inserted Image\nUser().FullName   // Inserted Text Label\nUser().Email   // Inserted Text Label\n</code></pre></li> </ul>"},{"location":"rpa-m2-formula/#5-variables","title":"5. Variables","text":""},{"location":"rpa-m2-formula/#local-variables","title":"Local Variables","text":"<ol> <li>Set TextInput1 and TextInput2</li> <li>OnSelect (Button) <pre><code>UpdateContext({N1:TextInput1.Text, N2:TextInput2.Text})\n</code></pre></li> <li>Set in Label (Addition) <pre><code>N1 + N2\n</code></pre></li> </ol>"},{"location":"rpa-m2-formula/#global-variables","title":"Global Variables","text":"<ol> <li>OnSelect (Button) <pre><code>Set(Fname, TextInput1_1.Text);\nSet(Lname, TextInput2_1.Text)\n</code></pre></li> <li>Set in Label <pre><code>Fname &amp; \" \" &amp; Lname\n</code></pre> OR <pre><code>Concatenate(Fname, \" \", Lname)\n</code></pre></li> </ol>"},{"location":"rpa-m2-formula/#collections","title":"Collections","text":"<ol> <li>Add Item to Collection <pre><code>Collect(mycollection, {Product:TextInput1.Text, Price: TextInput2.Text})\n</code></pre></li> <li>Reset Collection <pre><code>Clear(mycollection)\n</code></pre></li> </ol>"},{"location":"rpa-m2-formula/#6-navigation","title":"6. Navigation","text":"<p>Create Home Screen and Detail Screen, then add buttons for navigation.</p>"},{"location":"rpa-m2-formula/#home-button-onselect","title":"Home Button (OnSelect)","text":"<pre><code>Navigate(DetailScreen, ScreenTransition.Cover)\n</code></pre>"},{"location":"rpa-m2-formula/#detail-button-onselect","title":"Detail Button (OnSelect)","text":"<pre><code>Navigate(HomeScreen, ScreenTransition.Cover)\n</code></pre>"},{"location":"rpa-m2-formula/#7-login-system","title":"7. Login System","text":""},{"location":"rpa-m2-formula/#static-login","title":"Static Login","text":""},{"location":"rpa-m2-formula/#inputs","title":"Inputs:","text":"<ul> <li>Username (<code>txt_username</code>)</li> <li>Password (<code>txt_password</code>)  </li> </ul> <p>Set Password Mode: <pre><code>TextMode.Password\n</code></pre></p> <p>OnSelect Property (Submit Button) <pre><code>If(\n    txt_Password.Text = \"pass\",\n    Navigate('Welcome Screen', ScreenTransition.None),\n    Notify(\"Invalid Password!!! Please Enter a Valid Password\", NotificationType.Error)\n);\nReset(txt_Username);\nReset(txt_Password);\n</code></pre></p>"},{"location":"rpa-m2-formula/#login-using-sharepoint-list","title":"Login Using SharePoint List","text":"<ol> <li>Create SharePoint Credentials List (<code>credentials_list</code>)</li> <li>OnStart Property (App Object) <pre><code>ClearCollect(\n    colUserCredentials,\n    'credentials_list'\n)\n</code></pre></li> <li>OnSelect Property (Login Button) <pre><code>If(\n    CountRows(\n        Filter(\n            colUserCredentials,\n            And(\n                txt_Username.Text = Title,\n                txt_Password.Text = Password\n            )\n        )\n    ) = 1,\n    Navigate('Welcome', ScreenTransition.None),\n    Notify(\"Invalid Login Details\", NotificationType.Error)\n);\nReset(txt_Username);\nReset(txt_Password);\n</code></pre></li> </ol>"},{"location":"rpa-m2-formula/#8-filtering","title":"8. Filtering","text":"<ol> <li>Create a Dropdown (Dropdown1)</li> <li>Set Items Property <pre><code>[\"All\", \"Pen\", \"Pencil\", \"Mouse\", \"Pad\"]\n</code></pre></li> <li>Set Gallery Items Property <pre><code>Filter(\n    Table1,\n    If(Dropdown1.SelectedText.Value = \"All\", true, Product = Dropdown1.SelectedText.Value)\n)\n</code></pre></li> </ol>"},{"location":"rpa-m2-formula/#9-search-functionality","title":"9. Search Functionality","text":"<ol> <li>Create Search Input (SearchText)</li> <li>Set Gallery Items Property <pre><code>Search(Table1, SearchText.Text, 'Product', 'Country')\n</code></pre></li> </ol>"},{"location":"rpa-m2-formula/#10-combined-search-filter","title":"10. Combined Search &amp; Filter","text":"<ul> <li>Apply to Gallery Items Property <pre><code>Search(\n    Filter(\n        Table1,\n        If(Dropdown1_2.SelectedText.Value = \"All\", true, Country = Dropdown1_2.SelectedText.Value)\n    ),\n    search_inp_2.Text,\n    Product\n)\n</code></pre> ```</li> </ul>"},{"location":"rpa-m2/","title":"RPA","text":""},{"location":"rpa-m2/#create-a-power-apps-application-showcasing-login-functionality-with-validation","title":"Create a Power Apps application showcasing login functionality with validation.","text":"<p>login-screen-1.txt login-screen-2.txt</p>"},{"location":"rpa-m2/#create-a-sharepoint-list-and-implement-cascading-dropdowns-in-power-apps","title":"Create a SharePoint List and Implement Cascading Dropdowns in Power Apps","text":"<p>Create a new list in SharePoint under the team RPA Sem 12 </p> <p>\ud83d\udccc Code Reference: cascading-dropdown.txt </p> <p> </p> <p>The list should look similar to this:  </p> <p> </p>"},{"location":"rpa-m2/#power-apps-configuration","title":"Power Apps Configuration","text":"<ol> <li>Connect the SharePoint List </li> <li>Open Power Apps \u2192 Create a Canvas App </li> <li> <p>Connect to the \"LocationData\" SharePoint list  </p> </li> <li> <p>Add Cascading Dropdowns </p> </li> <li>Country Dropdown (<code>ddlCountry</code>) <pre><code>Distinct(LocationData, Country)\n</code></pre></li> <li> <p>City Dropdown (<code>ddlCity</code>) <pre><code>Filter(LocationData, Country = ddlCountry.Selected.Result).City\n</code></pre></p> </li> <li> <p>Add Personalization (Bottom-Left Corner) </p> </li> <li>Add a Label </li> <li>Set <code>Text</code> to: <pre><code>\"Welcome, \" &amp; User().FullName\n</code></pre></li> </ol>"},{"location":"rpa-m2/#create-a-canvas-app-that-demonstrates-how-to-use-local-and-global-variables","title":"Create a Canvas app that demonstrates how to use local and global variables.","text":"<p>local-variable.txt</p> <p>global-variable.txt</p> <p>calculator.txt</p>"},{"location":"rpa-m2/#create-an-expense-tracker-app-for-microsoft-teams-and-publish-it-in-the-team-channel","title":"Create an expense tracker app for Microsoft teams and publish it in the team channel","text":"<ol> <li> <p>Set Up Data </p> <ul> <li>Use Microsoft Lists, SharePoint, or Dataverse.  </li> <li>Add columns: Expense Name, Amount, Category, Date, Status (Hold/Approved/Rejected), Submitted By.  </li> </ul> </li> <li> <p>Create the App in Power Apps </p> <ul> <li>Connect to your data source.  </li> <li>Power Apps will auto-generate the form.  </li> </ul> </li> <li> <p>Customize the Form </p> <ul> <li>Modify fields for better usability.  </li> <li>Use this formula for status color coding: <pre><code>Switch(\n    ThisItem.'Expense Status',\n    \"Hold\", Color.Orange,\n    \"Approved\", Color.Green,\n    \"Rejected\", Color.Red\n)\n</code></pre></li> </ul> </li> </ol> <p>expense-tracker.txt</p>"},{"location":"rpa-m2/#search-and-filter","title":"Search and Filter","text":"<p>search.txt</p> <p>filter.txt</p>"},{"location":"rpa-pad/","title":"Rpa pad","text":"Power automate desktop Power Apps"},{"location":"rpa-pad/#power-automate-desktop","title":"Power Automate Desktop","text":""},{"location":"rpa-pad/#check-palindrome-number","title":"Check Palindrome Number","text":"<p>Create a bot to check whether the given number is Palindrome or not.</p> <p>Palindrome</p> <p>1\ufe0f\u20e3 Input a number. 2\ufe0f\u20e3 Convert the input to a number. 3\ufe0f\u20e3 Initialize <code>reversedNumber = 0</code> and store the original number as <code>tempNumber</code>. 4\ufe0f\u20e3 Loop while <code>originalNumber</code> is not 0:     - Extract the last digit (<code>originalNumber mod 10</code>).     - Update <code>reversedNumber</code> (<code>reversedNumber * 10 + last digit</code>).     - Remove the last digit from <code>originalNumber</code> (<code>originalNumber / 10</code>). 5\ufe0f\u20e3 Compare <code>reversedNumber</code> with <code>tempNumber</code>. 6\ufe0f\u20e3 Print \"Palindrome\" if equal, else \"Not a Palindrome\".  </p> <p>palindrome.txt</p>"},{"location":"rpa-pad/#check-vowel-or-consonant","title":"Check Vowel or Consonant","text":"<p>Create a PAD flow to determine if the input character is a vowel or consonant.</p> <p>Vowel-consonant</p> <p>1\ufe0f\u20e3 Take input from the user (a single character). 2\ufe0f\u20e3 Convert the character to lowercase for case insensitivity. 3\ufe0f\u20e3 Check if the character is a vowel (<code>a, e, i, o, u</code>) using a switch case:     - \u2705 If it matches, display \"It is a vowel\".     - \u274c Otherwise, display \"It is a consonant\".  </p> <p>vowel-consonant.txt</p>"},{"location":"rpa-pad/#move-pdf-and-docx-files","title":"Move PDF and DOCX Files","text":"<p>Create a PAD flow to move PDF and DOCX files from the download location to a designated folder on your machine.</p> <p>Note</p> <p>Choose a filter to limit the files retrieved. This allows wild cards, for example, <code>*.txt</code> or <code>document?.doc</code>. To allow for multiple file filters, separate the choices with a semi-colon, for example, <code>*.txt;*.exe</code>.</p> <p>move-files.txt</p>"},{"location":"rpa-pad/#check-even-or-odd-number","title":"Check Even or Odd Number","text":"<p>Take a number input from the user and display whether it is Even or Odd (e.g., \"Even Number\" or \"Odd Number\").</p> <p>Note</p> <p>Use % Number mod 2 % to determine if the number is even or odd.</p> <p>even-odd.txt</p>"},{"location":"rpa-pad/#process-full-name-to-uppercase","title":"Process Full Name to Uppercase","text":"<p>Prompt the user to provide their complete name, convert it to UPPERCASE, count the characters, and display the result.</p> <p>Note</p> <p>Display: Your Full Name is %TextWithNewCase% and is of %TextWithNewCase.length% characters.</p> <p>name-uppercase.txt</p>"},{"location":"rpa-pad/#validate-mobile-number","title":"Validate Mobile Number","text":"<p>Ask the user for a mobile number, ensure it is 10 digits, and print it using a message dialog box.</p> <p>Note</p> <p>Use split text to separate the numbers and store into a list, then iterate through the list to validate.</p> <p>verify-mobile-number.txt</p>"},{"location":"rpa-pad/#perform-addition-and-subtraction","title":"Perform Addition and Subtraction","text":"<p>Take two number inputs from the user, calculate Addition and Subtraction, and display the results using a Message Box.</p> <p>Note</p> <p>You are in 12th semester, so this should be straightforward.</p> <p>add-subtract.txt</p>"},{"location":"rpa-pad/#group-employees-by-salary","title":"Group Employees by Salary","text":"<p>Read Employee Salary Data from an Excel file, categorize employees based on salary, and write the group into the Excel Group column.</p> <p>Note</p> <p>Open Excel, read salary data, and categorize employees into \"Group1\" (&gt;= 50k) or \"Group2\" (&lt; 50k) based on their salary.</p> <p>salary-excel.txt</p>"},{"location":"rpa-pad/#extract-tutorial-titles-from-website","title":"Extract Tutorial Titles from Website","text":"<p>Create a bot to extract all tutorial titles from https://www.xelplus.com/all-tutorials/ and display the extracted data in a message box.</p> <p>Note</p> <p>Change the link if needed and enable the Power Automate extension.</p> <p>web-to-excel.txt</p>"},{"location":"rpa-pad/#collect-family-holiday-destination-suggestions","title":"Collect Family Holiday Destination Suggestions","text":"<p>Create a bot that collects family holiday destination suggestions from three members (India, US, UK), adds them to a list, randomly removes two destinations, and displays the remaining options in a message box.</p> <p>Note</p> <p>Use a shuffle list to remove destinations randomly.</p> <p>family-holiday.txt</p>"},{"location":"rpa-pad/#hr-onboarding-process","title":"HR Onboarding Process","text":"<p>Create a bot for the HR onboarding process that reads data from an Excel file (<code>EmployeeID Generation.xlsx</code>), fills data dynamically on the portal, generates Employee ID and Corporate ID, and stores them in an Excel file (http://happybots.in/Employee-Onboarding-Process.html).</p> <p>Note</p> <p>Skip this question in the exam if possible.</p> <p>hr-main.txt</p> <p>hr-subflow.txt</p>"},{"location":"rpa-pad/#multiplication-table","title":"Multiplication Table","text":"<p>Create a PAD flow to generate a Multiplication Table.</p> <p>Note</p> <p>This is an easy task.</p> <p>multiplication-table.txt</p>"},{"location":"rpa-tee/","title":"PAD Automation","text":""},{"location":"rpa-tee/#create-a-bot-to-check-palindrome-number","title":"Create a Bot to Check Palindrome Number","text":"<p>Create a bot to check the given number is palindrome or not.</p>"},{"location":"rpa-tee/#check-vowel-or-consonant","title":"Check Vowel or Consonant","text":"<p>Create PAD to know input character is vowels or consonant.</p>"},{"location":"rpa-tee/#move-pdf-and-docx-files","title":"Move PDF and DOCX Files","text":"<p>Create PAD flow to moves pdf and docx files from download location to pdf and docx folder that is create in drive present in your machine.</p>"},{"location":"rpa-tee/#check-even-or-odd-number","title":"Check Even or Odd Number","text":"<p>Take a number input from the user and Display the given number is Even or odd (e.g. If Even Display message \"Even Number\" else \"Odd Number\").</p>"},{"location":"rpa-tee/#process-full-name","title":"Process Full Name","text":"<p>Prompt the user to provide their complete name, Change the case to UPPER, Count the characters and display Your full name is %name% and is of %number% characters.</p>"},{"location":"rpa-tee/#validate-mobile-number","title":"Validate Mobile Number","text":"<p>Ask the user for a mobile number, ensure it is 10 digits and print it using a message dialog box.</p>"},{"location":"rpa-tee/#perform-addition-and-subtraction","title":"Perform Addition and Subtraction","text":"<p>Take two number input from user and Derive the Addition, Subtraction and Display using the Message Box.</p>"},{"location":"rpa-tee/#group-employees-by-salary","title":"Group Employees by Salary","text":"<p>Read the Employee Salary Data from the Excel As per the Salary value divide the Employee into the group like if Salary&gt;40k then Group A Else Group B Write the Group into the excel Group column Save and Close Excel.</p>"},{"location":"rpa-tee/#extract-tutorial-titles","title":"Extract Tutorial Titles","text":"<p>Create a bot to Extract all the tutorials title from https://www.xelplus.com/all-tutorials/ and display the extracted data in a message box.</p>"},{"location":"rpa-tee/#scrape-book-details","title":"Scrape Book Details","text":"<p>Design a bot to scrape book details from http://books.toscrape.com, save them into text files and Excel, categorize them, identify the highest-priced book, calculate the average price, and submit these details through a form.</p>"},{"location":"rpa-tee/#collect-holiday-destination-suggestions","title":"Collect Holiday Destination Suggestions","text":"<p>Create a bot that collects family holiday destination suggestions from three members (India, US, UK), adds them to a list, randomly removes two destinations, and displays the remaining options through a message box.</p>"},{"location":"rpa-tee/#hr-onboarding-process","title":"HR Onboarding Process","text":"<p>Create a bot for the HR onboarding process that reads data from an Excel file (EmployeeID Generation.xlsx), fills in data dynamically on the portal, generates Employee ID and Corporate ID, and stores them in an Excel file (http://happybots.in/Employee-Onboarding-Process.html).</p>"},{"location":"rpa-tee/#read-excel-and-store-in-text-file","title":"Read Excel and Store in Text File","text":"<p>Create a PAD flow read the data from excel and store in text file.</p>"},{"location":"rpa-tee/#conditional-statement-examples","title":"Conditional Statement Examples","text":"<p>Conditional statement examples.</p>"},{"location":"rpa-tee/#multiplication-table","title":"Multiplication Table","text":"<p>Multiplication Table</p>"},{"location":"rpa-tee/#cloud-flows-and-power-automate","title":"Cloud Flows and Power Automate","text":""},{"location":"rpa-tee/#send-email-notification-for-microsoft-forms","title":"Send Email Notification for Microsoft Forms","text":"<p>Create a cloud flow that sends an email notification whenever a new response is submitted through a Microsoft Forms survey.</p>"},{"location":"rpa-tee/#leave-request-approval-flow-first-instance","title":"Leave Request Approval Flow (First Instance)","text":"<p>Demonstrate the Leave request approval flow using Power Automate.</p>"},{"location":"rpa-tee/#leave-request-approval-flow-second-instance","title":"Leave Request Approval Flow (Second Instance)","text":"<p>Leave Request approval flow using Power automate. </p>"},{"location":"rpa-tee/#power-apps","title":"Power Apps","text":""},{"location":"rpa-tee/#login-functionality-with-validation","title":"Login Functionality with Validation","text":"<p>Create an app that demonstrates the Login Functionality with validation in the power app.</p>"},{"location":"rpa-tee/#expense-tracker-app-for-microsoft-teams","title":"Expense Tracker App for Microsoft Teams","text":"<p>Create an expense tracker app for Microsoft Teams and publish it in the team channel.</p>"},{"location":"rpa-tee/#cascading-list-with-sharepoint","title":"Cascading List with SharePoint","text":"<p>Create a list on SharePoint with fields Country, City and demonstrate cascading list using canvas app. Add personalization at the bottom of the left corner.</p>"},{"location":"rpa-tee/#search-functionality-in-power-app","title":"Search Functionality in Power App","text":"<p>Create an app that demonstrates the Search functionality in a Power app and creates a list, as mentioned in Snap.</p>"},{"location":"rpa-tee/#canvas-app-with-personalization","title":"Canvas App with Personalization","text":"<p>Create a Canvas App as per the provided snapshot and add personalization to the bottom right corner.</p>"},{"location":"rpa-tee/#expense-tracking-power-app-for-teams","title":"Expense Tracking Power App for Teams","text":"<p>Design a Power App for Teams that facilitates expense tracking for team members. The app should feature a single screen where users can add, view, edit, and delete expense entries. Each expense entry should include date, description, category, amount, and status fields. Implement CRUD functionality to enable users to manage their expenses effectively directly within the Team environment. Ensure that the app provides a user-friendly interface and seamless integration with Microsoft Teams for convenient access and usage by team members.</p>"},{"location":"rpa-tee/#sharepoint-list-with-canvas-app","title":"SharePoint List with Canvas App","text":"<p>Create a list on SharePoint and call it emp_data with the following fields and connect to the Canvas app display form: - Employee ID - Name - Age - Gender - Department - Job Role Add personalization at the bottom of the left corner.</p>"},{"location":"rpa-tee/#form-validation-and-save","title":"Form Validation and Save","text":"<p>Perform validation on the form. Employee ID and Age must be 5 and 3 digits respectively. Add a 'Save' button. Clicking on this button will save the list data.</p>"},{"location":"rpa-tee/#global-variables-in-canvas-app","title":"Global Variables in Canvas App","text":"<p>Create a Canvas app that demonstrates how to use global variables.</p>"},{"location":"rpa-tee/#collection-variables-in-canvas-app","title":"Collection Variables in Canvas App","text":"<p>Create a Canvas app that demonstrates how to use collection variables.</p>"},{"location":"rpa-tee/#screen-navigation-in-canvas-app","title":"Screen Navigation in Canvas App","text":"<p>Create a Canvas app that demonstrates how to navigate from one screen to another.</p>"},{"location":"rpa-tee/#login-credentials-with-sharepoint-list","title":"Login Credentials with SharePoint List","text":"<p>Create a list with login credentials like username and password and connect to Canvas App.</p>"},{"location":"rpa-tee/#module-driven-reference-links","title":"Module Driven Reference Links","text":"<p>Module Driven Reference Link FYR https://www.youtube.com/watch?v=Lpet21432-Y&amp;list=PLpAhafsPn3DsrwenYiCjVR9zMj-Dx7Lx-&amp;index=2 https://www.youtube.com/watch?v=d-XGkPOFjz0&amp;list=PLpAhafsPn3DsrwenYiCjVR9zMj-Dx7Lx-&amp;index=4</p>"},{"location":"rpa-tee/#patch-function","title":"Patch Function","text":"<p>Patch Function</p>"},{"location":"trial/","title":"Trial","text":""},{"location":"trial/#machine-learning-types","title":"Machine Learning Types","text":"<pre><code>graph LR\n    subgraph Input\n    A[Data with Labels] --&gt; B[Supervised Learning]\n    C[Data without Labels] --&gt; D[Unsupervised Learning]\n    E[States + Actions] --&gt; F[Reinforcement Learning]\n    end\n\n    B --&gt; G[Mapping]\n    D --&gt; H[Classes]\n    F --&gt; I[Action]\n\n    B -.-&gt;|Error| B\n    F -.-&gt;|Reward| F\n\n</code></pre>"},{"location":"trial/#supervised-learning","title":"Supervised Learning","text":"<ul> <li>Input: Labeled data (features + target labels)</li> <li>Process: Learning from labeled examples</li> <li>Output: Prediction model</li> <li>Feedback: Error measurement against known labels</li> <li>Applications: </li> <li>Classification (spam detection, image recognition)</li> <li>Regression (price prediction, sales forecasting)</li> </ul>"},{"location":"trial/#unsupervised-learning","title":"Unsupervised Learning","text":"<ul> <li>Input: Unlabeled data</li> <li>Process: Pattern/structure discovery</li> <li>Output: Data grouping/structure</li> <li>Feedback: Internal validation metrics</li> <li>Applications:</li> <li>Clustering (customer segmentation)</li> <li>Dimensionality reduction (feature extraction)</li> </ul>"},{"location":"trial/#reinforcement-learning","title":"Reinforcement Learning","text":"<ul> <li>Input: States + possible actions</li> <li>Process: Trial and error learning</li> <li>Output: Action policy</li> <li>Feedback: Rewards/penalties</li> <li>Applications:</li> <li>Game AI (chess, Go)</li> <li>Robotics (navigation, control)</li> </ul>"},{"location":"trial/#common-algorithms","title":"Common Algorithms","text":"<ul> <li>Supervised: Linear Regression, Random Forest, Neural Networks</li> <li>Unsupervised: K-means, PCA, Autoencoders</li> <li>Reinforcement: Q-Learning, Policy Gradient, DQN</li> </ul>"},{"location":"trial/#reinforcement-learning_1","title":"Reinforcement Learning:","text":"<ul> <li>What to do</li> <li>How to map situations to actions</li> <li>Maximizing a numerical reward signal</li> </ul> <p>Reinforcement learning is an autonomous, self-teaching system that essentially learns by trial and error. It performs actions with the aim of maximizing rewards, or in other words, it is learning by doing in order to achieve the best outcomes.</p> <p>Reinforcement Learning is a feedback-based Machine learning technique in which an agent learns to behave in an environment by performing the actions and seeing the results of actions. For each good action, the agent gets positive feedback, and for each bad action, the agent gets negative feedback or penalty</p>"},{"location":"trial/#key-characteristics","title":"Key Characteristics","text":"<p>Reinforcement Learning is inspired by how humans and animals learn through interactions:</p> <ul> <li>Reward and Punishment: Encourages repeating actions that lead to rewards and avoiding punishments.</li> <li>Trial and Error: Similar to trying different methods until the correct one is found.</li> <li>Learning Over Time: Improvement occurs through continuous experience.</li> <li> <p>Rewards Come from a Sequence of Actions.</p> </li> <li> <p>The learner is not told which actions to take but must discover them through trial and error.</p> </li> <li>Actions affect not only the immediate reward but also future situations and rewards.</li> <li>Works well in problems where a sequence of decisions is important.</li> </ul> <p>RL is an autonomous, self-teaching system that learns by trial and error. The goal is to maximize rewards over time.</p> <p>Example Applications:     - Chess     - Maze solving     - Industrial robot arms     - Path planning     - Sweeper robots</p>"},{"location":"trial/#how-rl-differs-from-supervised-learning","title":"How RL Differs from Supervised Learning","text":"Feature Supervised Learning Reinforcement Learning Training Data Has labeled answers No labeled answers; learns from experience Decision Making Independent of past decisions Dependent on past decisions Learning Method Trained with a dataset Learns through trial and error"},{"location":"trial/#elements-of-rl","title":"Elements of RL","text":"<p>![[Pasted image 20250131000424.png|500]]</p>"},{"location":"trial/#agent","title":"Agent","text":"<ul> <li>Definition: An entity that interacts with the environment.</li> <li>Examples: Robot, human, software program.</li> </ul>"},{"location":"trial/#environment","title":"Environment","text":"<ul> <li>Definition: The external system in which the agent operates.</li> <li>Examples: Physical world, game simulation.</li> </ul>"},{"location":"trial/#learning-process","title":"Learning Process","text":"<ol> <li>The agent moves from the initial state to the goal state.</li> <li>The agent continually asks, \"What is the best action in each state?\"</li> </ol>"},{"location":"trial/#advantages-of-reinforcement-learning","title":"Advantages of Reinforcement Learning","text":"<p>\u2705 No need for predefined instructions or human intervention.  \u2705 Can adapt to both static and dynamic environments.  \u2705 Solves a wide range of problems (decision-making, prediction, optimization).  \u2705 Improves with experience and fine-tunes over time.</p>"},{"location":"trial/#disadvantages-of-reinforcement-learning","title":"Disadvantages of Reinforcement Learning","text":"<p>\u274c Performance depends on the quality of the reward function.  \u274c Designing and tuning RL models can be complex.</p> <p>[!NOTE]</p>"},{"location":"trial/#when-to-apply-reinforcement-learning","title":"When to Apply Reinforcement Learning?","text":"<p>Reinforcement Learning is most suitable when: - The problem environment is complex and uncertain, making traditional programming methods ineffective. - Feedback is sparse, delayed, and dependent on multiple decisions. - Decision-making (actions) follows a feedback loop.</p>"},{"location":"trial/#why-is-reinforcement-learning-difficult","title":"Why Is Reinforcement Learning Difficult?","text":"<p>The toughest parts of Reinforcement Learning are: - Mapping the Environment. - Including All Possible Actions.</p>"},{"location":"trial/#core-concepts","title":"Core Concepts","text":"<ul> <li>Goal-Oriented Learning: The agent learns by trying to achieve a goal.</li> <li>Learning from Consequences: The agent learns from the consequences of its actions.</li> <li>Active Research Area: RL is one of the most active fields in Artificial Intelligence (AI).</li> </ul>"},{"location":"trial/#rl-algorithm-steps","title":"RL Algorithm Steps","text":"<pre><code>graph TD;\n    A[Agent Observes Environment] --&gt; B[Agent Performs Action];\n    B --&gt; C[Agent Moves to New State];\n    C --&gt; D[Agent Receives Reward];\n    D --&gt; E[Agent Evaluates Action - Good or Bad];\n    E --&gt; F[Agent Adjusts Strategy to Maximize Reward];\n\n</code></pre>"},{"location":"trial/#learning-and-planning","title":"Learning and Planning","text":""},{"location":"trial/#two-fundamental-problems-in-sequential-decision-making","title":"Two Fundamental Problems in Sequential Decision Making","text":""},{"location":"trial/#reinforcement-learning-rl","title":"Reinforcement Learning (RL):","text":"<ul> <li>The environment is initially unknown.</li> <li>The agent interacts with the environment.<ul> <li>The agent improves its policy.</li> </ul> </li> </ul>"},{"location":"trial/#planning","title":"Planning:","text":"<ul> <li>A model of the environment is known.</li> <li>The agent performs computations with its model (without any external interaction).</li> <li>The agent improves its policy, also known as deliberation, reasoning, introspection, pondering, thought, search.</li> </ul>"},{"location":"trial/#model-of-the-environment","title":"Model of the Environment:","text":"<ul> <li>A model mimics the behavior of the environment. With the help of the model, one can make inferences about how the environment will behave. For example, if a state and an action are given, the model can predict the next state and reward.</li> <li>The model is used for planning, providing a way to take a course of action by considering all future situations before actually experiencing those situations.</li> <li>Approaches for solving RL problems with the help of the model are termed model-based approach.</li> <li>An approach without using a model is called a model-free approach.</li> </ul> <p>![[Pasted image 20250130232904.png]]</p>"},{"location":"trial/#types-of-reinforcement-learning-algorithms-on-the-basis-of-model-based","title":"Types of Reinforcement Learning Algorithms ( on the basis of model based)","text":"<p>There are various algorithms used in reinforcement learning such as Q-learning, policy gradient methods, Monte Carlo method and many more. All these algorithms can be classified into two broad categories - </p>"},{"location":"trial/#model-free-reinforcement-learning","title":"Model-free Reinforcement Learning :","text":"<ul> <li>It is a category of reinforcement learning algorithms that learns to make decisions by</li> <li>interacting with the environment directly, without creating a model of the environment's</li> <li>dynamics.</li> <li>The agent performs different actions multiple times to learn the outcomes and creates a</li> <li>strategy (policy) that optimizes its reward points. This is ideal for changing, large or complex</li> <li>environments.</li> <li>Not applicable for some scenario like self driving car.</li> </ul>"},{"location":"trial/#model-based-reinforcement-learning","title":"Model-based Reinforcement Learning:","text":"<ul> <li>This category of reinforcement learning algorithms involves creating a model of the environment's dynamics to make decisions and improve performance.</li> <li>Ideal for environments that are static and well-defined, where real-world environment testing is difficult.</li> </ul>"},{"location":"trial/#key-differences-between-model-free-and-model-based-reinforcement-learning","title":"Key Differences Between Model-free and Model-based Reinforcement Learning","text":"Feature Model-Free RL Model-Based RL Learning Approach Direct learning from environment Indirect learning through model building Efficiency Requires more real-world interactions More sample-efficient Complexity Simpler implementation More complex due to model learning Environment Utilization No internal model Builds and uses a model Adaptability Slower to adapt to changes Faster adaptation with accurate model Computational Requirements Less intensive More computational resources needed Examples Q-Learning, SARSA, DQN, PPO Dyna-Q, Model-Based Value Iteration"},{"location":"trial/#rl-framework-the-rl-process-a-loop-of-state-action-reward-and-next-state","title":"RL Framework - The RL Process: A Loop of State, Action, Reward, and Next State","text":"<p>![[Pasted image 20250130232937.png]]</p>"},{"location":"trial/#main-characteristics-of-rl","title":"Main Characteristics of RL","text":"<ul> <li>No supervisor while training.</li> <li>Environment is generally stochastic for real-world applications.</li> <li>Model of the environment can be incomplete.</li> <li>Feedback (Negative/Positive Reward) can be delayed or partial.</li> <li>The agent uses experience from the past to improve its performance over time.</li> <li>Actions that have fetched more rewards are preferred.</li> <li>The agent tries various actions and prefers those that are best or have fetched more rewards.</li> <li>RL uses Markov Decision Process (MDP) framework to define the interaction between a learning agent and its environment.</li> </ul>"},{"location":"trial/#reinforcement-learning-rl-problem-challenges-in-rl","title":"Reinforcement Learning (RL) Problem - Challenges in RL","text":""},{"location":"trial/#trade-off-between-exploration-and-exploitation","title":"Trade-off between Exploration and Exploitation:","text":"<ul> <li>To obtain rewards, an RL agent must prefer actions that it has tried in the past and found effective (Exploit).</li> <li>However, to discover such actions, it must try actions it has not selected before (Explore).</li> </ul> <p>[!NOTE] Neither exploration nor exploitation can be pursued exclusively without failing at the task. </p>"},{"location":"trial/#fundamental-components-of-rl","title":"Fundamental Components of RL","text":"<ul> <li>Policy: Defines the agent\u2019s behavior.</li> <li>Reward Function: Provides feedback on actions.</li> <li>Value Function: Evaluates future rewards.</li> <li>Model of the Environment: Simulates how the environment works.</li> </ul>"},{"location":"trial/#policy","title":"Policy:","text":"<p>A policy is a strategy or set of rules that defines the actions the agent should take in a given state.</p> <ul> <li>The policy can be deterministic (one action for a state) or stochastic (probabilistic actions for a state).</li> <li>The goal is to find an optimal policy that maximizes the total expected reward.</li> </ul> <p>Example:</p> <ul> <li>A robot navigating a maze may follow a policy that says, \"Always turn left unless there's an obstacle, then turn right.\"</li> </ul>"},{"location":"trial/#human-analogy","title":"Human Analogy:","text":"<ul> <li>A policy is like a person's habit or plan of action, such as the decision to exercise every morning or take an umbrella when it's cloudy.</li> </ul>"},{"location":"trial/#value-function","title":"Value function:","text":"<p>Roughly speaking, the value of a state is the total amount of reward an agent can expect to accumulate over the future, starting from that state.  - Rewards determine the immediate, intrinsic desirability of environmental states.  - Values indicate the long-term desirability of states after considering the states likely to follow and the rewards available in those states.  - Example: - A state might always yield a low immediate reward but still have a high value because it is followed by states that yield high rewards. </p>"},{"location":"trial/#human-analog","title":"Human Analog","text":"<ul> <li>Rewards are somewhat like kepleasureur (if high) and ndpainai (if low). - Values correspond to a more rerefined and farsighted judgmenten of how pleased or displeased we are by the environment.nt.</li> </ul>"},{"location":"trial/#reward-function","title":"Reward Function:","text":"<p>The reward function provides feedback on the actions the agent takes, indicating whether an action was good or bad.</p> <ul> <li>It assigns a numeric value to the agent's actions, which the agent uses to evaluate the desirability of its actions in a given state.</li> <li>The goal of the agent is to maximize the cumulative reward over time.</li> </ul> <p>Example:</p> <ul> <li>In a game, winning a round might give a reward of +10, while losing gives a reward of -1.</li> </ul>"},{"location":"trial/#human-analogy_1","title":"Human Analogy:","text":"<ul> <li>The reward function is like the feedback a person gets from their actions, such as feeling happy after a good deed or guilty after a mistake.</li> </ul>"},{"location":"trial/#model-of-the-environment_1","title":"Model of the Environment:","text":"<p>The model of the environment simulates how the environment behaves, helping the agent predict the outcomes of actions.</p> <ul> <li>This model can be used for planning future actions by simulating potential outcomes.</li> <li>A model-free approach directly learns from experience, while a model-based approach uses a model to predict actions' results before performing them.</li> </ul> <p>Example:</p> <ul> <li>A self-driving car may use a model to simulate various driving scenarios and plan its route accordingly.</li> </ul>"},{"location":"trial/#human-analogy_2","title":"Human Analogy:","text":"<ul> <li>The model of the environment is like a mental map that a person forms, which helps them predict the likely outcomes of their actions, such as deciding to avoid a route with heavy traffic.</li> </ul>"},{"location":"trial/#final-element-of-rl-systems-model-of-the-environment","title":"Final Element of RL Systems: Model of the Environment","text":"<ul> <li>The model mimics the behavior of the environment, allowing inferences to be made about how the environment will behave.</li> <li>For example, given a state and action, the model might predict the resultant next state and next reward.</li> <li> <p>Models are used for planning, helping the agent decide on a course of action by considering future situations before they are experienced.</p> </li> <li> <p>Methods for solving RL problems that use models and planning are called model-based methods, while simpler trial-and-error learning methods are called model-free methods.</p> </li> </ul>"},{"location":"trial/#types-of-reinforcement-learning","title":"Types of Reinforcement Learning","text":"<p>There are three main types of Reinforcement Learning (RL): - Value-Based - Policy-Based - Model-Based</p> <p>Each approach has its own strengths and weaknesses, and the choice of algorithm will depend on the specific problem you are trying to solve.</p>"},{"location":"trial/#value-based-reinforcement-learning","title":"Value-Based Reinforcement Learning","text":"<ul> <li>In this approach, the agent learns to estimate the value of each state or action based on the rewards it receives.</li> <li>This value is known as Q-values.</li> <li>The agent then selects the actions with the highest Q-value in each state to maximize its long-term reward.</li> <li>The most commonly used algorithm for value-based reinforcement learning is Q-learning.</li> </ul>"},{"location":"trial/#policy-based-reinforcement-learning","title":"Policy-Based Reinforcement Learning","text":"<ul> <li>In this approach, the agent learns an optimal policy, which is a mapping from states to actions, without calculating the value function.</li> <li>The policy is updated based on the rewards received by the agent, with the goal of maximizing the expected reward over time.</li> <li>The most common algorithm used for policy-based reinforcement learning is the REINFORCE algorithm.</li> </ul>"},{"location":"trial/#model-based-reinforcement-learning_1","title":"Model-Based Reinforcement Learning","text":"<ul> <li>In this approach, the agent learns a model of the environment, which it can use to simulate different scenarios and plan its actions accordingly.</li> <li>The model can learn through supervised or unsupervised learning, and the agent can use it to predict the outcome of its actions before taking them.</li> <li>The most common model-based reinforcement learning algorithm is the Dyna algorithm.</li> </ul>"}]}