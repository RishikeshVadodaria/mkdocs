# Introduction to Computer Vision

## Unit 1
 
## Introduction
- **Image Processing**: Image in ‚Üí Image out.
- **Computer Vision**: Image/Video in ‚Üí Interpretation out.
- **Objective**: Enable computers to see and interpret objects like humans.

## Human vs. Computer Vision
- **Humans**: Quick recognition, intelligent decision-making.
- **Computers**: Require complex processing, pattern recognition, and AI.

## Features of Human Vision
- **Stereo Vision**: Two eyes perceive depth using different distances.
- **Texture & Color**: Identifies objects based on patterns and colors.
- **Object Recognition**: Recognizes objects despite illumination, viewpoint, or expression changes.
- **Context Awareness**: Infers key information from a scene.

## Limitations of Human Vision
- **Memory Constraints**: Limited ability to recall vast image data.
- **Restricted Spectrum**: Limited to visible light.
- **Optical Illusions**: Misinterpretations of size, shape, and perspective.

## Computer Vision vs. Image Processing
- **Image Processing**: Low-level operations (compression, restoration, enhancement).
- **Computer Vision**: High-level understanding (object recognition, scene interpretation).

## Applications of Computer Vision
- **Self-driving Cars**: Navigation and obstacle detection.
- **Facial Recognition**: Identity verification.
- **Augmented Reality**: Merging virtual objects with reality.
- **Medical Imaging**: Detecting anomalies in X-rays and MRIs.
- **Manufacturing**: Detecting defective products.
- **Retail & Banking**: OCR, fraud detection, and identity verification.

## Computer Vision Processing Levels

### Low-Level Processing
- **Enhances image quality** and extracts **basic features** like **edges, corners, textures**.
- Works on **raw pixel data** without understanding objects.
- **Steps for low level processing**:
  - **Image Preprocessing**: Contrast enhancement, noise reduction.
  - **Feature Extraction**: **Edge detection** (Canny, Sobel filters).
  - **Segmentation**: Divides an image into meaningful parts.
  - **Super-Resolution**: Converts **low-resolution** to **high-resolution** images.

!!! Important
    Low-level processing extracts fundamental features such as edges, lines, corners, and salient points from an image. These features serve as the building blocks for higher-level processing, enabling pattern recognition, object detection, and scene understanding.

How Low-Level Processing Helps:
- ‚úÖ Feature Extraction: Identifies edges, textures, and key points in an image.
- ‚úÖ Segmentation: Divides images into meaningful regions and shapes.
- ‚úÖ Noise Reduction: Enhances image clarity by removing unwanted distortions.
- ‚úÖ Super-Resolution: Generates higher-resolution images from fewer pixels.
- ‚úÖ Depth Perception: Uses stereo vision (left & right cameras) to create disparity maps for estimating depth.

### Mid-Level Processing
- Uses **patterns and object features** for recognition.
- Works on **segmented objects** to **classify, track, and detect motion**.
- **Examples**:
  - **Object Detection**: Recognizes and labels objects.
  - **Image Classification**: Assigns categories to images.
  - **Image Matching & Stitching**: Used in **panoramas**.
  - **Object Tracking**: **Predicts movement** using **optical flow**.
  - **Clustering (K-Means)**: Segments objects into groups.

### High-Level Processing
- Involves **complex scene understanding** and **AI-based interpretations**.
- Integrates **low-level features** for **semantic meaning**.
- **Examples**:
  - **Semantic Segmentation**: Classifies pixels into categories (e.g., road, car, tree).
  - **Instance Segmentation**: Differentiates between multiple **objects of the same type**.
  - **Panoptic Segmentation**: Combines **semantic + instance segmentation**.
  - **Deep Learning for Segmentation**: Uses **CNNs & RNNs** for precise object recognition.
  - **Theme Understanding**: Identifies scene context (e.g., **marketplace vs. garden**).
  - **Visual Question Answering (VQA)**: AI interprets **images + text-based queries**.

## Applications of Computer Vision
- **Self-Driving Cars**: Detects lanes, pedestrians, and traffic signs.
- **Facial Recognition**: Matches faces for identity verification.
- **Medical Imaging**: Detects diseases in X-rays & MRIs.
- **Manufacturing**: Identifies **defective products**.
- **Retail & Banking**: Uses **OCR, fraud detection, and customer authentication**.

## Deep Learning for Image Segmentation
üîπ Convolutional Neural Networks (CNNs) play a crucial role in image segmentation, enabling computers to understand objects at a pixel level.

How Deep Learning Works for Image Segmentation:
- 1Ô∏è‚É£ Feature Extraction with CNNs: CNNs process images and detect key features for segmentation.
- 2Ô∏è‚É£ Object Localization with Region Proposal Network (RPN): Identifies potential object locations and generates bounding boxes.
- 3Ô∏è‚É£ Refining Features from the Region of Interest (ROI): CNN extracts features within the bounding box.
- 4Ô∏è‚É£ Instance Segmentation using Fully Convolutional Networks (FCN): The extracted features are passed into an FCN, which learns to segment the object from its surroundings.
- 5Ô∏è‚É£ Binary Mask Output: The FCN produces a binary mask, highlighting which pixels belong to the object and which do not.

üöÄ From raw images to object masks, deep learning models enhance precision in image segmentation by combining feature extraction, region detection, and pixel-level classification! üöÄ

## Difference Between Low-Level and High-Level Features

| **Feature Type** | **Low-Level Features** üñºÔ∏è | **High-Level Features** üß† |
|------------------|--------------------------|---------------------------|
| **Content** | Deals with **raw pixel data**, detecting **edges, textures, and simple patterns**. | Focuses on **object understanding, classification, and relationships**. |
| **Sensitivity** | More **sensitive to noise**, lighting, and orientation changes. | More **robust**, can interpret **complex scenes** despite variations. |
| **Scale** | Extracted from **local regions** (e.g., edges in a small part of the image). | **Global features**‚Äîconsiders the entire image for **context**. |
| **Resources** | Requires **fewer system resources**, as it focuses on simple features. | Uses **advanced AI models**, requiring **higher computation power**. |
| **Use Cases** | Applied in **image segmentation, feature matching, and object detection**. | Used in **image classification, object recognition, and scene understanding**. |

üîç **Low-level features** lay the foundation by detecting **shapes and patterns**, while **high-level features** bring **context and meaning** to an image. Together, they power modern **computer vision applications**! üöÄ

## Edge Detection

## Sharpening Spatial Filters
üñºÔ∏è **Purpose**:
- Removes **blurring** and **enhances edges** in images.
- Highlights **intensity transitions** using **spatial differentiation**.
- **Image gradients** measure the **rate of change in pixel intensity**, crucial for detecting edges.

## Image Gradients
üìå **Fundamental for computer vision & image processing**
üîπ Used for:
‚úÖ **Edge detection**
‚úÖ **Finding object contours**
‚úÖ **Outlining shapes**

üîπ Computes:
- **Gradient Magnitude** (Strength of the edge)
- **Gradient Orientation** (Direction of the edge)

‚ú® **Popular techniques built on image gradients**:
- **Histogram of Oriented Gradients (HOG)**
- **Scale-Invariant Feature Transform (SIFT)**

## Edge Detection Using Image Gradients
üí° **Gradient computation is a key pre-processing step** for edge detection.

### Computing Image Gradients
The **gradient of an image** is calculated using finite differences:
- **Gradient along the vertical direction ($G_y$):**
  $$ G_y = f(r+1, c) - f(r-1, c) $$
- **Gradient along the horizontal direction ($G_x$):**
  $$ G_x = f(r, c+1) - f(r, c-1) $$

üìå **Gradient masks (filters) for edge detection:**

| **Filter** | **Mask** |
|------------|-------------|
| **Vertical ($G_y$) Sobel Filter** | \(\begin{bmatrix} -1 & 0 & 1 \end{bmatrix}\) |
| **Horizontal ($G_x$) Sobel Filter** | \(\begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix}\) |

## Image Gradient & Gradient Vector
üñºÔ∏è **Purpose**:
- Computes **rate of change** in pixel intensity.
- **Gradient Magnitude ($M$)** measures the **strength** of intensity change.
- **Gradient Orientation ($\alpha$)** determines **direction** of the edge.
- The **matrix size** for magnitude and angle is the **same** as the original image.

üîπ **Mathematical Representation:**
- **Gradient Angle ($\alpha$):**
  $$ \alpha = \tan^{-1} \left(\frac{g_y}{g_x} \right) $$
- **Gradient Magnitude ($M$):**
  $$ M = \sqrt{g_x^2 + g_y^2} $$

üìå **Where:**
- $g_x$ = Gradient in the **horizontal direction**.
- $g_y$ = Gradient in the **vertical direction**.
- $\alpha$ = Angle between the **vertical axis** and the **edge direction**.

## Sobel Filter for Edge Detection
üí° **Sobel filters** compute **image gradients** using convolution masks.

### Gradient Computation with Sobel Operator
üîπ **Sobel Operator for Horizontal ($G_x$) and Vertical ($G_y$) Gradients:**

| **Gradient Direction** | **Filter Mask (Kernel)** |
|----------------|-----------------------------------|
| **$G_x$ (Horizontal Gradient)** | $\begin{bmatrix} -1 & 0 & 1 \\ -2 & 0 & 2 \\ -1 & 0 & 1 \end{bmatrix}$ |
| **$G_y$ (Vertical Gradient)** | $\begin{bmatrix} -1 & -2 & -1 \\ 0 & 0 & 0 \\ 1 & 2 & 1 \end{bmatrix}$ |

üîπ **Steps to Compute Edge Strength:**
1Ô∏è‚É£ Convolve the **image** with **$G_x$** to compute **horizontal changes**.
2Ô∏è‚É£ Convolve the **image** with **$G_y$** to compute **vertical changes**.
3Ô∏è‚É£ Compute **gradient magnitude** and **angle** using:
   $$ M = \sqrt{G_x^2 + G_y^2} $$
   $$ \alpha = \tan^{-1} \left(\frac{G_y}{G_x} \right) $$

üìå **Why Sobel Filters?**
‚úÖ Enhances **edges** by detecting **gradients** in both directions.
‚úÖ **Smooths noise** while emphasizing high-frequency intensity changes.
‚úÖ Used in **edge detection algorithms** like **Canny Edge Detector**.

## Gaussian Filter for Image Smoothing
üîπ The **Gaussian filter** is a **smoothing filter** that reduces **noise and detail** in an image.
üîπ It applies a **Gaussian function** to weight pixels, giving higher importance to the center pixel and gradually reducing weights outward.

### Mathematical Representation
The **Gaussian function** for a 2D image is:
$$ G_\sigma(x, y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}} $$
where:
- \( \sigma \) = Standard deviation (controls blurring strength)
- \( x, y \) = Pixel coordinates

üìå **Higher \( \sigma \) ‚Üí More blur**
üìå **Lower \( \sigma \) ‚Üí Less blur, preserves more details**

### Gaussian Filter Kernels
| **Filter Size** | **Kernel Matrix (Normalized)** |
|---------------|----------------------------|
| **3√ó3 (œÉ = 1)** | \( \frac{1}{16} \begin{bmatrix} 1 & 2 & 1 \\ 2 & 4 & 2 \\ 1 & 2 & 1 \end{bmatrix} \) |
| **5√ó5 (œÉ = 1)** | \( \frac{1}{330} \begin{bmatrix} 1 & 4 & 7 & 4 & 1 \\ 4 & 20 & 33 & 20 & 4 \\ 7 & 33 & 54 & 33 & 7 \\ 4 & 20 & 33 & 20 & 4 \\ 1 & 4 & 7 & 4 & 1 \end{bmatrix} \) |
| **5√ó5 (œÉ = 2)** | \( \frac{1}{34} \begin{bmatrix} 1 & 1 & 1 & 1 & 1 \\ 1 & 2 & 2 & 2 & 1 \\ 1 & 2 & 2 & 2 & 1 \\ 1 & 2 & 2 & 2 & 1 \\ 1 & 1 & 1 & 1 & 1 \end{bmatrix} \) |

üìå **Larger filter size ‚Üí More blur & smoothing**
üìå **Smaller filter size ‚Üí Preserves more details**

## Laplacian Filter for Edge Detection
üîπ The **Laplacian filter** is a **second-order derivative filter** used for **edge detection**.
üîπ It highlights regions of **rapid intensity change** by computing the **second derivative** of an image.

### Mathematical Representation
The Laplacian operator is given by:

\[ \nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}\]

where \( f(x, y) \) is the image intensity at a given point.

### Laplacian Filter Kernels
| **Filter Type** | **Kernel Matrix** |
|----------------|------------------|
| **4-Neighbor Laplacian** | \( \begin{bmatrix} 0 & -1 & 0 \\ -1 & 4 & -1 \\ 0 & -1 & 0 \end{bmatrix} \) |
| **8-Neighbor Laplacian** | \( \begin{bmatrix} -1 & -1 & -1 \\ -1 & 8 & -1 \\ -1 & -1 & -1 \end{bmatrix} \) |

üîπ The **4-neighbor Laplacian** considers only direct neighbors, while the **8-neighbor Laplacian** accounts for diagonal edges as well.